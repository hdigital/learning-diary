[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Code snippets of smaller things I learned ‚Äì Today I learned (TIL)"
  },
  {
    "objectID": "posts/2023-06-20-r-cell-conditional/index.html",
    "href": "posts/2023-06-20-r-cell-conditional/index.html",
    "title": "Conditional R cells",
    "section": "",
    "text": "Conditional R cells\nFor R notebooks in Quarto not all information that can be presented in an html-document is feasible for the respective pdf-document. So sometimes, I want to include information in html but not in the pdf.\nInteractive data tables with reactable are an example. They allow to explore smaller data sets quickly within a notebook, but work only in html documents. A pdf simply fails to render with Quarto.\nSo I was looking for a solution to execute R code in a notebook only for the html-document but not the pdf.\nConditional chunk execution is not implemented in Quarto so far ‚Äî see ticket #3260.\nHowever, for R I found an approach that is working well.\n\nif (knitr::is_html_output()) {\n  print(\"code block run\")\n}\n\n[1] \"code block run\"\n\n\n\nif (! knitr::is_html_output()) {\n  print(\"code block not run\")\n}\n\n\nAn example for a notebook with a dynamic table in a html document and a static table in the pdf document"
  },
  {
    "objectID": "posts/2023-06-03-github-pages/index.html",
    "href": "posts/2023-06-03-github-pages/index.html",
    "title": "GitHub Pages",
    "section": "",
    "text": "GitHub Pages\nI published my first two web sites with GithHub Pages.\n\nlearning diary\ndata snippets\n\nQuarto has a tutorial about publishing Quarto sites to GitHub Pages. This worked well.\nI was a little confused by the different options: docs folder, publish command, GitHub Actions.\nThe quarto publish command worked well for the learning diary page. I like that you can publish a page with a command instead of deploying the page with every GitHub push.\nFor the data snippets page I used the GitHub Actions approach. In the project, I have a static page in a subfolder with a Quarto based single index page. So neither the Quarto nor the default GitHub Pages workflow to publish the page seemed to fit well. In the GitHub Actions approach I chose, the page is deployed with every GitHub push."
  },
  {
    "objectID": "posts/2023-04-27-geocoding/index.html",
    "href": "posts/2023-04-27-geocoding/index.html",
    "title": "Geocoding in Python",
    "section": "",
    "text": "Get geographic coordinates for an address with Nominatim from OpenStreetMap data.\n\nfrom geopy.geocoders import Nominatim\n\n# Create a geolocator object\ngeolocator = Nominatim(user_agent=\"get-the-geocode\")\n\n# Define the address for geocoding\naddress = \"Unter Sachsenhausen 6, K√∂ln, Germany\"\n\n# Retrieve the geolocation (latitude and longitude) for the given address\nlocation = geolocator.geocode(address)\n\nprint((location.latitude, location.longitude))\n\n(50.9426253, 6.9524319)\n\n\n\nimport folium\n\ncoordinates = [location.latitude, location.longitude]\n\n# Create a map object\nm = folium.Map(location=coordinates, zoom_start=15)\n\n# Add a marker for each coordinate\nfolium.Marker(location=coordinates, popup=address).add_to(m)\n\nm  # Display the map in Jupyter Notebook\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "posts/2023-06-12-nbdev-clean/index.html",
    "href": "posts/2023-06-12-nbdev-clean/index.html",
    "title": "Jupyter notebooks in Git",
    "section": "",
    "text": "Jupyter notebooks in Git\nWorking with Jupyter notebooks in Git repositories has always caused some struggles for me with the Git commit history. Jupyter notebooks use the json-format and include some metadata such as the number of times a notebook has been run. So far, I have just cleared the output restarted and run notebooks once to have somewhat clean metadata. This has not always worked and let to some slightly noisy git commits.\nNow, I have tried a solution that I remembered when I wanted to commit a Jupyter notebook and run into noisy git diffs again. nbdev_clean removes cell execution related metadata from a notebook.\nnbdev_clean --fname . cleans all Juypter notebooks in a repository. I run it on this learning diary Git repository to clean the two notebooks in the snippets folder. I also used it in the project that initially caused me to look into nbdev.\nFinally, i used Codespaces to quickly create minimal, reproducible examples of git diffs without and with nbdev_clean. Again, Codespaces are really nice."
  },
  {
    "objectID": "posts/2023-04-26-dataverse/index.html",
    "href": "posts/2023-04-26-dataverse/index.html",
    "title": "Dataverse URLs",
    "section": "",
    "text": "Dataverse URLs\nI followed a talk on electoral politics in Honduras. The presenter referred to the very stable two party system in Honduras. That made me interested to look at election results in Honduras. A quick analysis with Elections Global gave a good overview ‚Äì see below.\nThe technical point is that I wanted to access the original data file at the Harvard Dataverse.\nData uploaded to the Dataverse is imported and a tab separated data version of the imported data is provided by the Dataverse. This is not the original file and may include some import errors. I ran into the issue in previous work so that I have worked with the original data file from the Dataverse. However, there is no direct link available at the Dataverse page of a data file.\nHere is an example for the Elections Global data used in the snippet ‚Äì see page screenshot below.\ndoi:10.7910/DVN/OGOURC/YK9DOZ&version=2.0\nSo I tried to find the permanent link to the original data file.\nFirst, I checked the documentation of the Dataverse API but could not find a way to access an original data file through API parameters. Only the imported file is available through the API.\nSecond, I got the link by checking the request from clicking on the respective dynamic button at the Dataverse page with the browser developer tools. However, this url does not seem to have a structure that is related to the identifier of the dataset. Getting the url of the original data file this way is cumbersome.\nFor now, I will start to using the imported data version with the provided url for data files from the Dataverse.\n\n\nCode\nlibrary(conflicted)\nlibrary(tidyverse)\nconflicts_prefer(dplyr::filter)\n\n\n\nif(FALSE) {\n  url_csv &lt;- \"https://dataverse.harvard.edu/api/access/datafile/3754546?format=original\"\n  elec_raw &lt;- read_csv(url_csv)\n}\n\nurl &lt;- \"https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/OGOURC/YK9DOZ\"\n\nif(! exists(\"elec_raw\")) {\n  elec_raw &lt;- read_tsv(url)\n}\n\n# glimpse(elec_raw)\n\n\n\nCode\nhnd &lt;-\n  elec_raw |&gt;\n  filter(country == \"HND\") |&gt;\n  mutate(\n    year = as.integer(substr(election_date, 1, 4)),\n    seats_share = 100*seats/seats_total\n    )\n\nhnd |&gt;\n  summarise(\n    n = n(),\n    share_mean = mean(seats_share, na.rm = TRUE) |&gt; round(1),\n    share_max = max(seats_share, na.rm = TRUE) |&gt; round(1),\n    year_first = min(year, na.rm = TRUE),\n    year_last = max(year, na.rm = TRUE),\n    .by = party\n  ) |&gt;\n  select(party, n, n:year_last) |&gt;\n  arrange(desc(n), desc(share_mean))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparty\nn\nshare_mean\nshare_max\nyear_first\nyear_last\n\n\n\n\nNational Party of Honduras\n25\n60.8\n100.0\n1923\n2013\n\n\nLiberal Party of Honduras\n20\n40.3\n62.1\n1923\n2013\n\n\nother (other-script)\n13\n4.0\n9.4\n1923\n2013\n\n\nLiberal Constitutionalist Party of Honduras\n2\n71.4\n100.0\n1916\n1923\n\n\nNational Reformist Movement\n2\n13.6\n20.3\n1954\n1957\n\n\nLiberty and Refoundation\n1\n28.9\n28.9\n2013\n2013\n\n\nAnti-Corruption Party\n1\n10.2\n10.2\n2013\n2013\n\n\nCentral American Unionist Party\n1\n8.7\n8.7\n1926\n1926\n\n\nDemocratic Unification Party\n1\n3.9\n3.9\n2005\n2005\n\n\n\n\n\n\n\n\nCode\nhnd |&gt;\n  mutate(n = n(), .by = party) |&gt;\n  filter(n &gt; 10) |&gt;\n  ggplot(aes(year, seats_share, colour = party)) +\n  geom_line()"
  },
  {
    "objectID": "posts/2023-02-26-altair/index.html",
    "href": "posts/2023-02-26-altair/index.html",
    "title": "Python visualization with Altair",
    "section": "",
    "text": "I have been interested in finding a visualization library for Python that is similiar to ggplot2 in R. I like the quick plots in pandas but Matplotlib has never worked for me.\nFor customized visualizations I like the ggplot2 approach with layers. Its grammar of graphics provides a good balance between adjusting a visualization and productivity. The code with layers is nicely readable.\nVega-Altair, a Python library, uses a grammar to create visualization as well. So I gave it a try and it went well ‚Äì see code below.\npandas and Altaire are likely to be the visualization tools that I use primarily in Python.\nHere is some information on the penguins dataset üêß in the visualization. I didn‚Äôt want to use mtcars üöó again.\n\nimport altair as alt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndt = sns.load_dataset(\"penguins\")\n\n(alt.Chart(dt)\n    .mark_circle()\n    .encode(\n      alt.X('flipper_length_mm', scale=alt.Scale(zero=False)),\n      alt.Y('body_mass_g', scale=alt.Scale(zero=False)),\n      color='species',\n      tooltip=['species', 'island', 'sex']\n    )\n)\n\n\n\n\n\n\n\n\ndt\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nGentoo\nBiscoe\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nBiscoe\n46.8\n14.3\n215.0\n4850.0\nFemale\n\n\n341\nGentoo\nBiscoe\n50.4\n15.7\n222.0\n5750.0\nMale\n\n\n342\nGentoo\nBiscoe\n45.2\n14.8\n212.0\n5200.0\nFemale\n\n\n343\nGentoo\nBiscoe\n49.9\n16.1\n213.0\n5400.0\nMale\n\n\n\n\n344 rows √ó 7 columns"
  },
  {
    "objectID": "posts/2023-03-15-pyscript/index.html",
    "href": "posts/2023-03-15-pyscript/index.html",
    "title": "PyScript (WebAssembly)",
    "section": "",
    "text": "I used pyscript for the first time and created a web page that run some Python code.\nSo here is the script I run.\n\nimport random\n\nn = 20\nemojis = \"üôÇüòäüôÇüòÄüòáüòÖüòÉüòÑüòÅüòÇüòÜüòâüòãüòéü§ó\"\n\nlines = [\"\".join(random.choices(emojis, k=n)) for index in range(n)]\n\nprint(\"\\n\".join(lines))\n\nü§óüòÄü§óüòãüòéüòâüòÖüòäüòÅüòäüòÇüòéü§óüòÑüòÉüòáüòÜüòãüòÜüòé\nüòãüòéüòÄüòÖüòÑüòÅüòÇüòÜüòéüòáü§óüòÉüòâüòÑüòÖüòâüòÖüòâüòÉüòÅ\nüòâüòÑüòÖüòéüôÇüôÇüòÜü§óüòäüòÜüòãüòÉüòäüòÇüòãüòÉüòâüòÑüòÜüòé\nüòÄüòÅüòáüòÑüòéüòÑüòáüòÑüôÇüòÖü§óüôÇüòÅüòÄüòÅü§óüòáüòÑüòãüòÉ\nüòÜüòÇüòäüòãüòâüòáüòáüòéüòÇüòéüòÄüòÄüòÅüòÉüôÇüòéüòÑüòÄüòãüòÅ\nüòäüòéüòÅüòäüòäüòäüòäüòÖüòÅüòãü§óüôÇüòÉüòÑüòÑüòÉüòÅüôÇüòÅüôÇ\nüòÑüòãüôÇüôÇüòÄüôÇüòÅüòÑüòãüòãüòáüòÜüòéüòÖüòÉüòÑüôÇüôÇüòâüòÄ\nüòÉüôÇüòÖü§óüòÇüòÉüòÄüôÇüòäüòäü§óüòäüòäüòÅüòÅüòÖüòÖüòÇüòÜüôÇ\nüòÄüòáüòÇüòÄüòÖüòÉüòäüòÑüòãü§óüòáüòáüòÑüòéüòÅüòãüòÑüôÇüòÑüòâ\nüòÇü§óüòÅüòâüôÇüòéüòéüòÅüòÉüòÇü§óüòÖüòáüòÅüòÄüòãüòäüòÖüòäüòä\nüòáüòÜüôÇüòéü§óüòÄü§óüôÇüôÇüòéüòáüòáüòÜüòÖüòÖüôÇüòÇüòÖüòÅü§ó\nüòäüòãüòéüòáüòáüòâüòäüòãüòÑüòÇüòÜüòÇü§óüòÑüòâüòÄüòâüòéüòÖüòé\nüòÉüòÑü§óüòéü§óüôÇüòáüòÑüòÅüòâüòÉüòéüòéüòÉüòÉüòÖüòÄüôÇüôÇüòâ\nüòÖüòÇüòÖü§óüòÄü§óüòâüòéüòâüòäüòâüòÅüòáüòéü§óüòãüòÑüòáüòÑüòÇ\nüòâüòÇüôÇüòäüòÉüòéü§óüòÜüòÉüòäüôÇüòâüòäüòãüòÖüòãüòÜü§óüôÇüòä\nüòäüôÇüòÇüòäüòâüòáü§óüòÖüòÅüôÇüòäüòáüôÇüòãüòÜüòÉüôÇüòäüòÇüòÄ\nüòÜüòÜüòÜüòéüòãüòâüòÉüòÇüòÅüòÜüòÅüôÇüòäüòãü§óüòãüòâüòÉüòÅüòÅ\nüòÄüôÇüòäüòÉüòÇüòÑü§óüòÅüòãüòÉü§óü§óüòäüòÜüòÅüòÑüòáüòÑüòéüòÇ\nüôÇüòÄüòÇüòÉüòÄüòäüòãüôÇüòÑüòÜüòÅüòáüòÉüòéüòãüòÜüòäüòéüòÜüòâ\nüòáüòÖüòÜüòÜüòÜüòáüòÅüòéüòéüòéüôÇüòéüòÄüòÅüòÑüòÅüòÄü§óüòÅüòÑ\n\n\nHere is the full html page that uses pyscript.\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n\n    &lt;head&gt;\n        &lt;meta charset=\"UTF-8\"&gt;\n        &lt;title&gt;Happy DSS Hacking&lt;/title&gt;\n        &lt;link rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /&gt;\n        &lt;script defer src=\"https://pyscript.net/latest/pyscript.js\"&gt;&lt;/script&gt;\n    &lt;/head&gt;\n\n    &lt;body&gt;\n        &lt;py-script&gt;\n            import random\n\n            n = 100\n            emojis = \"üôÇüòäüôÇüòÄüòáüòÖüòÉüòÑüòÅüòÇüòÜüòâüòãüòéü§ó\"\n\n            lines = [\"\".join(random.choices(emojis, k=n)) for index in range(n)]\n\n            print(\"\\n\".join(lines))\n        &lt;/py-script&gt;\n    &lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/2023-04-23-chatgpt/index.html",
    "href": "posts/2023-04-23-chatgpt/index.html",
    "title": "R coding with ChatGPT",
    "section": "",
    "text": "R coding with ChatGPT\nFinally I got into ChatGPT and started using it.\nI was inspired to give ChatGPT a try after reading a post. The author describes using ChatGPT to code a  model.\nSo I had a conversation with ChatGPT about the social sciences, statistics and R.\nI have to say that I am impressed.\nChatGPT and I had an exchange about R. I asked for some examples. ChatGPT originally had a preference for Base-R code but it used more Tidyverse-R approaches after I asked for it. Or it converted the Base-R code to Tidyverse-R at my request.\nThe code examples were good and I really liked the comments it added to the code. At some point ChatGPT went back to Base-R and I could not fully convince it to use a Tidyverse-R first approach.\nSo here is a nice output from our exchange. I asked for a text analysis of a Biden speech in R.\nParts from the content of the exchange are below.\nI added the rvest::read_html parts from the ChatGPT suggestion. I did not find a way that ChatGPT added it to its initial script. ChatGPT had some Base-R and Tidyverse-R confusion at this point. I updated the title of the figure to the new speech title used as well.\nI don‚Äôt use tidytext regularly so looking up the information would have taken some time for me. Here, ChatGPT was very helpful. Thanks.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(rvest)\n\n# Read in the HTML document\nhtml_doc &lt;- read_html(\"https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\")\n\n# Extract the text\nbiden_speech &lt;- html_text(html_doc)\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(\n    x = \"Frequency\",\n    y = \"Word\",\n    title = \"Joe Biden's American Jobs Plan speech\",\n    subtitle = \"Most common words\"\n    )\n\n\n\n\n\n\nuser can we analyse a biden speech?\nChatGPT Yes, we can use text analysis techniques to analyze a speech by Joe Biden. Here‚Äôs an example using the tidytext package:\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Load speech data\nbiden_speech &lt;- read_lines(\"https://www.rev.com/blog/transcripts/joe-biden-covid-speech-transcript-september-9\")\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(x = \"Frequency\", y = \"Word\", title = \"Most common words in Joe Biden's COVID speech\")\nIn this example, we load the transcript of a speech by Joe Biden on the topic of COVID-19, which is available as a text file from the Rev.com blog. We tokenize the speech using the unnest_tokens() function, remove stop words using the anti_join() function, and calculate word frequencies using the count() function. Finally, we visualize the most common words using ggplot2. Note that in order to run this code, you will need to have the readr package installed to read in the text file from the web.\nuser the url does not work\nChatGPT I apologize for that. Here‚Äôs an updated example using a different speech by Joe Biden that is available as a text file from the University of Pennsylvania:\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Load speech data\nbiden_speech &lt;- read_lines(\"https://www.sas.upenn.edu/~jkingsby/BidenIowaSpeech.txt\")\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(x = \"Frequency\", y = \"Word\", title = \"Most common words in Joe Biden's Iowa speech\")\nIn this example, we load a different speech by Joe Biden that is available as a text file from the University of Pennsylvania. The rest of the code is the same as in the previous example.\nuser that url is also not working. do you have a link for a biden speech\nChatGPT I apologize for the inconvenience. Here is a link to a transcript of a recent speech by Joe Biden on infrastructure:\nhttps://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\nYou can copy the text of the speech from this page and use it in the read_lines() function to load it into R for analysis using the tidytext package.\nuser how can i convert a html document to text in r?\nChatGPT You can use the rvest package in R to extract text from HTML documents. Here‚Äôs an example code snippet that shows how to do this:\nlibrary(rvest)\n\n# Read in the HTML document\nhtml_doc &lt;- read_html(\"https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\")\n\n# Extract the text\ntext &lt;- html_text(html_doc)\n\n# Print the text\ncat(text)\nIn this example, we use the read_html() function from rvest to read in the HTML document from the provided URL. We then use the html_text() function to extract the text from the HTML document. Finally, we use cat() to print the text to the console.\nNote that the rvest package is designed for web scraping, so it is important to respect the terms of use and not use it to scrape websites without permission.\nuser ok, can you add that to the r code snippet above?\nChatGPT\n(‚Ä¶)"
  },
  {
    "objectID": "posts/2023-02-18-jupyter/index.html",
    "href": "posts/2023-02-18-jupyter/index.html",
    "title": "Jupyter notebooks with Quarto",
    "section": "",
    "text": "Jupyter notebooks with Quarto\nJupyter notebooks can be rendered with Quarto.\nIn a first step, I create a simple notebook with the code from the Quarto documentation on Jupyter Lab. Secondly, I copied the notebook and added a Quarto header in a Raw first cell. Finally, I converted the original notebook into a Quarto document with quarto convert.\nI rendered all versions of the Jupyter notebook with Quarto and here are the results:\n\nJupyter notebook\nnotebook with Quarto first cell\nnotebook converted to Quarto document\n\nI also learned that you have to pass an option when rendering ipynb-files ‚Äì quarto render notebook.ipynb --execute. The assumption is that a notebook was already run and that the results shall be rendered.\nThis all worked well for me and it solved a major issue I had with Jupyter notebooks. With R Markdown I really liked that you could convert a notebook into static HTML. To my knowledge, this was not possible with Jupyter notebooks. They could be exported to HTML in Jupyter Lab but not rendered into HTML.\n\n\n\nJupyter Lab"
  },
  {
    "objectID": "posts/2023-06-30-dplyr-programming/index.html",
    "href": "posts/2023-06-30-dplyr-programming/index.html",
    "title": "dplyr programming",
    "section": "",
    "text": "TODO ‚Äî write post - add dplyr logo - maybe ‚Äì create sections\nhttps://dplyr.tidyverse.org/articles/programming.html\nlibrary(tidyverse)\n\n\ncars &lt;-\n  datasets::mtcars |&gt;\n  as_tibble()\n\nvar_select &lt;- \"cyl\""
  },
  {
    "objectID": "posts/2023-06-30-dplyr-programming/index.html#pronoun-.data",
    "href": "posts/2023-06-30-dplyr-programming/index.html#pronoun-.data",
    "title": "dplyr programming",
    "section": "Pronoun .data",
    "text": "Pronoun .data\n\ncars |&gt; count(.data[[var_select]])\n\n\n\n\n\ncyl\nn\n\n\n\n\n4\n11\n\n\n6\n7\n\n\n8\n14"
  },
  {
    "objectID": "posts/2023-06-30-dplyr-programming/index.html#embrace-argument",
    "href": "posts/2023-06-30-dplyr-programming/index.html#embrace-argument",
    "title": "dplyr programming",
    "section": "Embrace argument",
    "text": "Embrace argument\n\ncount_var &lt;- \\(.dt, .var) summarise(.dt, n = n(), .by = all_of({{.var}}))\n\ncount_var(cars, var_select)\n\n\n\n\n\ncyl\nn\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var(cars, c(var_select, \"vs\"))\n\n\n\n\n\ncyl\nvs\nn\n\n\n\n\n6\n0\n3\n\n\n4\n1\n10\n\n\n6\n1\n4\n\n\n8\n0\n14\n\n\n4\n0\n1"
  },
  {
    "objectID": "posts/2023-06-30-dplyr-programming/index.html#name-injection",
    "href": "posts/2023-06-30-dplyr-programming/index.html#name-injection",
    "title": "dplyr programming",
    "section": "Name injection",
    "text": "Name injection\n\ncars |&gt;\n  summarise(\"{var_select}_count\" := n(),\n            .by = all_of({{var_select}}))\n\n\n\n\n\ncyl\ncyl_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var2 &lt;- function(dt, var) {\n  summarise(dt, \"{var}_count\" := n(),\n            .by = all_of({{var}}))\n}\n\ncount_var2(cars, \"cyl\")\n\n\n\n\n\ncyl\ncyl_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var3 &lt;- function(dt, var) {\n  summarise(dt, \"{{var}}_count\" := n(),\n            .by = all_of({{var}}))\n}\n\ncount_var3(cars, var_select)\n\n\n\n\n\ncyl\nvar_select_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\nsummarise_dt &lt;- function(data, var) {\n  data |&gt;\n    summarise(\n      \"mean_{{var}}\" := mean({{ var }}),\n      \"sum_{{var}}\" := sum({{ var }}),\n      \"n_{{var}}\" := n()\n   )\n}\n\nsummarise_dt(cars, cyl)\n\n\n\n\n\nmean_cyl\nsum_cyl\nn_cyl\n\n\n\n\n6.1875\n198\n32"
  },
  {
    "objectID": "posts/2023-04-27-posit-cloud/index.html",
    "href": "posts/2023-04-27-posit-cloud/index.html",
    "title": "Posit Cloud",
    "section": "",
    "text": "Posit Cloud\nI use RStudio in Posit Cloud sometimes. It is a convenient solution on a Chromebook or on a computer where R/RStudio is not installed. I also like to use it for mini-project that I work on from different machines.\nOver the last days, I used it a little more. One goal was to figure out how a more extensive use would work out.\nThis worked out well. I like just opening a browser and start working with R in RStudio. Especially, a Chrome browser with the tab in full screen mode works very well. It almost feels like working on a desktop application.\nWorking in Posit Cloud, I am still struggling slightly with two issues.\nFirst, not all shortcuts work the way I am used to from the RStudio desktop application. Some browser shortcuts take precedence over RStudio shortcuts. Showing the command pallete works. So I can use it to run a command from the keyboard. However, I am just used to some shortcuts that I am irritated if typing them does not lead to the expected next step working in RStudio.\nSecond, I find the file handling still a little inconvenient. Uploading a file into to project folder or moving files across project folders takes some steps and mulitple clicks. Here, the Posit Cloud interface to RStudio is just not as reactive as for example file handling in Google Drive.\nUsing RStudio with Posit Cloud regularly remains a regular part of my data science tools.\nActually, this time I used it so extensivly that I exceeded the free quota of my account. So I have to wait for a while until I can start using it again.\n\n\n\nPosit Cloud limit"
  },
  {
    "objectID": "posts/2023-06-24-str-glue/index.html",
    "href": "posts/2023-06-24-str-glue/index.html",
    "title": "string interpolation with str_glue()",
    "section": "",
    "text": "string interpolation with str_glue()\nIn R, I like string interpolation with glue and prefer it over Base-R paste(), paste0(), sprintf(). Regularly, I use glue() and forget to load the respective library at the top of the script or find glue::glue() rather verbose.\nA tidyverse blog post made me realize that stringr includes a str_glue() function that wraps glue(). stringr is loaded with library(tidyverse) so that I can include it into my regular tidyverse workflow.\nIt is also documented on the stringr cheatsheet, but I have not relized that. It serves as useful reminder to look at the Posit Cheatsheets more regularly to review and update my workflow.\n\nlibrary(tidyverse)\n\nname &lt;- \"Jane\"\n\nstr_glue(\"Hi {name}. How are you?\")\n\nHi Jane. How are you?"
  },
  {
    "objectID": "snippets/r-cell-conditional.html",
    "href": "snippets/r-cell-conditional.html",
    "title": "Conditional R code cell execution",
    "section": "",
    "text": "https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/cars.html"
  },
  {
    "objectID": "snippets/r-cell-conditional.html#explore-data",
    "href": "snippets/r-cell-conditional.html#explore-data",
    "title": "Conditional R code cell execution",
    "section": "Explore data",
    "text": "Explore data"
  },
  {
    "objectID": "snippets/jupyter.html",
    "href": "snippets/jupyter.html",
    "title": "Learning",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nOriginal Jupyter notebook rendered with Quarto\nsee post\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "snippets/jupyter-quarto.html",
    "href": "snippets/jupyter-quarto.html",
    "title": "Learning",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nQuarto document converted from Jupyter notebook with quarto convert\nsee post\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "snippets/jupyter-options.html",
    "href": "snippets/jupyter-options.html",
    "title": "Jupyter Quarto",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nJupyter notebook with Quarto options in first cell\nsee post\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "posts/2023-05-01-wikipedia-data/index.html",
    "href": "posts/2023-05-01-wikipedia-data/index.html",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "",
    "text": "I wanted to get the first image of a Wikipedia page and the coordinates.\nChatGPT was very helpful here as well.\nThe code ChatGPT provided worked with the examples it used. I made only some small adjustments to the code below."
  },
  {
    "objectID": "posts/2023-05-01-wikipedia-data/index.html#image",
    "href": "posts/2023-05-01-wikipedia-data/index.html#image",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Image",
    "text": "Image\n\n\nCode\ntry:\n    import wikipedia\nexcept ImportError:\n    ! pip install wikipedia\n\n\nCollecting wikipedia\n  Using cached wikipedia-1.4.0-py3-none-any.whl\nRequirement already satisfied: beautifulsoup4 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.0.0 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from wikipedia) (2.31.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from requests&lt;3.0.0,&gt;=2.0.0-&gt;wikipedia) (3.1.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from requests&lt;3.0.0,&gt;=2.0.0-&gt;wikipedia) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from requests&lt;3.0.0,&gt;=2.0.0-&gt;wikipedia) (2.0.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from requests&lt;3.0.0,&gt;=2.0.0-&gt;wikipedia) (2023.5.7)\nRequirement already satisfied: soupsieve&gt;1.2 in /Users/hd/hd/learning/learning-diary/.venv/lib/python3.10/site-packages (from beautifulsoup4-&gt;wikipedia) (2.4.1)\nInstalling collected packages: wikipedia\nSuccessfully installed wikipedia-1.4.0\n\n\nChatGPT added comments to every line of the code. I combined them into blocks to make the snippet more concise.\n\nimport urllib\n\nimport requests\nimport wikipedia\n\nfrom bs4 import BeautifulSoup\n\n# Set the Wikipedia page title and get page\npage_title = \"Berlin\"\npage = wikipedia.page(page_title)\n\n# Get html content of page and parse it with BeautifulSoup\nhtml = page.html()\nsoup = BeautifulSoup(html, \"html.parser\")\n\n# Find the infobox image element and get url image\nimage_element = soup.find(\"table\", class_=\"infobox\").find(\"img\")\nimage_url = \"https:\" + image_element[\"src\"]\n\n# Download the image\nurllib.request.urlretrieve(image_url, 'image.jpg')\n\n('image.jpg', &lt;http.client.HTTPMessage at 0x7fd1ae7ecd90&gt;)"
  },
  {
    "objectID": "posts/2023-05-01-wikipedia-data/index.html#coordinates",
    "href": "posts/2023-05-01-wikipedia-data/index.html#coordinates",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Coordinates",
    "text": "Coordinates\n\nimport requests\nimport json\n\n# function to get the coordinates from the infobox of a Wikipedia article\ndef get_coordinates(title):\n    url = \"https://en.wikipedia.org/w/api.php\"\n    params = {\n        \"action\": \"query\",\n        \"prop\": \"coordinates\",\n        \"titles\": title,\n        \"format\": \"json\",\n        \"formatversion\": 2\n    }\n    response = requests.get(url, params=params)\n    data = json.loads(response.text)\n    pages = data[\"query\"][\"pages\"]\n    coordinates = None\n    for page in pages:\n        if \"coordinates\" in page:\n            coordinates = page[\"coordinates\"][0]\n            break\n    return coordinates\n\n# example usage\ntitle = \"Berlin\"\ncoordinates = get_coordinates(title)\nprint(coordinates[\"lat\"], coordinates[\"lon\"])\n\n52.52 13.405"
  },
  {
    "objectID": "posts/2023-05-01-wikipedia-data/index.html#map",
    "href": "posts/2023-05-01-wikipedia-data/index.html#map",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Map",
    "text": "Map\n\nimport folium\n\nmap_coord = [coordinates['lat'], coordinates['lon']]\n\n# create the map\nmap = folium.Map(location=map_coord, zoom_start=3.5)\n\n# add a marker at the location\nfolium.Marker(location=map_coord, popup=title).add_to(map)\n\n# display the map\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "posts/2023-02-26-quarto/index.html",
    "href": "posts/2023-02-26-quarto/index.html",
    "title": "A few days of Quarto",
    "section": "",
    "text": "So I have had my first experience with creating dynamic documents in Quarto. It has been a pleasant experience. I could use some of my RMarkdown und knitr skills and like that it is a program independent of R and RStudio. Working in VS Code to create a blog on Things I Learned worked well.\nOnly working with Python was really challenging. For some time several attempts to find the local Python version in the env folder did not work. quarto check found the respective Python version but it was not used when I rendered the document. At the end it was simply the header option jupyter: python3 in the qmd-document that did the trick.\nRendering a document with Python and R cells remained a challenge. Again, it was an option that was missing. Setting #| python.reticulate: false in a Python cell solved the issue.\nMany of my Python struggles in Quarto may have been related to the reticulate R package."
  },
  {
    "objectID": "posts/2023-02-26-quarto/index.html#quarto",
    "href": "posts/2023-02-26-quarto/index.html#quarto",
    "title": "A few days of Quarto",
    "section": "",
    "text": "So I have had my first experience with creating dynamic documents in Quarto. It has been a pleasant experience. I could use some of my RMarkdown und knitr skills and like that it is a program independent of R and RStudio. Working in VS Code to create a blog on Things I Learned worked well.\nOnly working with Python was really challenging. For some time several attempts to find the local Python version in the env folder did not work. quarto check found the respective Python version but it was not used when I rendered the document. At the end it was simply the header option jupyter: python3 in the qmd-document that did the trick.\nRendering a document with Python and R cells remained a challenge. Again, it was an option that was missing. Setting #| python.reticulate: false in a Python cell solved the issue.\nMany of my Python struggles in Quarto may have been related to the reticulate R package."
  },
  {
    "objectID": "posts/2023-02-26-quarto/index.html#docker",
    "href": "posts/2023-02-26-quarto/index.html#docker",
    "title": "A few days of Quarto",
    "section": "Docker",
    "text": "Docker\nTo get there I also created a Dockerfile to have an OS independent version of Quarto. That was another challenge until I first found a Rocker configuration that worked with Python. It is a whopping 4.5 GB image but incudes Latex to create pdf-files.\nLater I did some more experimenting with Docker and created a Jupyter Lab Docker image that is also quite large with almost 5 GB. In addition, I created a smaller image that includes only a minimal Python and Jupyter Lab. At least this one is a little smaller than 1 GB.\nI‚Äôll try to work with the local Quarto versions mainly but it is good to have OS independent Docker versions as well."
  },
  {
    "objectID": "posts/2023-02-26-quarto/index.html#python-in-quarto",
    "href": "posts/2023-02-26-quarto/index.html#python-in-quarto",
    "title": "A few days of Quarto",
    "section": "Python in Quarto",
    "text": "Python in Quarto\nHere is a Quarto Guide demonstration of a line plot on a polar axis, see Figure¬†1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'}\n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure¬†1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html",
    "href": "posts/2023-02-16-welcome/index.html",
    "title": "Things I learned: A new TIL",
    "section": "",
    "text": "My idea is to keep a more systematic collection of things I learned (TIL).\nI was inspired by posts of Simon Wilson and Peter Baumgartner that documented things they have learned.\nSo here is an initial version and today the TIL has been Quarto.\nHere is an example of integrating Tidyverse-R code.\nlibrary(tidyverse)\n\nmtcars &lt;- as_tibble(datasets::mtcars)\n\nggplot(mtcars, aes(x = hp, y = mpg)) +\n  geom_point(aes(color = factor(cyl))) +\n  geom_smooth()\nHere is an example of integrating Python code.\nimport statsmodels.api as sm\nimport pandas as pd\n\nmtcars = sm.datasets.get_rdataset('mtcars').data\n\nmtcars.plot(x = \"hp\", y = \"mpg\", kind = \"scatter\")"
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html#some-background",
    "href": "posts/2023-02-16-welcome/index.html#some-background",
    "title": "Things I learned: A new TIL",
    "section": "Some background",
    "text": "Some background\nSetting up a blog in Quarto was easy and well documented. So I started quickly.\nGetting the right Python version running in Quarto was quite a challenge. At the end, the documented recommendation to work with a virtual environment in an env folder worked. It took me some time to get there.\nIt only worked temporarily and I will try to run Python in Quarto again at some later point."
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html#afterwards",
    "href": "posts/2023-02-16-welcome/index.html#afterwards",
    "title": "Things I learned: A new TIL",
    "section": "Afterwards",
    "text": "Afterwards\nIt turned out that the particular challenge was having a page with R and Python.\nFor Python pages a header option was missing. jupyter: python3 solved the Python challenge that took quite some time.\nRendering a Quarto document with R and Python was only possible with a version Docker on the computer."
  },
  {
    "objectID": "posts/2023-06-04-codespaces/index.html",
    "href": "posts/2023-06-04-codespaces/index.html",
    "title": "GitHub Codespaces",
    "section": "",
    "text": "GitHub Codespaces\nGitHub offered me to review the code of a pull request in GitHub Codespaces. It is an environment to run code online. I used it briefly before but not for one of my GitHub repositories. Today, I gave it a try for the pull request of a repository.\nFor the pull request, it created an environment with VS Code as the IDE and included Python as well as Git. I used it for a small Django project of mine. Two things were required to run my code. First, I needed to install the Python packages used by the project. The project includes a requirements file with pinned versions so that installing the dependencies was easy. Second, it asked me to add some VS Code extensions which I did as well.\nCompleting these two steps allowed me to work in an online enviroment very similiar to my local VS Code set up. It was linked to the GitHub repository so that I could sync my cloud changes with the project. I was impressed how smoothly it went and how little configuration it required.\nI made some minor modifications to the project to use Codespaces even more effortlessly in the future. First, I updated my settings.json.example so that I can quickly create a copy in a Codesspaces settings.json that includes my settings. Second, I specified the VS Code extensions I am regularly using in a launch.json. These two additions should allow me to work in new Codespaces in the future even more quickly.\nOverall, I really liked my first more in depth usage of Codespaces and plan to use it more in the future. I have yet to figure out how much I can use it with free quota and what monthly costs may occur by using it more regularly."
  },
  {
    "objectID": "posts/2023-06-17-git-rebase/index.html",
    "href": "posts/2023-06-17-git-rebase/index.html",
    "title": "Git rebase interactive",
    "section": "",
    "text": "Git rebase interactive\nGit rebase interactive is nice. I have used Git for a long time and correcting wrong commits has been a hassle so far. I try to keep a nice Git history and pay attention to details in Git commits. Merge conflicts and rebasing in Git have so far been challenging to me and I run regular into conflicts.\nSo today I was pleasently surprised how well interactive rebasing in Git works. Here is the magic message:\ngit rebase -i HEAD~5\nRevising the commit history in a text editor worked really well.\n\npick c86752b Use date last modified for TIL post\npick faa548f Add post Jupyter notebooks in Git\npick 86096fa Add TIL Markdown comments\npick a682d0d Add codespace init script\npick c993202 Add VS Code settings\n\n# Rebase 22b5523..c993202 onto 22b5523 (5 commands)\n#\n# Commands:\n# p, pick &lt;commit&gt; = use commit\n# r, reword &lt;commit&gt; = use commit, but edit the commit message\n# e, edit &lt;commit&gt; = use commit, but stop for amending\n# s, squash &lt;commit&gt; = use commit, but meld into previous commit\n# f, fixup [-C | -c] &lt;commit&gt; = like \"squash\" but keep only the previous\n#                    commit's log message, unless -C is used, in which case\n#                    keep only this commit's message; -c is same as -C but\n#                    opens the editor\n# x, exec &lt;command&gt; = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with 'git rebase --continue')\n# d, drop &lt;commit&gt; = remove commit\n# l, label &lt;label&gt; = label current HEAD with a name\n# t, reset &lt;label&gt; = reset HEAD to a label\n# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]\n#         create a merge commit using the original merge commit's\n#         message (or the oneline, if no original merge commit was\n#         specified); use -c &lt;commit&gt; to reword the commit message\n# u, update-ref &lt;ref&gt; = track a placeholder for the &lt;ref&gt; to be updated\n#                       to this position in the new commits. The &lt;ref&gt; is\n#                       updated at the end of the rebase\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#"
  },
  {
    "objectID": "posts/2023-03-20-r-wasm/index.html",
    "href": "posts/2023-03-20-r-wasm/index.html",
    "title": "WebR (WebAssembly)",
    "section": "",
    "text": "WebR (WebAssembly)\nI read about the webR release on the Tidyverse blog. It allows to run R in a browser.\nSo I went to webr.r-wasm.org and gave it a try.\nI tried to install the tidyverse with webr::install(\"tidyverse\"). That did not work. For me, there is little use of R without the tidyverse.\nInstalling dplyr and ggplot2 individually worked. So that I could run the following code.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndt &lt;- as_tibble(mtcars)\nglimpse(dt)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,‚Ä¶\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,‚Ä¶\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16‚Ä¶\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180‚Ä¶\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,‚Ä¶\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.‚Ä¶\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18‚Ä¶\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,‚Ä¶\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,‚Ä¶\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,‚Ä¶\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,‚Ä¶\n\nggplot(dt, aes(x=hp, y=mpg, color=cyl)) + geom_point()\n\n\n\n\nTyping the R commands in a browser shell without tab completion and no R help was challenging though.\nHaving R in a browser quickly available is nice üòä."
  },
  {
    "objectID": "posts/2023-02-22-hello-jupyter/index.html",
    "href": "posts/2023-02-22-hello-jupyter/index.html",
    "title": "Hello Jupyter",
    "section": "",
    "text": "Hello Jupyter\nI used my new Quarto and Jupyter skills to create web pages for an introduction to notebooks that Arnim Bleier gave recently at GESIS DSS."
  },
  {
    "objectID": "posts/2023-til/index.html",
    "href": "posts/2023-til/index.html",
    "title": "Today I learned (TIL)",
    "section": "",
    "text": "Set default printing function for data frames in Quarto notebook with html option df-print: kable.\nUseful to have html tables instead of monospace tables in notebooks.\nSo far, I prefer kable (knitr::kable()) over paged (rmarkdown::paged_table())).\n---\ntitle: \"Document\"\nformat:\n   html:\n     df-print: kable\n---"
  },
  {
    "objectID": "posts/2023-til/index.html#june",
    "href": "posts/2023-til/index.html#june",
    "title": "Today I learned (TIL)",
    "section": "",
    "text": "Set default printing function for data frames in Quarto notebook with html option df-print: kable.\nUseful to have html tables instead of monospace tables in notebooks.\nSo far, I prefer kable (knitr::kable()) over paged (rmarkdown::paged_table())).\n---\ntitle: \"Document\"\nformat:\n   html:\n     df-print: kable\n---"
  },
  {
    "objectID": "posts/2023-til/index.html#june-1",
    "href": "posts/2023-til/index.html#june-1",
    "title": "Today I learned (TIL)",
    "section": "29. June",
    "text": "29. June\nDidn‚Äôt know n_distinct() and used length(unique()) for too long. A small and nice thing i learned that makes pipes more readable."
  },
  {
    "objectID": "posts/2023-til/index.html#june-2",
    "href": "posts/2023-til/index.html#june-2",
    "title": "Today I learned (TIL)",
    "section": "13. June",
    "text": "13. June\nAdding a comment in Markdown by using standard html comments. It works for Markdown in pandoc used by Quarto.\n&lt;!--- comment  --&gt;\n\n&lt;!---\nmulti-line\ncomments\n--&gt;\nI used it now with the current TIL page to have a short intro about a new TIL on the landing page. The previous one sentence summary of the page is now a comment."
  },
  {
    "objectID": "posts/2023-til/index.html#june-3",
    "href": "posts/2023-til/index.html#june-3",
    "title": "Today I learned (TIL)",
    "section": "10. June",
    "text": "10. June\nAdding a page break to a pdf in Quarto.\n---\nformat: pdf\n---\n\nPage 1\n\n{{&lt; pagebreak &gt;}}\n\nPage 2\nIn addition, I learned to ignore shortcuts in a cell with {.markdown shortcodes=\"false\"}"
  },
  {
    "objectID": "posts/2023-til/index.html#june-4",
    "href": "posts/2023-til/index.html#june-4",
    "title": "Today I learned (TIL)",
    "section": "9. June",
    "text": "9. June\nI wanted to run a Bash shell script from any folder. The initial solution worked on my local computer but not on GitHub Codespaces. Here is the solution I came up with. The script runs from any location or stops and gives a message that it should be run from the script folder.\n# Use path relative to script location, if feasible\nif [ -n \"$BASH_SOURCE\" ]; then\n    cd \"$( cd \"$(dirname \"${BASH_SOURCE[0]}\")\" ; pwd -P )\"\nelse\n    if ! [ -e \"package-lock.json\" ]; then\n        echo \"Run script in project folder\"\n        exit 1\n    fi\nfi"
  },
  {
    "objectID": "posts/2023-til/index.html#may",
    "href": "posts/2023-til/index.html#may",
    "title": "Today I learned (TIL)",
    "section": "17. May",
    "text": "17. May\nAnother use of the Base-R shorthand anonymous function and explaining it to a colleague. I like to use .x now for the local variable name to make the local context more explicit.\nadd_three &lt;- \\(.x) .x+3"
  },
  {
    "objectID": "posts/2023-til/index.html#may-1",
    "href": "posts/2023-til/index.html#may-1",
    "title": "Today I learned (TIL)",
    "section": "6. May",
    "text": "6. May\nExcluding variables in tidyselect is now done with ! as I found out by reading the documentation more carfully. I have still used - to exclude variables by their name. This is not documented in the tidyselect help page anymore.\nreadstata13 creates more R friendly data structures than haven. Its default option converts labeled data into factors if appropriate."
  },
  {
    "objectID": "posts/2023-til/index.html#may-2",
    "href": "posts/2023-til/index.html#may-2",
    "title": "Today I learned (TIL)",
    "section": "5. May",
    "text": "5. May\nUsed Quarto a lot and got more comfortable with the options ‚Äî esp.¬†caching, creating pdf, figures."
  },
  {
    "objectID": "posts/2023-til/index.html#may-3",
    "href": "posts/2023-til/index.html#may-3",
    "title": "Today I learned (TIL)",
    "section": "3. May",
    "text": "3. May\nConvert an RMarkdown file into an R file with knitr::purl(\"purl.Rmd\") ‚Äì see details.\nChatGPT did not provide the solution. I remembered doing this years ago. An internet search quickly led to the information needed."
  },
  {
    "objectID": "posts/2023-til/index.html#may-4",
    "href": "posts/2023-til/index.html#may-4",
    "title": "Today I learned (TIL)",
    "section": "2. May",
    "text": "2. May\nA bug in the current version of RStudio kept me busy. I reinstalled R and RStudio on Windows, but RStudio did not find the new R version afterwards. So I reinstalled the two and it kept not working. Fortunately, I found information about the RStudio bug somewhat quickly. I installed the daily build and had R/RStudio running again.\nOriginally, I only wanted to do a quick data analysis but my previous R/RStudio updates came in between."
  },
  {
    "objectID": "posts/2023-til/index.html#apr.",
    "href": "posts/2023-til/index.html#apr.",
    "title": "Today I learned (TIL)",
    "section": "25. Apr.",
    "text": "25. Apr.\nI got back into Quarto and created a website for a learning project I have started. My goal is to have some structured information about topics of a book I am reading and some code snippets that apply concepts of the book.\nSetting up the page worked well. I got a little confused by the quarto difference between freeze and cache. I also wondered why the cache was added into several folders in the main directory and not into a _cache folder."
  },
  {
    "objectID": "posts/2023-til/index.html#apr.-1",
    "href": "posts/2023-til/index.html#apr.-1",
    "title": "Today I learned (TIL)",
    "section": "3. Apr.",
    "text": "3. Apr.\nI read about the new pandas release. None of the changes seem to be relevant for my work with pandas"
  },
  {
    "objectID": "posts/2023-til/index.html#feb.",
    "href": "posts/2023-til/index.html#feb.",
    "title": "Today I learned (TIL)",
    "section": "25. Feb.",
    "text": "25. Feb.\nI worked on code from a causal inference book. It includes Stata, R and Python versions of the examples.\nFor R and Python I wanted to have one environment to install all dependencies. This led me to conda.\nCreating a new conda environment in a new file was extremly slow. It also took me a while to fully configure Jupyter Lab with Python and R.\nAt the end, VS Code seems to be the more convenient interface."
  },
  {
    "objectID": "posts/2023-06-02-dalle-ai-images/index.html",
    "href": "posts/2023-06-02-dalle-ai-images/index.html",
    "title": "AI images with DALL-E",
    "section": "",
    "text": "AI images with DALL-E\nToday, I became aware of an OpenAI service to generate images ‚Äî DALL-E.\nThis has worked well and may solve my issue of needing images for blog posts, readme documents, and other content. I like having visual elements in writings and presentations.\nSometimes, images from Wikimedia Commons worked well. It often took some time to find nice images. DALL-E may be a quicker approach to get an image.\nI had to pay for the service but the number of images that can be generated for 15$ seem to be resonable.\nI have still to twist the art styles to results that I like.\n\nHere are some examples.\n‚Äúa man working on a computer ‚Äì style Pieter Bruegel the Elder‚Äù\n\n‚Äúa working class man on a computer ‚Äì leipzig school art style‚Äù\n\n‚ÄúA comic book cover of a superhero working on a computer doing data analysis‚Äù\n\n‚Äúa man working on a computer ‚Äì style 3d art‚Äù"
  },
  {
    "objectID": "posts/2023-07-16 r4ds-pr/index.html",
    "href": "posts/2023-07-16 r4ds-pr/index.html",
    "title": "First pull request accepted ¬∑ üòä",
    "section": "",
    "text": "First pull request accepted ¬∑ üòä\nMy first public pull request on Github was accepted.\nOver the last weeks, I have been reading R for Data Science (2e) (R4DS). The first edition really helped me to get deeply into the tidyverse. So I was interested in the content of the second edition.\nAt some point, I realized that the book used an older parameter in case_when() that was recently superseded in dplyr 1.1. Since, I had switched to the new .default parameter already, I thought that it may be a small and valuable contribution to update the section.\nMaking the code changes was easy. It took me a little to find out how to clone the project and submit the pull requests. The GitHub documentation was helpful and it went smoothly following it.\nI have used R4DS and the tidyverse so often that I am quite proud about my very minor addition to it."
  },
  {
    "objectID": "posts/2023-02-17-geom-col/index.html",
    "href": "posts/2023-02-17-geom-col/index.html",
    "title": "Horizontal bar chart",
    "section": "",
    "text": "Horizontal bar chart\nTo have horizontal bar charts ordered by frequency, I have used geom_bar() and coord_flip for a long time.\nI have now learned in an example that this is not necessary.\nHere are a few examples and the code for future references.\n\nlibrary(tidyverse)\n\nmtcars &lt;- as_tibble(datasets::mtcars)\n\n\nggplot(mtcars, aes(x = cyl)) +\n  geom_bar(fill = \"lightgreen\")\n\n\n\n\nI used to do some pre-processing to prepare data for the plot.\n\npl_dt &lt;-\n  mtcars |&gt;\n  mutate(cyl = fct_infreq(factor(cyl)) |&gt; fct_rev())\n\nFor the figure, I used coord_flip.\n\nggplot(pl_dt, aes(cyl)) +\n  geom_bar(fill = \"grey\") +\n  coord_flip()\n\n\n\n\nThat was not necessary, as I have learned now.\n\nggplot(pl_dt, aes(y = cyl)) +\n  geom_bar(fill = \"lightblue\")\n\n\n\n\nHere is an alternative approach with geom_col().\n\npl_dt &lt;-\n  mtcars |&gt;\n  count(cyl) |&gt;\n  mutate(cyl = fct_reorder(factor(cyl), n))\n\nggplot(pl_dt, aes(x = n, y = cyl)) +\n  geom_col(fill = \"lightblue\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning",
    "section": "",
    "text": "First pull request accepted ¬∑ üòä\n\n\n\n\n\n\n\nR\n\n\ngit\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2023\n\n\n\n\n\n\n  \n\n\n\n\nstring interpolation with str_glue()\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nConditional R cells\n\n\n\n\n\n\n\nR\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGit rebase interactive\n\n\n\n\n\n\n\ngit\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGitHub Codespaces\n\n\n\n\n\n\n\ncloud\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWikipedia, Python, ChatGPT\n\n\n\n\n\n\n\nPython\n\n\nAI\n\n\ngeo\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPosit Cloud\n\n\n\n\n\n\n\nR\n\n\ncloud\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nR coding with ChatGPT\n\n\n\n\n\n\n\nR\n\n\nAI\n\n\n\n\n\n\n\n\n\n\n\nApr 23, 2023\n\n\n\n\n\n\n  \n\n\n\n\nA few days of Quarto\n\n\n\n\n\n\n\nDocker\n\n\nPython\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n  \n\n\n\n\ndplyr programming\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\n\n\n\n\n  \n\n\n\n\nToday I learned (TIL)\n\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n  \n\n\n\n\nJupyter notebooks in Git\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGitHub Pages\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2023\n\n\n\n\n\n\n  \n\n\n\n\nAI images with DALL-E\n\n\n\n\n\n\n\nAI\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDataverse URLs\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nGeocoding in Python\n\n\n\n\n\n\n\nPython\n\n\ngeo\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWebR (WebAssembly)\n\n\n\n\n\n\n\nR\n\n\ncloud\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPyScript (WebAssembly)\n\n\n\n\n\n\n\nPython\n\n\ncloud\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPython visualization with Altair\n\n\n\n\n\n\n\nPython\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHello Jupyter\n\n\n\n\n\n\n\nPython\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\n\n\n\n\n  \n\n\n\n\nJupyter notebooks with Quarto\n\n\n\n\n\n\n\nPython\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n  \n\n\n\n\nHorizontal bar chart\n\n\n\n\n\n\n\nR\n\n\nggplot\n\n\n\n\n\n\n\n\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nThings I learned: A new TIL\n\n\n\n\n\n\n\nR\n\n\nPython\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\n\n\n\n\nNo matching items"
  }
]
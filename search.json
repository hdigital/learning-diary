[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Code snippets of smaller things I learned – Today I learned (TIL)"
  },
  {
    "objectID": "posts/2023-11-23-py-jupyter-lite/index.html",
    "href": "posts/2023-11-23-py-jupyter-lite/index.html",
    "title": "JupyterLite",
    "section": "",
    "text": "I listened to the the recent Talk Python To Me episode Celebrating JupyterLab 4 and Jupyter 7 Releases and became aware of JupyterLite which I had not used before.\nI was impressed to see that you can now run JupyterLab in a browser.\nMany shortcuts work and you can activate the command pallette with Shift + Cmd/Ctrl + C\nFor me, the examples in the pyodide folder were helpful and demonstrated how much Python data analysis can be already done with this fully web based version of Jupyter.\nSo now I can run Python in an interactive environment on any computer with JupyterLite. I may use Codespaces or Google Colab in a browser more often because they provide the standard Python environment. For small snippets and examples I will also use JupyterLite."
  },
  {
    "objectID": "posts/2023-11-23-py-jupyter-lite/index.html#visualization-example",
    "href": "posts/2023-11-23-py-jupyter-lite/index.html#visualization-example",
    "title": "JupyterLite",
    "section": "Visualization example",
    "text": "Visualization example\nHere is an example form the altair.ipynb notebook in the pyodide folder. It runs here but also in the JupyterLite, purely browser based, version.\n\nimport altair as alt\nimport pandas as pd\n\nsource = pd.DataFrame({\n    'a': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'],\n    'b': [28, 55, 43, 91, 81, 53, 19, 87, 52]\n})\n\nalt.Chart(source).mark_bar().encode(\n    x='a',\n    y='b'\n)"
  },
  {
    "objectID": "posts/2023-11-23-py-jupyter-lite/index.html#http-requests",
    "href": "posts/2023-11-23-py-jupyter-lite/index.html#http-requests",
    "title": "JupyterLite",
    "section": "http requests",
    "text": "http requests\nI played around a little with making http requests. You can install the requests package but the http requests don’t work. You have to use the js module provided by pyodide instead.\nHere is the notebook I wrote.\nnetwork-requests.ipynb.txt\nI added a txt extension because I don’t want the notebook to be rendered in Quarto. Save it, remove the txt extension, drag and drop it into the JupyterLite browser window and run it."
  },
  {
    "objectID": "posts/2023-11-23-py-jupyter-lite/index.html#pip-with-micropip",
    "href": "posts/2023-11-23-py-jupyter-lite/index.html#pip-with-micropip",
    "title": "JupyterLite",
    "section": "pip with micropip",
    "text": "pip with micropip\nYou can install packages with pip. In JupyterLite, it is based on micropip.\nThe recommended way to install packages is:\n%pip install -q snowballstemmer\nSo far, I have been reluctant to use pip with a magic command but may use it more regularly in the future.\nHere is a Python version to use micropip.\nimport micropip\n\nif \"snowballstemmer\" not in micropip.list():\n    await micropip.install(\"snowballstemmer\")"
  },
  {
    "objectID": "posts/2023-02-18-py-jupyter/index.html",
    "href": "posts/2023-02-18-py-jupyter/index.html",
    "title": "Jupyter notebooks with Quarto",
    "section": "",
    "text": "Jupyter notebooks with Quarto\nJupyter notebooks can be rendered with Quarto.\nIn a first step, I create a simple notebook with the code from the Quarto documentation on Jupyter Lab. Secondly, I copied the notebook and added a Quarto header in a Raw first cell. Finally, I converted the original notebook into a Quarto document with quarto convert.\nI rendered all versions of the Jupyter notebook with Quarto and here are the results:\n\nJupyter notebook\nnotebook with Quarto first cell\nnotebook converted to Quarto document\n\nI also learned that you have to pass an option when rendering ipynb-files – quarto render notebook.ipynb --execute. The assumption is that a notebook was already run and that the results shall be rendered.\nThis all worked well for me and it solved a major issue I had with Jupyter notebooks. With R Markdown I really liked that you could convert a notebook into static HTML. To my knowledge, this was not possible with Jupyter notebooks. They could be exported to HTML in Jupyter Lab but not rendered into HTML.\n\n\n\nJupyter Lab"
  },
  {
    "objectID": "posts/2023-06-20-r-cell-conditional/index.html",
    "href": "posts/2023-06-20-r-cell-conditional/index.html",
    "title": "Conditional R cells",
    "section": "",
    "text": "Conditional R cells\nFor R notebooks in Quarto not all information that can be presented in an html-document is feasible for the respective pdf-document. So sometimes, I want to include information in html but not in the pdf.\nInteractive data tables with reactable are an example. They allow to explore smaller data sets quickly within a notebook, but work only in html documents. A pdf simply fails to render with Quarto.\nSo I was looking for a solution to execute R code in a notebook only for the html-document but not the pdf.\nConditional chunk execution is not implemented in Quarto so far — see ticket #3260.\nHowever, for R I found an approach that is working well.\n\nif (knitr::is_html_output()) {\n  print(\"code block run\")\n}\n\n[1] \"code block run\"\n\n\n\nif (!knitr::is_html_output()) {\n  print(\"code block not run\")\n}\n\n\nAn example for a notebook with a dynamic table in a html document and a static table in the pdf document"
  },
  {
    "objectID": "posts/2023-06-02-ai-dalle-images/index.html",
    "href": "posts/2023-06-02-ai-dalle-images/index.html",
    "title": "AI images with DALL-E",
    "section": "",
    "text": "AI images with DALL-E\nToday, I became aware of an OpenAI service to generate images — DALL-E.\nThis has worked well and may solve my issue of needing images for blog posts, readme documents, and other content. I like having visual elements in writings and presentations.\nSometimes, images from Wikimedia Commons worked well. It often took some time to find nice images. DALL-E may be a quicker approach to get an image.\nI had to pay for the service but the number of images that can be generated for 15$ seem to be resonable.\nI have still to twist the art styles to results that I like.\n\nHere are some examples.\n“a man working on a computer – style Pieter Bruegel the Elder”\n\n“a working class man on a computer – leipzig school art style”\n\n“A comic book cover of a superhero working on a computer doing data analysis”\n\n“a man working on a computer – style 3d art”"
  },
  {
    "objectID": "posts/2023-03-15-py-pyscript/index.html",
    "href": "posts/2023-03-15-py-pyscript/index.html",
    "title": "PyScript (WebAssembly)",
    "section": "",
    "text": "PyScript (WebAssembly)\nI used pyscript for the first time and created a web page that run some Python code.\nSo here is the script I run.\n\nimport random\n\nn = 20\nemojis = \"🙂😊🙂😀😇😅😃😄😁😂😆😉😋😎🤗\"\n\nlines = [\"\".join(random.choices(emojis, k=n)) for index in range(n)]\n\nprint(\"\\n\".join(lines))\n\n🙂😋😀😎😄😆🤗😅🙂😊🙂😊😂😀😇😋😄😂😀😆\n😎😇😆😉😃😇😉😊😊😇😇😅😃😀😋😉😅😄😇🙂\n😄😎😀😃😋😁😉😉😉😄😁🤗🙂😄🤗🙂😃😃😅😉\n😀😎😋😋😊😂😎😇😅🙂😇😅😇😀😋🤗🙂😋😄😁\n😄🙂😋😁😆🤗😎🙂😊😋😊🙂😆😉😋😋😋😊😂😇\n😃😊😉😃😃🙂🤗😊😂😁😊😊😉😉😂😅😂😃😅🙂\n😅😄😋🤗😉😊😋🙂😁😎😀🙂😂😄😁🙂😉😇😄😋\n😃😁😃😎😄😁😎😄😁😆😇😋😄😄😅😁😅🙂😆😅\n🙂😂🤗😁😂😉😉😃😉😅🙂😃😀😊🙂😊😁😉😂😆\n😇🤗🙂😀😃😋😁😃😋😆😆😅😆😇😅😄🙂😆🙂😊\n😆😄😇😋🙂😇🙂🙂🙂😃😋😆😂😁😀😇😂😎😎😎\n🤗😀😇😉😎😂🙂😂😅😊😇🤗😂🤗😇😉😀😊😉🙂\n😅🤗😆😋😁😅😋😋🤗😉😆😀😆😄🤗😁🙂🙂😉😀\n🙂😀😁🙂😎😂🙂😁🙂😊😁😋😅😎😅😆🙂😋🙂😆\n😄😃😆😀😅😁😆😊😃😊😋😋😎😂😀😃😅😉😁😂\n🙂😎😀😎😃😁😅😉😁😅😊😊🙂😁😁😁😋😂😃😂\n😃😆😄😇😁😀😆😄😊😇😅😊😎😉😋😁😁😂😀🤗\n😄😎😎😀😃😂🤗🙂😀🙂😋😅😆😅🙂😁🤗😁😁🙂\n😇😉😃😂😃😂🤗😊🙂😊🤗🤗😃🙂😃😋😂😊😋😊\n😁😁😅😊😋😂😋😊😄😂🙂😇😉😎😅😁😃😆😊😂\n\n\nHere is the full html page that uses pyscript.\n&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n\n    &lt;head&gt;\n        &lt;meta charset=\"UTF-8\"&gt;\n        &lt;title&gt;Happy DSS Hacking&lt;/title&gt;\n        &lt;link rel=\"stylesheet\" href=\"https://pyscript.net/latest/pyscript.css\" /&gt;\n        &lt;script defer src=\"https://pyscript.net/latest/pyscript.js\"&gt;&lt;/script&gt;\n    &lt;/head&gt;\n\n    &lt;body&gt;\n        &lt;py-script&gt;\n            import random\n\n            n = 100\n            emojis = \"🙂😊🙂😀😇😅😃😄😁😂😆😉😋😎🤗\"\n\n            lines = [\"\".join(random.choices(emojis, k=n)) for index in range(n)]\n\n            print(\"\\n\".join(lines))\n        &lt;/py-script&gt;\n    &lt;/body&gt;\n\n&lt;/html&gt;"
  },
  {
    "objectID": "posts/2024-07-17-r-sf-intersection/index.html",
    "href": "posts/2024-07-17-r-sf-intersection/index.html",
    "title": "Select map region in R",
    "section": "",
    "text": "Select map region in R\nHere is an example of selecting a region from a map by specifying a rectangle for the selection.\n\n\nCode\ncities &lt;-\n  maps::world.cities |&gt;\n  filter(country.etc == \"Germany\") |&gt;\n  st_as_sf(coords = c(\"long\", \"lat\"), crs = 4326, agr = \"constant\") |&gt;\n  filter(pop &gt;= 100000) |&gt;\n  mutate(label = if_else(pop &gt; 800000, name, NA_character_))\n\nwrite_rds(cities, \"cities-deu.rds\")\n\n\nFirst, I create a map of German cities with more than 100,000 inhabitants.\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\n\ncities &lt;- read_rds(\"cities-deu.rds\")\n\nggplot(cities) +\n  geom_sf(aes(size = pop), color = \"grey80\", alpha = 0.5) +\n  geom_sf_label(aes(label = label), alpha = 0.4) +\n  guides(size = \"none\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\nThen, I select the wider Ruhr area by defining the bottom left and the top right of the selection area.\n\n\nCode\ncreate_sf_rectangle &lt;- function(xmin, xmax, ymin, ymax, crs = \"OGC:CRS84\") {\n  matrix(\n    c(xmin, ymin, xmax, ymin, xmax, ymax, xmin, ymax, xmin, ymin),\n    ncol = 2, byrow = TRUE\n  ) |&gt;\n    list() |&gt;\n    st_polygon() |&gt;\n    st_sfc(crs = crs)\n}\n\nnrw_select &lt;- create_sf_rectangle(6.5, 7.9, 50.9, 51.7)\n\nnrw &lt;-\n  cities |&gt;\n  st_intersection(nrw_select)\n\n\nFinally, I create a map of the cities in the wider Ruhr area.\n\n\nCode\nnrw |&gt;\n  mutate(label = if_else(pop &gt; 500000, name, NA_character_)) |&gt;\n  ggplot() +\n  geom_sf(aes(size = pop), color = \"grey80\", alpha = 0.5) +\n  geom_sf_label(aes(label = label), alpha = 0.4) +\n  guides(size = \"none\") +\n  theme_void()"
  },
  {
    "objectID": "posts/2023-04-27-r-posit-cloud/index.html",
    "href": "posts/2023-04-27-r-posit-cloud/index.html",
    "title": "Posit Cloud",
    "section": "",
    "text": "Posit Cloud\nI use RStudio in Posit Cloud sometimes. It is a convenient solution on a Chromebook or on a computer where R/RStudio is not installed. I also like to use it for mini-project that I work on from different machines.\nOver the last days, I used it a little more. One goal was to figure out how a more extensive use would work out.\nThis worked out well. I like just opening a browser and start working with R in RStudio. Especially, a Chrome browser with the tab in full screen mode works very well. It almost feels like working on a desktop application.\nWorking in Posit Cloud, I am still struggling slightly with two issues.\nFirst, not all shortcuts work the way I am used to from the RStudio desktop application. Some browser shortcuts take precedence over RStudio shortcuts. Showing the command pallete works. So I can use it to run a command from the keyboard. However, I am just used to some shortcuts that I am irritated if typing them does not lead to the expected next step working in RStudio.\nSecond, I find the file handling still a little inconvenient. Uploading a file into to project folder or moving files across project folders takes some steps and mulitple clicks. Here, the Posit Cloud interface to RStudio is just not as reactive as for example file handling in Google Drive.\nUsing RStudio with Posit Cloud regularly remains a regular part of my data science tools.\nActually, this time I used it so extensivly that I exceeded the free quota of my account. So I have to wait for a while until I can start using it again.\n\n\n\nPosit Cloud limit"
  },
  {
    "objectID": "posts/2023-06-03-github-pages/index.html",
    "href": "posts/2023-06-03-github-pages/index.html",
    "title": "GitHub Pages",
    "section": "",
    "text": "GitHub Pages\nI published my first two web sites with GithHub Pages.\n\nlearning diary\ndata snippets\n\nQuarto has a tutorial about publishing Quarto sites to GitHub Pages. This worked well.\nI was a little confused by the different options: docs folder, publish command, GitHub Actions.\nThe quarto publish command worked well for the learning diary page. I like that you can publish a page with a command instead of deploying the page with every GitHub push.\nFor the data snippets page I used the GitHub Actions approach. In the project, I have a static page in a subfolder with a Quarto based single index page. So neither the Quarto nor the default GitHub Pages workflow to publish the page seemed to fit well. In the GitHub Actions approach I chose, the page is deployed with every GitHub push."
  },
  {
    "objectID": "posts/2024-03-22-r-codespaces/index.html",
    "href": "posts/2024-03-22-r-codespaces/index.html",
    "title": "R in Docker and Codespaces",
    "section": "",
    "text": "For my work, I use Docker regularly to create fully reproducible environments."
  },
  {
    "objectID": "posts/2024-03-22-r-codespaces/index.html#docker",
    "href": "posts/2024-03-22-r-codespaces/index.html#docker",
    "title": "R in Docker and Codespaces",
    "section": "Docker",
    "text": "Docker\nFinding a configuration for R with Rocker has taken some effort over time and led to several changes.\nRecently, working with pak has worked well for me to install all R packages when the container is build.\nHere is a minimal example for such a workflow.\nFROM rocker/tidyverse\n\nWORKDIR /home/rstudio\n\nCOPY pkg.lock .\nRUN R -e 'pak::lockfile_install()'\nThe full example is available in my R template. There, I use an R script to create a pkg.lock with the pinned versions of R packages used in a project."
  },
  {
    "objectID": "posts/2024-03-22-r-codespaces/index.html#codespaces",
    "href": "posts/2024-03-22-r-codespaces/index.html#codespaces",
    "title": "R in Docker and Codespaces",
    "section": "Codespaces",
    "text": "Codespaces\nWorking with Python, I use Codespaces quite regularly now. Figuring out a configuration with R took me some time. By now, I have a configuration that I feel comfortable with.\nI started with the example from github.com/revodavid/devcontainers-rstudio that demonstrates running RStudio in Codespaces.\nOver time, I moved to a codespace configuration that uses more of the settings in devcontainer.json and a minimal Dockerfile.\nThe codespace includes R, Python and Quarto. It takes quite some to build though.\nOverall, it is a nice way to briefly explore an R project in a browser without installing any software locally. I keep codespaces only for a short time and delete them quickly. That is why I use Posit Cloud as a persistent online R environment.\nMost of my R development is still in a local RStudio environment though. For reproducibility, I add a Docker configuration and make sure that the final version of a project can be replicated in that environment and has pinned versions of all dependencies."
  },
  {
    "objectID": "posts/2023-08-12-r-dplyr-join-by/index.html",
    "href": "posts/2023-08-12-r-dplyr-join-by/index.html",
    "title": "dplyr join_by() argument",
    "section": "",
    "text": "dplyr join_by() argument\ndplyr 1.1 introduced a new option for the by argument to the *_join() family of functions. You can now use join_by() instead of the previous c().\n\nlibrary(tidyverse)\nlibrary(gapminder)\n\ndt_1 &lt;-\n  gapminder |&gt;\n  left_join(country_codes, by = join_by(country == country))\n\nThe short version without the named parameter works as well when using it as the third parameter in a *_join() function (the second parameter in a pipe.)\n\ndt_2 &lt;-\n  gapminder |&gt;\n  left_join(country_codes, join_by(country == country))\n\nIt is an alternative to using c() in the argument.\n\ndt_3 &lt;-\n  gapminder |&gt;\n  left_join(country_codes, by = c(\"country\" = \"country\"))\n\nThe three created data frames are identical.\n\nidentical(dt_1, dt_2) & identical(dt_1, dt_3)\n\n[1] TRUE\n\n\nAnd here is a figure using the created data frame.\n\n\nCode\nset.seed(2)\n\npl_dt &lt;-\n  dt_1 |&gt;\n  filter(year == max(year)) |&gt;\n  select(country = iso_alpha, gdp_per_capita = gdpPercap, life_expectency = lifeExp)\n\nggplot(pl_dt, aes(x = gdp_per_capita, y = life_expectency)) +\n  geom_point(color = \"darkgrey\") +\n  scale_x_log10() +\n  geom_smooth() +\n  geom_text(\n    data = sample_n(pl_dt, 10),\n    aes(x = gdp_per_capita, y = life_expectency, label = country),\n    vjust = -0.8, size = 3.5\n  )\n\n\n\n\n\n\n\n\n\n\nThis is something I missed when reading the change log of the dplyr 1.1. release and did not find out about by reading the help pages of the *_join() functions.\nIt was different with the multiple matches revisions in dplyr 1.1. Here, I quickly run into the new warning message, explored and used it. To handle multiple matches more explicitly is really nice and I have started to use it regularly.\nThe recent post Teaching the tidyverse in 2023 provided a good review of the new features in the tidyverse released over the last months. I was aware of most of the changes and have started using the new approaches.\nIt is nice to see that the tidyverse is evolving and that the changes are documented so well."
  },
  {
    "objectID": "posts/2023-06-12-py-nbdev-clean/index.html",
    "href": "posts/2023-06-12-py-nbdev-clean/index.html",
    "title": "Jupyter notebooks in Git",
    "section": "",
    "text": "Jupyter notebooks in Git\nWorking with Jupyter notebooks in Git repositories has always caused some struggles for me with the Git commit history. Jupyter notebooks use the json-format and include some metadata such as the number of times a notebook has been run. So far, I have just cleared the output restarted and run notebooks once to have somewhat clean metadata. This has not always worked and let to some slightly noisy git commits.\nNow, I have tried a solution that I remembered when I wanted to commit a Jupyter notebook and run into noisy git diffs again. nbdev_clean removes cell execution related metadata from a notebook.\nnbdev_clean --fname . cleans all Juypter notebooks in a repository. I run it on this learning diary Git repository to clean the two notebooks in the snippets folder. I also used it in the project that initially caused me to look into nbdev.\nFinally, i used Codespaces to quickly create minimal, reproducible examples of git diffs without and with nbdev_clean. Again, Codespaces are really nice."
  },
  {
    "objectID": "posts/2025-til/index.html",
    "href": "posts/2025-til/index.html",
    "title": "Today I learned (TIL) · 2025",
    "section": "",
    "text": "Format Markdown with mdformat and uv.\nuvx mdformat markdown-file.md"
  },
  {
    "objectID": "posts/2025-til/index.html#april",
    "href": "posts/2025-til/index.html#april",
    "title": "Today I learned (TIL) · 2025",
    "section": "",
    "text": "Format Markdown with mdformat and uv.\nuvx mdformat markdown-file.md"
  },
  {
    "objectID": "posts/2025-til/index.html#january",
    "href": "posts/2025-til/index.html#january",
    "title": "Today I learned (TIL) · 2025",
    "section": "16. January",
    "text": "16. January\nRun a Python script with uv in a temporary virtual environment, specifying the Python version and script dependencies.\nuv run --python 3.11 --with cowsay python -c 'import cowsay;cowsay.cow(\"Hello Cow\")'"
  },
  {
    "objectID": "posts/2025-til/index.html#january-1",
    "href": "posts/2025-til/index.html#january-1",
    "title": "Today I learned (TIL) · 2025",
    "section": "03. January",
    "text": "03. January\nself-installing Python scripts with uv (2024)\n#!/usr/bin/env -S uv run --script"
  },
  {
    "objectID": "posts/2023-07-29-r-renv/index.html",
    "href": "posts/2023-07-29-r-renv/index.html",
    "title": "Package versions with renv",
    "section": "",
    "text": "renv::snapshot() creates an renv.lock file that includes the versions of all R packages used in R code in the current project folder.\nThis is something I have looked for for a long time. In Python, I like to use pip-compile to pin my dependencies to specified versions. For R, I have just not realized that renv can also do that without creating a full renv project.\nThe full renv workflow has seemed to me to be overhead. I prefer to create fully reproducible environments with Rocker."
  },
  {
    "objectID": "posts/2023-07-29-r-renv/index.html#versions-snapshot",
    "href": "posts/2023-07-29-r-renv/index.html#versions-snapshot",
    "title": "Package versions with renv",
    "section": "",
    "text": "renv::snapshot() creates an renv.lock file that includes the versions of all R packages used in R code in the current project folder.\nThis is something I have looked for for a long time. In Python, I like to use pip-compile to pin my dependencies to specified versions. For R, I have just not realized that renv can also do that without creating a full renv project.\nThe full renv workflow has seemed to me to be overhead. I prefer to create fully reproducible environments with Rocker."
  },
  {
    "objectID": "posts/2023-07-29-r-renv/index.html#find-project-packages",
    "href": "posts/2023-07-29-r-renv/index.html#find-project-packages",
    "title": "Package versions with renv",
    "section": "Find project packages",
    "text": "Find project packages\nrenv::dependencies() can be used to find all the packages used in a project.\n\nlibrary(renv)\n\ndependencies() |&gt; select(-Source)\n\nFinding R package dependencies ... Done!\n\n\n\n\n\n\nPackage\nRequire\nVersion\nDev\n\n\n\n\ndplyr\n\n\nFALSE\n\n\npurrr\n\n\nFALSE\n\n\nrenv\n\n\nFALSE\n\n\ncallr\n\n\nFALSE\n\n\nconflicted\n\n\nFALSE\n\n\ndplyr\n\n\nFALSE\n\n\nrmarkdown\n\n\nFALSE\n\n\nrmarkdown\n\n\nFALSE\n\n\ndplyr\n\n\nFALSE\n\n\npurrr\n\n\nFALSE\n\n\nrenv\n\n\nFALSE\n\n\ncallr\n\n\nFALSE\n\n\nconflicted\n\n\nFALSE\n\n\ndplyr\n\n\nFALSE\n\n\n\n\n\n\nPackage version number can be added with some tidyverse magic.\n\ndependencies() |&gt;\n  mutate(version = map_chr(Package, \\(.x) as.character(packageVersion(.x)))) |&gt;\n  select(Package, version) |&gt;\n  arrange(Package) |&gt;\n  distinct()\n\nFinding R package dependencies ... Done!\n\n\n\n\n\n\nPackage\nversion\n\n\n\n\ncallr\n3.7.6\n\n\nconflicted\n1.2.0\n\n\ndplyr\n1.1.4\n\n\npurrr\n1.1.0\n\n\nrenv\n1.1.4\n\n\nrmarkdown\n2.29"
  },
  {
    "objectID": "posts/2023-07-29-r-renv/index.html#customized-session-info",
    "href": "posts/2023-07-29-r-renv/index.html#customized-session-info",
    "title": "Package versions with renv",
    "section": "Customized session info",
    "text": "Customized session info\nThis led me to a condensed version of loading all project packages before calling sessionInfo()\n\nconflicted::conflicts_prefer(callr::run)\nmap_lgl(dplyr::pull(dependencies(), Package), require)\n\nFinding R package dependencies ... Done!\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\nsessionInfo()\n\nR version 4.5.1 (2025-06-13)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] rmarkdown_2.29   conflicted_1.2.0 callr_3.7.6      renv_1.1.4      \n[5] purrr_1.1.0      dplyr_1.1.4     \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.5       cli_3.6.5         knitr_1.50        rlang_1.1.6      \n [5] xfun_0.52         processx_3.8.6    generics_0.1.4    jsonlite_2.0.0   \n [9] glue_1.8.0        htmltools_0.5.8.1 ps_1.9.1          evaluate_1.0.4   \n[13] tibble_3.3.0      fastmap_1.2.0     yaml_2.3.10       lifecycle_1.0.4  \n[17] memoise_2.0.1     compiler_4.5.1    htmlwidgets_1.6.4 pkgconfig_2.0.3  \n[21] digest_0.6.37     R6_2.6.1          tidyselect_1.2.1  pillar_1.11.0    \n[25] magrittr_2.0.3    tools_4.5.1       withr_3.0.2       cachem_1.1.0"
  },
  {
    "objectID": "posts/2023-04-26-r-dataverse/index.html",
    "href": "posts/2023-04-26-r-dataverse/index.html",
    "title": "Dataverse URLs",
    "section": "",
    "text": "Dataverse URLs\nI followed a talk on electoral politics in Honduras. The presenter referred to the very stable two party system in Honduras. That made me interested to look at election results in Honduras. A quick analysis with Elections Global gave a good overview – see below.\nThe technical point is that I wanted to access the original data file at the Harvard Dataverse.\nData uploaded to the Dataverse is imported and a tab separated data version of the imported data is provided by the Dataverse. This is not the original file and may include some import errors. I ran into the issue in previous work so that I have worked with the original data file from the Dataverse. However, there is no direct link available at the Dataverse page of a data file.\nHere is an example for the Elections Global data used in the snippet – see page screenshot below.\ndoi:10.7910/DVN/OGOURC/YK9DOZ&version=2.0\nSo I tried to find the permanent link to the original data file.\nFirst, I checked the documentation of the Dataverse API but could not find a way to access an original data file through API parameters. Only the imported file is available through the API.\nSecond, I got the link by checking the request from clicking on the respective dynamic button at the Dataverse page with the browser developer tools. However, this url does not seem to have a structure that is related to the identifier of the dataset. Getting the url of the original data file this way is cumbersome.\nFor now, I will start to using the imported data version with the provided url for data files from the Dataverse.\n\n\nCode\nlibrary(conflicted)\nlibrary(tidyverse)\nconflicts_prefer(dplyr::filter)\n\n\n\nif (FALSE) {\n  url_csv &lt;- \"https://dataverse.harvard.edu/api/access/datafile/3754546?format=original\"\n  elec_raw &lt;- read_csv(url_csv)\n}\n\nurl &lt;- \"https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/OGOURC/YK9DOZ\"\n\nif (!exists(\"elec_raw\")) {\n  elec_raw &lt;- read_tsv(url)\n}\n\n# glimpse(elec_raw)\n\n\n\nCode\nhnd &lt;-\n  elec_raw |&gt;\n  filter(country == \"HND\") |&gt;\n  mutate(\n    year = as.integer(substr(election_date, 1, 4)),\n    seats_share = 100 * seats / seats_total\n  )\n\nhnd |&gt;\n  summarise(\n    n = n(),\n    share_mean = mean(seats_share, na.rm = TRUE) |&gt; round(1),\n    share_max = max(seats_share, na.rm = TRUE) |&gt; round(1),\n    year_first = min(year, na.rm = TRUE),\n    year_last = max(year, na.rm = TRUE),\n    .by = party\n  ) |&gt;\n  select(party, n, n:year_last) |&gt;\n  arrange(desc(n), desc(share_mean))\n\n\n\n\nCode\nhnd |&gt;\n  mutate(n = n(), .by = party) |&gt;\n  filter(n &gt; 10) |&gt;\n  ggplot(aes(year, seats_share, colour = party)) +\n  geom_line()"
  },
  {
    "objectID": "posts/2023-til/index.html",
    "href": "posts/2023-til/index.html",
    "title": "Today I learned (TIL) · 2023",
    "section": "",
    "text": "Keep the date of a git commit after changing the history with rebase\ngit rebase -i --committer-date-is-author-date &lt;SHA&gt;"
  },
  {
    "objectID": "posts/2023-til/index.html#november",
    "href": "posts/2023-til/index.html#november",
    "title": "Today I learned (TIL) · 2023",
    "section": "",
    "text": "Keep the date of a git commit after changing the history with rebase\ngit rebase -i --committer-date-is-author-date &lt;SHA&gt;"
  },
  {
    "objectID": "posts/2023-til/index.html#november-1",
    "href": "posts/2023-til/index.html#november-1",
    "title": "Today I learned (TIL) · 2023",
    "section": "21. November",
    "text": "21. November\nThere is a magic method in iPython to install packages with pip. It comes handy for a quick install in a notebook.\n%pip install -q requests\nSpecifying dependencies in requirements.in or pyproject.toml and pinning them with pip-tools is the better solution to create reproducible environments."
  },
  {
    "objectID": "posts/2023-til/index.html#july",
    "href": "posts/2023-til/index.html#july",
    "title": "Today I learned (TIL) · 2023",
    "section": "31. July",
    "text": "31. July\nSimple debugging with IPython — found at Real Python (now gated).\nimport IPython\n\nvar_1 = \"hello\"\n\nIPython.embed()\n\nvar_2 = \"world\""
  },
  {
    "objectID": "posts/2023-til/index.html#june",
    "href": "posts/2023-til/index.html#june",
    "title": "Today I learned (TIL) · 2023",
    "section": "30. June",
    "text": "30. June\nSet default printing function for data frames in Quarto notebook with html option df-print: kable.\nUseful to have html tables instead of monospace tables in notebooks.\nSo far, I prefer kable (knitr::kable()) over paged (rmarkdown::paged_table())).\n---\ntitle: \"Document\"\nformat:\n   html:\n     df-print: kable\n---"
  },
  {
    "objectID": "posts/2023-til/index.html#june-1",
    "href": "posts/2023-til/index.html#june-1",
    "title": "Today I learned (TIL) · 2023",
    "section": "29. June",
    "text": "29. June\nDidn’t know n_distinct() and used length(unique()) for too long. A small and nice thing i learned that makes pipes more readable."
  },
  {
    "objectID": "posts/2023-til/index.html#june-2",
    "href": "posts/2023-til/index.html#june-2",
    "title": "Today I learned (TIL) · 2023",
    "section": "13. June",
    "text": "13. June\nAdding a comment in Markdown by using standard html comments. It works for Markdown in pandoc used by Quarto.\n&lt;!--- comment  --&gt;\n\n&lt;!---\nmulti-line comments\n--&gt;\nI used it now with the current TIL page to have a short intro about a new TIL on the landing page. The previous one sentence summary of the page is now a comment."
  },
  {
    "objectID": "posts/2023-til/index.html#june-3",
    "href": "posts/2023-til/index.html#june-3",
    "title": "Today I learned (TIL) · 2023",
    "section": "10. June",
    "text": "10. June\nAdding a page break to a pdf in Quarto.\n---\nformat: pdf\n---\n\nPage 1\n\n{{&lt; pagebreak &gt;}}\n\nPage 2\nIn addition, I learned to ignore shortcuts in a cell with {.markdown shortcodes=\"false\"}"
  },
  {
    "objectID": "posts/2023-til/index.html#june-4",
    "href": "posts/2023-til/index.html#june-4",
    "title": "Today I learned (TIL) · 2023",
    "section": "09. June",
    "text": "09. June\nI wanted to run a Bash shell script from any folder. The initial solution worked on my local computer but not on GitHub Codespaces. Here is the solution I came up with. The script runs from any location or stops and gives a message that it should be run from the script folder.\n# Use path relative to script location, if feasible\nif [ -n \"$BASH_SOURCE\" ]; then\n    cd \"$( cd \"$(dirname \"${BASH_SOURCE[0]}\")\" ; pwd -P )\"\nelse\n    if ! [ -e \"package-lock.json\" ]; then\n        echo \"Run script in project folder\"\n        exit 1\n    fi\nfi"
  },
  {
    "objectID": "posts/2023-til/index.html#may",
    "href": "posts/2023-til/index.html#may",
    "title": "Today I learned (TIL) · 2023",
    "section": "17. May",
    "text": "17. May\nAnother use of the Base-R shorthand anonymous function and explaining it to a colleague. I like to use .x now for the local variable name to make the local context more explicit.\nadd_three &lt;- \\(.x) .x+3"
  },
  {
    "objectID": "posts/2023-til/index.html#may-1",
    "href": "posts/2023-til/index.html#may-1",
    "title": "Today I learned (TIL) · 2023",
    "section": "06. May",
    "text": "06. May\nExcluding variables in tidyselect is now done with ! as I found out by reading the documentation more carfully. I have still used - to exclude variables by their name. This is not documented in the tidyselect help page anymore.\nreadstata13 creates more R friendly data structures than haven. Its default option converts labeled data into factors if appropriate."
  },
  {
    "objectID": "posts/2023-til/index.html#may-2",
    "href": "posts/2023-til/index.html#may-2",
    "title": "Today I learned (TIL) · 2023",
    "section": "05. May",
    "text": "05. May\nUsed Quarto a lot and got more comfortable with the options — esp. caching, creating pdf, figures."
  },
  {
    "objectID": "posts/2023-til/index.html#may-3",
    "href": "posts/2023-til/index.html#may-3",
    "title": "Today I learned (TIL) · 2023",
    "section": "03. May",
    "text": "03. May\nConvert an RMarkdown file into an R file with knitr::purl(\"purl.Rmd\") – see details.\nChatGPT did not provide the solution. I remembered doing this years ago. An internet search quickly led to the information needed."
  },
  {
    "objectID": "posts/2023-til/index.html#may-4",
    "href": "posts/2023-til/index.html#may-4",
    "title": "Today I learned (TIL) · 2023",
    "section": "02. May",
    "text": "02. May\nA bug in the current version of RStudio kept me busy. I reinstalled R and RStudio on Windows, but RStudio did not find the new R version afterwards. So I reinstalled the two and it kept not working. Fortunately, I found information about the RStudio bug somewhat quickly. I installed the daily build and had R/RStudio running again.\nOriginally, I only wanted to do a quick data analysis but my previous R/RStudio updates came in between."
  },
  {
    "objectID": "posts/2023-til/index.html#apr.",
    "href": "posts/2023-til/index.html#apr.",
    "title": "Today I learned (TIL) · 2023",
    "section": "25. Apr.",
    "text": "25. Apr.\nI got back into Quarto and created a website for a learning project I have started. My goal is to have some structured information about topics of a book I am reading and some code snippets that apply concepts of the book.\nSetting up the page worked well. I got a little confused by the quarto difference between freeze and cache. I also wondered why the cache was added into several folders in the main directory and not into a _cache folder."
  },
  {
    "objectID": "posts/2023-til/index.html#apr.-1",
    "href": "posts/2023-til/index.html#apr.-1",
    "title": "Today I learned (TIL) · 2023",
    "section": "03. Apr.",
    "text": "03. Apr.\nI read about the new pandas release. None of the changes seem to be relevant for my work with pandas"
  },
  {
    "objectID": "posts/2023-til/index.html#feb.",
    "href": "posts/2023-til/index.html#feb.",
    "title": "Today I learned (TIL) · 2023",
    "section": "25. Feb.",
    "text": "25. Feb.\nI worked on code from a causal inference book. It includes Stata, R and Python versions of the examples.\nFor R and Python I wanted to have one environment to install all dependencies. This led me to conda.\nCreating a new conda environment in a new file was extremly slow. It also took me a while to fully configure Jupyter Lab with Python and R.\nAt the end, VS Code seems to be the more convenient interface."
  },
  {
    "objectID": "posts/2023-03-20-r-wasm/index.html",
    "href": "posts/2023-03-20-r-wasm/index.html",
    "title": "WebR (WebAssembly)",
    "section": "",
    "text": "WebR (WebAssembly)\nI read about the webR release on the Tidyverse blog. It allows to run R in a browser.\nSo I went to webr.r-wasm.org and gave it a try.\nI tried to install the tidyverse with webr::install(\"tidyverse\"). That did not work. For me, there is little use of R without the tidyverse.\nInstalling dplyr and ggplot2 individually worked. So that I could run the following code.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndt &lt;- as_tibble(mtcars)\nglimpse(dt)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\nggplot(dt, aes(x = hp, y = mpg, color = cyl)) +\n  geom_point()\n\n\n\n\n\n\n\n\nTyping the R commands in a browser shell without tab completion and no R help was challenging though.\nHaving R in a browser quickly available is nice 😊."
  },
  {
    "objectID": "posts/2023-04-27-py-geocoding/index.html",
    "href": "posts/2023-04-27-py-geocoding/index.html",
    "title": "Geocoding in Python",
    "section": "",
    "text": "Geocoding in Python\nGet geographic coordinates for an address with Nominatim from OpenStreetMap data.\n\nfrom geopy.geocoders import Nominatim\n\n# Create a geolocator object\ngeolocator = Nominatim(user_agent=\"get-the-geocode\")\n\n# Define the address for geocoding\naddress = \"Unter Sachsenhausen 6, Köln, Germany\"\n\n# Retrieve the geolocation (latitude and longitude) for the given address\nlocation = geolocator.geocode(address)\n\nprint((location.latitude, location.longitude))\n\n(50.9426743, 6.9523815)\n\n\n\nimport folium\n\ncoordinates = [location.latitude, location.longitude]\n\n# Create a map object\nm = folium.Map(location=coordinates, zoom_start=15)\n\n# Add a marker for each coordinate\nfolium.Marker(location=coordinates, popup=address).add_to(m)\n\nm  # Display the map in Jupyter Notebook\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "posts/2023-10-07-r-pak-packaging/index.html",
    "href": "posts/2023-10-07-r-pak-packaging/index.html",
    "title": "R packages with pak",
    "section": "",
    "text": "I started using pak install and manage R packages.\npak can be used to install all R packages used in a project.\nThe use case I am mainly interested in is installing and locking project packages to create reproducible environments. This can be accomplished with pak and renv. In a previous post, I discussed an approach with renv only.\nrenv is used to detect all packages used in a project and pac to create a (platform dependent) lockfile. This lockfile can be used to install the version pinned in the lock file later with pak without creating an renv environment.\nHere is an example — not run:\n# get packages used in project folder\ndeps &lt;- unique(renv::dependencies()[[\"Package\"]])\n\n# install project packages\npak::pkg_install(deps, ask = FALSE, upgrade = FALSE)\n# pak::lockfile_install()\n\n# create lock files\npak::lockfile_create(deps)\n# renv::snapshot(prompt = FALSE)\nrenv can be used to create a lock file as well. However, currently you have to use renv to install dependencies from an renv.lock file and need to create a new renv environment to reinstall the packages. There are plans to support installing packages from renv.lock with pak — see #343\nHere are the R packages renv finds locally.\n\nrenv::dependencies()[[\"Package\"]] |&gt;\n  unique() |&gt;\n  sort()\n\nFinding R package dependencies ... Done!\n\n\n[1] \"renv\"      \"rmarkdown\"\n\n\n\n\nPinning package versions in a lock file is an established workflow in Python with pip-tools.\nIn renv pinning package versions and creating local environments are too tightly coupled in my view. Often, I don’t want to create an environment for a project and need to document the used package versions only. In Docker or cloud platforms I don’t like to use local environments. In a local R install, working with the latest versions of R packages and freezing them is often sufficient for me.\nI hope pak will provide the R packaging solution I am looking for."
  },
  {
    "objectID": "posts/2023-10-07-r-pak-packaging/index.html#python-vs.-r-packaging-tools",
    "href": "posts/2023-10-07-r-pak-packaging/index.html#python-vs.-r-packaging-tools",
    "title": "R packages with pak",
    "section": "",
    "text": "Pinning package versions in a lock file is an established workflow in Python with pip-tools.\nIn renv pinning package versions and creating local environments are too tightly coupled in my view. Often, I don’t want to create an environment for a project and need to document the used package versions only. In Docker or cloud platforms I don’t like to use local environments. In a local R install, working with the latest versions of R packages and freezing them is often sufficient for me.\nI hope pak will provide the R packaging solution I am looking for."
  },
  {
    "objectID": "posts/2025-01-05-farbtafeln/index.html",
    "href": "posts/2025-01-05-farbtafeln/index.html",
    "title": "Color Chart page with AI",
    "section": "",
    "text": "Farbtafel (Color Chart) webpage — Gerhard Richter inspired · 🤖🎨\nOver the weekend, I ran into two books in our local bookstore.\nFor some time, I had the idea of creating a program to reproduce the Farbtafeln (Color Charts) by Gerhard Richter, a German painter. Richter’s Farbtafeln are a series of abstract paintings composed of grids filled with randomly arranged colored squares, showcasing his exploration of color and chance. This weekend, paired with the inspiration from these two books, provided a good opportunity to bring that idea to life and explore how AI could assist in such a creative programming project."
  },
  {
    "objectID": "posts/2025-01-05-farbtafeln/index.html#project-overview",
    "href": "posts/2025-01-05-farbtafeln/index.html#project-overview",
    "title": "Color Chart page with AI",
    "section": "Project Overview · 📋",
    "text": "Project Overview · 📋\nIn this project, I created a program replicating Gerhard Richter’s Farbtafeln. By leveraging AI-assisted programming, I developed a webpage that generates a random color grid inspired by Richter’s work. This project highlights the potential of AI assistants in creative coding.\nIt marks my first experience with AI assistants suggesting nearly all of the code, which I then reviewed and refined. My knowledge of JavaScript, Processing (p5.js), and CSS is rather limited and the AI assistants helped me implement the Farbtafeln efficiently.\nThe resulting webpage dynamically reshuffles the colors of the grid with each refresh, offering a fresh take on Richter’s exploration of randomness and color."
  },
  {
    "objectID": "posts/2025-01-05-farbtafeln/index.html#development",
    "href": "posts/2025-01-05-farbtafeln/index.html#development",
    "title": "Color Chart page with AI",
    "section": "Development · 🛠️",
    "text": "Development · 🛠️\nSo here is a summary of my steps to create the Farbtafeln code, documentation, and this blog post with AI assistants.\n\n1. Some Tech Background · 🧑‍💻\nI knew that p5.js would be a good fit for creating a Farbtafel webpage. p5.js is a JavaScript library that simplifies the creation of graphics and interactive content for the web.\nHowever, my knowledge of p5.js, JavaScript, and CSS is limited. Building the project from scratch with these tools would have been tedious for me. With the help of AI assistants, the process became not only manageable but also enjoyable.\n\n\n2. A p5.js Script in ChatGPT · 🤖\nTo create the page, I started by uploading an image of one of the original Farbtafeln to ChatGPT and asking it to generate a p5.js script to replicate the image. I then revised the script. Here are the steps I took in ChatGPT:\n\nDefined the role for ChatGPT and provided information about my programming background.\nUploaded a Farbtafel image to ChatGPT and asked it to create a p5.js script.\nGot explanations for parts of the script.\nModified the script to remove square borders and add padding.\nRefactored the script with ChatGPT’s instructions (created functions).\nCreated a webpage with the script.\n\nWhile interacting with ChatGPT, I ran and modified the script in the p5.js Web Editor in another browser tab.\nChatGPT was an invaluable assistant to generate an initial version of the page, generating code, offering clear explanations, and refining the Farbtafeln script based on my inputs. It streamlined development and enriched my learning experience, highlighting the benefits of AI in creative coding.\n\n\n3. Completing with Copilot · 💻\nAfter creating the initial script with ChatGPT, I turned to GitHub Copilot for further refinements and enhancements. Here are the steps I followed with Copilot:\n\nCreated a project in VS Code with GitHub Copilot enabled.\nRevised the script based on Copilot’s recommendations.\nAdded and refined CSS styles for the page.\nAdded and revised page and script comments.\n\nCopilot helped me create a simple yet visually appealing webpage. The additional revisions I made to the processing script were minimal. I really appreciated the workflow, with the script in my editor being modified based on Copilot’s suggestions. It was an interactive process I preferred over the ChatGPT chat-based interaction.\n\n\n4. Creating the README · 📄\nWith GitHub Copilot, I generated a README file for the project by following these steps:\n\nCreated a new, empty README.md file in the project directory.\nUsed Copilot to generate an initial draft.\nReviewed and refined the content manually.\nAdded links to relevant resources.\n\nThe structure of the suggested README was helpful, and the content provided some good initial ideas. However, it was overly general and somewhat bloated, so I significantly revised the document manually.\n\n\n5. Writing the Blog Post · 📝\nFinally, I asked GitHub Copilot to generate this blog post based on the page code and the README. Here are the steps I used:\n\nCreated an empty Markdown file.\nAsked Copilot to generate the blog post.\nReviewed and revised each paragraph with Copilot.\nAdded sentences and paragraphs manually.\nRevised and finalized the draft with ChatGPT.\n\nThe generated post served as a solid foundation, but I refined it significantly to better reflect my experience. ChatGPT was particularly helpful for fine-tuning the content and improving its flow, while Copilot provided a reasonable starting point for structuring the post."
  },
  {
    "objectID": "posts/2025-01-05-farbtafeln/index.html#final-thoughts",
    "href": "posts/2025-01-05-farbtafeln/index.html#final-thoughts",
    "title": "Color Chart page with AI",
    "section": "Final Thoughts · 💭",
    "text": "Final Thoughts · 💭\nThis project was a great example of how AI, ChatGPT and Copilot, can assist in the development process. By generating code and providing suggestions, AI assistants helped streamline the creation of this random color grid. The result is a simple and visually appealing webpage that pays homage to Gerhard Richter’s iconic color charts.\nThe code was generated quickly with ChatGPT, and I was impressed by the quality. However, creating the documentation and blog post took more time. While AI drafted the README and blog post, it was less instrumental, and I spent significantly more time refining them manually.\nOverall, I thoroughly enjoyed this project, and I’m very pleased with how the Farbtafeln-inspired webpage turned out. It brings Richter’s exploration of color and chance nicely into a digital space."
  },
  {
    "objectID": "posts/2025-01-05-farbtafeln/index.html#links",
    "href": "posts/2025-01-05-farbtafeln/index.html#links",
    "title": "Color Chart page with AI",
    "section": "Links · 🔗",
    "text": "Links · 🔗\n\nGerhard Richter’s Color Charts\np5.js Library\np5.js Editor"
  },
  {
    "objectID": "posts/2024-09-22-r-patchwork/index.html",
    "href": "posts/2024-09-22-r-patchwork/index.html",
    "title": "Arrange plots with tables",
    "section": "",
    "text": "I use patchwork regularly to combine ggplots; see my R template.\nThe recent v1.3 release of patchwork allows adding gt tables.\nTables with short descriptive information are an essential element of my notebooks. So far, I have mainly relied on the default knitr for simple tables and used reactable for larger interactive tables.\nSo here is an example of patchwork that combines a figure and a gt table, using the palmerpenguins data.\n\n\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(gt)\n\nlibrary(palmerpenguins)\n\npg &lt;-\n  penguins %&gt;%\n  group_by(species) |&gt;\n  summarise(\n    n = n(),\n    bill = mean(bill_length_mm, na.rm = TRUE),\n    flipper = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\npl1 &lt;-\n  ggplot(penguins, aes(x = flipper_length_mm, y = bill_length_mm, color = factor(species))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme(legend.position = \"none\")\n\ngt1 &lt;-\n  gt(pg) |&gt;\n  tab_header(title = \"Length mean (mm)\") |&gt;\n  fmt_number(\n    columns = c(bill, flipper),\n    decimals = 1\n  )\n\npl1 + gt1"
  },
  {
    "objectID": "posts/2023-02-26-py-altair/index.html",
    "href": "posts/2023-02-26-py-altair/index.html",
    "title": "Python visualization with Altair",
    "section": "",
    "text": "Python visualization with Altair\nI have been interested in finding a visualization library for Python that is similiar to ggplot2 in R. I like the quick plots in pandas but Matplotlib has never worked for me.\nFor customized visualizations I like the ggplot2 approach with layers. Its grammar of graphics provides a good balance between adjusting a visualization and productivity. The code with layers is nicely readable.\nVega-Altair, a Python library, uses a grammar to create visualization as well. So I gave it a try and it went well – see code below.\npandas and Altaire are likely to be the visualization tools that I use primarily in Python.\nHere is some information on the penguins dataset 🐧 in the visualization. I didn’t want to use mtcars 🚗 again.\n\nimport altair as alt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndt = sns.load_dataset(\"penguins\")\n\n(alt.Chart(dt)\n    .mark_circle()\n    .encode(\n      alt.X('flipper_length_mm', scale=alt.Scale(zero=False)),\n      alt.Y('body_mass_g', scale=alt.Scale(zero=False)),\n      color='species',\n      tooltip=['species', 'island', 'sex']\n    )\n)\n\n\n\n\n\n\n\n\ndt\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nGentoo\nBiscoe\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nBiscoe\n46.8\n14.3\n215.0\n4850.0\nFemale\n\n\n341\nGentoo\nBiscoe\n50.4\n15.7\n222.0\n5750.0\nMale\n\n\n342\nGentoo\nBiscoe\n45.2\n14.8\n212.0\n5200.0\nFemale\n\n\n343\nGentoo\nBiscoe\n49.9\n16.1\n213.0\n5400.0\nMale\n\n\n\n\n344 rows × 7 columns"
  },
  {
    "objectID": "posts/2023-02-26-quarto-experience/index.html",
    "href": "posts/2023-02-26-quarto-experience/index.html",
    "title": "A few days of Quarto",
    "section": "",
    "text": "So I have had my first experience with creating dynamic documents in Quarto. It has been a pleasant experience. I could use some of my RMarkdown und knitr skills and like that it is a program independent of R and RStudio. Working in VS Code to create a blog on Things I Learned worked well.\nOnly working with Python was really challenging. For some time several attempts to find the local Python version in the env folder did not work. quarto check found the respective Python version but it was not used when I rendered the document. At the end it was simply the header option jupyter: python3 in the qmd-document that did the trick.\nRendering a document with Python and R cells remained a challenge. Again, it was an option that was missing. Setting #| python.reticulate: false in a Python cell solved the issue.\nMany of my Python struggles in Quarto may have been related to the reticulate R package."
  },
  {
    "objectID": "posts/2023-02-26-quarto-experience/index.html#quarto",
    "href": "posts/2023-02-26-quarto-experience/index.html#quarto",
    "title": "A few days of Quarto",
    "section": "",
    "text": "So I have had my first experience with creating dynamic documents in Quarto. It has been a pleasant experience. I could use some of my RMarkdown und knitr skills and like that it is a program independent of R and RStudio. Working in VS Code to create a blog on Things I Learned worked well.\nOnly working with Python was really challenging. For some time several attempts to find the local Python version in the env folder did not work. quarto check found the respective Python version but it was not used when I rendered the document. At the end it was simply the header option jupyter: python3 in the qmd-document that did the trick.\nRendering a document with Python and R cells remained a challenge. Again, it was an option that was missing. Setting #| python.reticulate: false in a Python cell solved the issue.\nMany of my Python struggles in Quarto may have been related to the reticulate R package."
  },
  {
    "objectID": "posts/2023-02-26-quarto-experience/index.html#docker",
    "href": "posts/2023-02-26-quarto-experience/index.html#docker",
    "title": "A few days of Quarto",
    "section": "Docker",
    "text": "Docker\nTo get there I also created a Dockerfile to have an OS independent version of Quarto. That was another challenge until I first found a Rocker configuration that worked with Python. It is a whopping 4.5 GB image but incudes Latex to create pdf-files.\nLater I did some more experimenting with Docker and created a Jupyter Lab Docker image that is also quite large with almost 5 GB. In addition, I created a smaller image that includes only a minimal Python and Jupyter Lab. At least this one is a little smaller than 1 GB.\nI’ll try to work with the local Quarto versions mainly but it is good to have OS independent Docker versions as well."
  },
  {
    "objectID": "posts/2023-02-26-quarto-experience/index.html#python-in-quarto",
    "href": "posts/2023-02-26-quarto-experience/index.html#python-in-quarto",
    "title": "A few days of Quarto",
    "section": "Python in Quarto",
    "text": "Python in Quarto\nHere is a Quarto Guide demonstration of a line plot on a polar axis, see Figure 1.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'}\n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "posts/2023-11-04-py-pyproject-toml/index.html",
    "href": "posts/2023-11-04-py-pyproject-toml/index.html",
    "title": "pyproject.toml metadata and dependencies",
    "section": "",
    "text": "pyproject.toml metadata and dependencies\nPython allows to specify metadata and dependencies in a pyproject.toml.\nI have started using the metadata declaration recently and tried the dependency specification this week.\nI added an example to the folder of the post. It contains project metadata and examples for project and development dependencies.\n\n\nCode\ndef print_file(file_name):\n  with open(file_name, \"r\") as file:\n      print(file.read())\n\nprint_file(\"pyproject.toml\")\n\n\n[project]\nname = \"hd-example\"\nversion = \"0.1\"\ndescription = \"An example for pyproject\"\nmaintainers = [{ name = \"Holger Döring\" }]\nlicense = { text = \"MIT License\" }\nrequires-python = \"&gt;=3.11\"\ndependencies = [\n  \"requests\",\n]\n\n[project.optional-dependencies]\ndev = [\n  \"pip-tools\",\n  \"ruff\",\n]\n\n[project.urls]\n homepage = \"\"\nrepository = \"https://github.com/hdigital/starter-python.git\"\n\n\n# specify build system to run pip-tools\n# (application is not a package and no build is needed)\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n\n\nThere is a toml parser in the standard library since Python 3.11, released in October last year. It can be used to read the pyproject.toml.\n\nimport tomli as tomllib  # Python &lt;= 3.10\n\nwith open(\"pyproject.toml\", \"rb\") as toml_file:\n    toml_data = tomllib.load(toml_file)\n\ntoml_data\n\n{'project': {'name': 'hd-example',\n  'version': '0.1',\n  'description': 'An example for pyproject',\n  'maintainers': [{'name': 'Holger Döring'}],\n  'license': {'text': 'MIT License'},\n  'requires-python': '&gt;=3.11',\n  'dependencies': ['requests'],\n  'optional-dependencies': {'dev': ['pip-tools', 'ruff']},\n  'urls': {'homepage': '',\n   'repository': 'https://github.com/hdigital/starter-python.git'}},\n 'build-system': {'requires': ['hatchling'],\n  'build-backend': 'hatchling.build'}}\n\n\nI like to pin dependencies in one requirements.txt. Such a file can be created with pip-tools.\npython -m piptools compile --upgrade --extra dev pyproject.toml\nUsually, I include the --generate-hashes option but leave it out here to shorten the output by not including hash keys.\n\n\nCode\nprint_file(\"requirements.txt\")\n\n\n#\n# This file is autogenerated by pip-compile with Python 3.11\n# by the following command:\n#\n#    pip-compile --extra=dev pyproject.toml\n#\nbuild==1.0.3\n    # via pip-tools\ncertifi==2023.7.22\n    # via requests\ncharset-normalizer==3.3.2\n    # via requests\nclick==8.1.7\n    # via pip-tools\nidna==3.4\n    # via requests\npackaging==23.2\n    # via build\npip-tools==7.3.0\n    # via hd-example (pyproject.toml)\npyproject-hooks==1.0.0\n    # via build\nrequests==2.31.0\n    # via hd-example (pyproject.toml)\nruff==0.1.4\n    # via hd-example (pyproject.toml)\nurllib3==2.0.7\n    # via requests\nwheel==0.41.3\n    # via pip-tools\n\n# The following packages are considered to be unsafe in a requirements file:\n# pip\n# setuptools"
  },
  {
    "objectID": "posts/2024-07-16-r-bar-chart/index.html",
    "href": "posts/2024-07-16-r-bar-chart/index.html",
    "title": "Bar charts with ggplot",
    "section": "",
    "text": "Bar charts with ggplot\nHorizontal bar charts are a regular part of my work with graphs in R. Nevertheless, I have to look up the details regularly, so here is another example.\nThe graph visualizes the disproportionality of the results in the recent UK election 2024.\nIt uses forcats to order categories, here the parties, by another value in the dataset, here the vote share.\nThe color codes of the parties are based on the BBC election page. I just used inspect on the internet browser to find the respective color code used on the page.\nFinding the details for the parameters to customize the legend and the axes in ggplot took some time. GitHub Copilot, my new AI pair programmer, was very helpful. In fact, I use it a lot now to get examples for the use of various tidyverse functions, that I used to look up regularly.\n\n\nCode\nlibrary(tidyverse)\nlibrary(patchwork)\n\nggplot2::theme_set(theme_minimal())\n\n\nelec_raw &lt;- read_csv(\"uk-election-2024_bbc.csv\")\n\npl_dt &lt;-\n  elec_raw |&gt;\n  mutate(\n    seat_share = round(seats / 650 * 100, 1), # total seats UK Parliament: 650\n    party = fct_reorder(party, vote_share)\n  ) |&gt;\n  filter(vote_share &gt;= 2.5)\n\nparty_colors &lt;-\n  c(\n    \"Lab\" = \"#E91D0E\",\n    \"Con\" = \"#0575C9\",\n    \"R-UK\" = \"#12b6cf\",\n    \"Lib\" = \"#FF9A02\",\n    \"Green\" = \"#99CC33\",\n    \"SNP\" = \"#0AD1E0\"\n  )\n\npl1 &lt;-\n  ggplot(pl_dt, aes(x = vote_share, y = party, fill = party)) +\n  geom_col() +\n  xlim(0, 60) +\n  scale_fill_manual(values = party_colors) +\n  labs(y = NULL) +\n  theme(legend.position = \"none\")\n\npl2 &lt;-\n  ggplot(pl_dt, aes(x = seat_share, y = party, fill = party)) +\n  geom_col() +\n  scale_fill_manual(values = party_colors) +\n  labs(y = NULL) +\n  theme(axis.text.y = element_blank(), legend.position = \"none\")\n\npl1 + pl2 +\n  plot_annotation(\n    title = \"UK election 2024\",\n    caption = \"Source: BBC\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhoto by Kristina Gadeikyte on Unsplash"
  },
  {
    "objectID": "posts/2023-08-21-quarto-docker/index.html",
    "href": "posts/2023-08-21-quarto-docker/index.html",
    "title": "Quarto version in Docker",
    "section": "",
    "text": "Quarto version in Docker\nI realized that installing the latest version of Quarto in Docker will not lead to a reproducible environment since the latest Docker version depends on the day an image is build. So I was looking for a Dockerfile configuration to install a specified version of Quarto in Docker.\nQuarto keeps a list of releases so that I had to figure out what the download url is. This was easy. The version number is used in the Quarto section of a Docker file three times so that I also wanted to find a way to specify that version in variable. This was a little more tricky.\nFor the final solution I needed several attempts but learned someting about defining arguments in a Dockerfile.\nHere is the solution I came up with.\nARG QUARTO_VERSION=1.3.450\nRUN apt-get -y update && apt-get install -y --no-install-recommends curl gdebi-core\nRUN curl -LO https://github.com/quarto-dev/quarto-cli/releases/download/v${QUARTO_VERSION}/quarto-${QUARTO_VERSION}-linux-amd64.deb\nRUN gdebi --non-interactive quarto-${QUARTO_VERSION}-linux-amd64.deb\nRUN install2.r markdown reticulate\n# RUN quarto install tinytex\nThis is the version for the latest release I have used so far.\nRUN apt-get -y update && apt-get install -y --no-install-recommends curl gdebi-core\nRUN curl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb\nRUN gdebi --non-interactive quarto-linux-amd64.deb\nRUN install2.r markdown reticulate\n# RUN quarto install tinytex"
  },
  {
    "objectID": "posts/2023-06-24-r-str-glue/index.html",
    "href": "posts/2023-06-24-r-str-glue/index.html",
    "title": "string interpolation with str_glue()",
    "section": "",
    "text": "string interpolation with str_glue()\nIn R, I like string interpolation with glue and prefer it over Base-R paste(), paste0(), sprintf(). Regularly, I use glue() and forget to load the respective library at the top of the script or find glue::glue() rather verbose.\nA tidyverse blog post made me realize that stringr includes a str_glue() function that wraps glue(). stringr is loaded with library(tidyverse) so that I can include it into my regular tidyverse workflow.\nIt is also documented on the stringr cheatsheet, but I have not relized that. It serves as useful reminder to look at the Posit Cheatsheets more regularly to review and update my workflow.\n\nlibrary(tidyverse)\n\nname &lt;- \"Jane\"\n\nstr_glue(\"Hi {name}. How are you?\")\n\nHi Jane. How are you?"
  },
  {
    "objectID": "posts/2024-04-30-py-pip-cell/index.html",
    "href": "posts/2024-04-30-py-pip-cell/index.html",
    "title": "pip install in cell",
    "section": "",
    "text": "Sometimes, I want to install pip packages in a Jupyter notebook without specifying the packages and pinning them in a requirements.txt.\nThis is mainly for short notebooks that I want to share and that should run without any modifications.\nI have now found a solution with two IPython magic commands.\n%%capture suppresses cell output so that no information about the pip install or the already installed packages is added to the notebook.\n%pip install installs the specified packages.\n\n%%capture\n\n%pip install goose3\n\n\nfrom goose3 import Goose\n\nurl = \"https://www.bbc.com/news/world-europe-68929873\"\n\ng = Goose()\narticle = g.extract(url=url)\n\narticle.meta_description\n\n'Nicaragua accused Germany of breaching the UN genocide convention by sending military hardware to Israel.'\n\n\n\n\n\nJupyter"
  },
  {
    "objectID": "snippets/r-cell-conditional.html",
    "href": "snippets/r-cell-conditional.html",
    "title": "Conditional R code cell execution",
    "section": "",
    "text": "https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/cars.html"
  },
  {
    "objectID": "snippets/r-cell-conditional.html#explore-data",
    "href": "snippets/r-cell-conditional.html#explore-data",
    "title": "Conditional R code cell execution",
    "section": "Explore data",
    "text": "Explore data"
  },
  {
    "objectID": "snippets/jupyter.html",
    "href": "snippets/jupyter.html",
    "title": "Learning",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nOriginal Jupyter notebook rendered with Quarto\nsee post\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"polar\"})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "snippets/ipython-display.html",
    "href": "snippets/ipython-display.html",
    "title": "iPython display examples",
    "section": "",
    "text": "Some JupyterLite inspired examples (see python.ipynb) of using iPython display.\nfrom IPython.display import HTML, JSON, Markdown, Math, display"
  },
  {
    "objectID": "snippets/ipython-display.html#single-elements",
    "href": "snippets/ipython-display.html#single-elements",
    "title": "iPython display examples",
    "section": "Single elements",
    "text": "Single elements\nIndividual elements can be rendered without display()\n\nHTML(\"&lt;h3&gt;HTML Title&lt;/h3&gt;\")\n\nHTML Title\n\n\n\nMarkdown(\"### Markdown title\")\n\nMarkdown title\n\n\n\nMath(\"a^2 + b^2 = c^2\")\n\n\\(\\displaystyle a^2 + b^2 = c^2\\)\n\n\n\nJSON([\"foo\", {\"bar\": (\"baz\", None, 1.0, 2)}], expanded=True)\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "snippets/ipython-display.html#multiple-elements",
    "href": "snippets/ipython-display.html#multiple-elements",
    "title": "iPython display examples",
    "section": "Multiple elements",
    "text": "Multiple elements\nUse display to show multipe elements from a single cell.\n\ndisplay(HTML(\"&lt;em&gt;HTML element&lt;/em&gt;\"))\ndisplay(Markdown(\"__Markdown title__\"))\ndisplay(Math(\"a^2 + b^2 = c^2\"))\n\nHTML element\n\n\nMarkdown title\n\n\n\\(\\displaystyle a^2 + b^2 = c^2\\)\n\n\n\nprint(\"'first element'\")\ndisplay(\"second element\")\nprint(\"'third element'\")\n\n'first element'\n\n\n'second element'\n\n\n'third element'\n\n\n\nThis does not work without display()\n\nHTML(\"first HTML element &lt;em&gt;not shown&lt;/em&gt;\")\nMarkdown(\"only last Markdown element _shown_\")\n\nonly last Markdown element shown"
  },
  {
    "objectID": "snippets/ipython-display.html#html",
    "href": "snippets/ipython-display.html#html",
    "title": "iPython display examples",
    "section": "HTML",
    "text": "HTML\n\nprint(\"Before display\")\n\ns = \"&lt;h3&gt;HTML Title&lt;/h3&gt;\"\ndisplay(HTML(s))\n\nprint(\"After display\")\n\nBefore display\n\n\nHTML Title\n\n\nAfter display\n\n\n\nHTML(\n    \"\"\"\n        &lt;div style=\"background: aliceblue; width: 200px; height: 100px; border-radius: 10px;\"&gt;\n        &lt;/div&gt;\n    \"\"\"  # noqa: E501\n)"
  },
  {
    "objectID": "snippets/ipython-display.html#markdown",
    "href": "snippets/ipython-display.html#markdown",
    "title": "iPython display examples",
    "section": "Markdown",
    "text": "Markdown\n\nMarkdown(\n    \"\"\"\n### Title\n\n**in bold**\n\n~~Strikethrough~~\n\"\"\"\n)\n\nTitle\nin bold\nStrikethrough"
  },
  {
    "objectID": "snippets/ipython-display.html#pandas-dataframe",
    "href": "snippets/ipython-display.html#pandas-dataframe",
    "title": "iPython display examples",
    "section": "Pandas DataFrame",
    "text": "Pandas DataFrame\n\nfrom string import ascii_uppercase as letters\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\ndf = pd.DataFrame(\n    np.random.randint(0, 100, size=(100, len(letters))), columns=list(letters)\n)\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n...\nQ\nR\nS\nT\nU\nV\nW\nX\nY\nZ\n\n\n\n\n0\n43\n27\n22\n30\n11\n64\n63\n50\n90\n53\n...\n2\n38\n30\n53\n50\n93\n43\n44\n20\n28\n\n\n1\n79\n21\n73\n33\n14\n84\n79\n21\n77\n37\n...\n93\n61\n32\n23\n38\n17\n10\n2\n89\n23\n\n\n2\n60\n89\n4\n35\n13\n53\n64\n12\n13\n66\n...\n25\n6\n53\n6\n60\n19\n98\n65\n73\n89\n\n\n3\n41\n64\n96\n28\n25\n8\n26\n65\n32\n30\n...\n4\n27\n53\n53\n11\n95\n10\n97\n88\n19\n\n\n4\n15\n93\n72\n37\n17\n94\n16\n22\n34\n77\n...\n22\n45\n22\n0\n35\n47\n15\n26\n53\n38\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\n96\n84\n86\n54\n51\n75\n39\n31\n78\n66\n...\n92\n97\n72\n58\n82\n51\n22\n51\n55\n13\n\n\n96\n56\n54\n86\n21\n86\n16\n65\n56\n96\n62\n...\n19\n8\n29\n58\n11\n28\n58\n55\n81\n0\n\n\n97\n62\n7\n94\n1\n1\n73\n83\n82\n42\n63\n...\n54\n59\n14\n92\n42\n54\n71\n33\n15\n7\n\n\n98\n86\n88\n62\n58\n60\n83\n79\n26\n32\n68\n...\n44\n49\n8\n8\n80\n26\n34\n59\n86\n14\n\n\n99\n91\n65\n43\n30\n51\n40\n97\n81\n35\n76\n...\n37\n2\n15\n24\n76\n99\n42\n84\n87\n5\n\n\n\n\n100 rows × 26 columns"
  },
  {
    "objectID": "snippets/ipython-display.html#math",
    "href": "snippets/ipython-display.html#math",
    "title": "iPython display examples",
    "section": "Math",
    "text": "Math\n\nfrom IPython.display import Math\n\nMath(r\"F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx\")\n\n\\(\\displaystyle F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx\\)"
  },
  {
    "objectID": "snippets/ipython-display.html#latex",
    "href": "snippets/ipython-display.html#latex",
    "title": "iPython display examples",
    "section": "Latex",
    "text": "Latex\n\nLatex(\n    r\"\"\"\n      \\begin{eqnarray}\n        \\nabla \\times \\vec{\\mathbf{B}} -\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{E}}}{\\partial t} & = \\frac{4\\pi}{c}\\vec{\\mathbf{j}} \\\\\n        \\nabla \\cdot \\vec{\\mathbf{E}} & = 4 \\pi \\rho \\\\\n        \\nabla \\times \\vec{\\mathbf{E}}\\, +\\, \\frac1c\\, \\frac{\\partial\\vec{\\mathbf{B}}}{\\partial t} & = \\vec{\\mathbf{0}} \\\\\n        \\nabla \\cdot \\vec{\\mathbf{B}} & = 0\n      \\end{eqnarray}\n      \"\"\"  # noqa: E501\n)\n\n&lt;IPython.core.display.Latex object&gt;"
  },
  {
    "objectID": "snippets/ipython-display.html#json",
    "href": "snippets/ipython-display.html#json",
    "title": "iPython display examples",
    "section": "JSON",
    "text": "JSON\n\nJSON([\"foo\", {\"bar\": (\"baz\", None, 1.0, 2)}], metadata={}, expanded=True, root=\"test\")\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "snippets/ipython-display.html#network-requests-and-json",
    "href": "snippets/ipython-display.html#network-requests-and-json",
    "title": "iPython display examples",
    "section": "Network requests and JSON",
    "text": "Network requests and JSON\nHere, I use requests instead of the JupyterLite version with js.\n\n%pip install -q requests\n\n/Users/hd/hd/learning/learning-diary/.venv/bin/python: No module named pip\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport requests\n\nr = requests.get(\"https://httpbin.org/get\")\nr.text\n\n'{\\n  \"args\": {}, \\n  \"headers\": {\\n    \"Accept\": \"*/*\", \\n    \"Accept-Encoding\": \"gzip, deflate\", \\n    \"Host\": \"httpbin.org\", \\n    \"User-Agent\": \"python-requests/2.31.0\", \\n    \"X-Amzn-Trace-Id\": \"Root=1-65fab6bc-1087d67f265788bf1f4c3a6d\"\\n  }, \\n  \"origin\": \"79.212.250.177\", \\n  \"url\": \"https://httpbin.org/get\"\\n}\\n'\n\n\n\nJSON(r.json())\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "snippets/jupyter-quarto.html",
    "href": "snippets/jupyter-quarto.html",
    "title": "Learning",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nQuarto document converted from Jupyter notebook with quarto convert\nsee post\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "snippets/jupyter-options.html",
    "href": "snippets/jupyter-options.html",
    "title": "Jupyter Quarto",
    "section": "",
    "text": "Jupyter notebook rendering with Quarto\n\nJupyter notebook with Quarto options in first cell\nsee post\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"polar\"})\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()"
  },
  {
    "objectID": "posts/2024-02-26-py-f-strings/index.html",
    "href": "posts/2024-02-26-py-f-strings/index.html",
    "title": "Python f-strings",
    "section": "",
    "text": "Python f-strings\nHere are some examples of f-strings in Python inspired by a post and a cheat sheet.\n\na = 2\nb = 3\n\n\nf\"{a} + {b}\"\n\n'2 + 3'\n\n\n\nf\"{a=} and {b=}\"\n\n'a=2 and b=3'\n\n\n\nf\"a + b = {a+b}\"\n\n'a + b = 5'\n\n\nCurly brackets in an f-string\n\nn = 123\n\nf'{{}}-{n}-{{{n}}}'\n\n'{}-123-{123}'\n\n\n\nNumber formatting\n\nvar = 1234567890.1234\n\nf'{var:,}'\n\n'1,234,567,890.1234'\n\n\n\nf'round: {var:.2f}'\n\n'round: 1234567890.12'\n\n\n\nf'comma: {var:,}'\n\n'comma: 1,234,567,890.1234'\n\n\n\nf'comma: {var:,.2f}'\n\n'comma: 1,234,567,890.12'\n\n\n\nimport datetime\n\ndt = datetime.datetime(2026, 2, 21, 19, 45, 30)\n\nf'{dt}'\n\n'2026-02-21 19:45:30'\n\n\n\nf'{dt:%Y-%m-%d}'\n\n'2026-02-21'\n\n\n\nf'{dt.isoformat()}'\n\n'2026-02-21T19:45:30'"
  },
  {
    "objectID": "posts/2023-06-04-github-codespaces/index.html",
    "href": "posts/2023-06-04-github-codespaces/index.html",
    "title": "GitHub Codespaces",
    "section": "",
    "text": "GitHub Codespaces\nGitHub offered me to review the code of a pull request in GitHub Codespaces. It is an environment to run code online. I used it briefly before but not for one of my GitHub repositories. Today, I gave it a try for the pull request of a repository.\nFor the pull request, it created an environment with VS Code as the IDE and included Python as well as Git. I used it for a small Django project of mine. Two things were required to run my code. First, I needed to install the Python packages used by the project. The project includes a requirements file with pinned versions so that installing the dependencies was easy. Second, it asked me to add some VS Code extensions which I did as well.\nCompleting these two steps allowed me to work in an online enviroment very similiar to my local VS Code set up. It was linked to the GitHub repository so that I could sync my cloud changes with the project. I was impressed how smoothly it went and how little configuration it required.\nI made some minor modifications to the project to use Codespaces even more effortlessly in the future. First, I updated my settings.json.example so that I can quickly create a copy in a Codesspaces settings.json that includes my settings. Second, I specified the VS Code extensions I am regularly using in a launch.json. These two additions should allow me to work in new Codespaces in the future even more quickly.\nOverall, I really liked my first more in depth usage of Codespaces and plan to use it more in the future. I have yet to figure out how much I can use it with free quota and what monthly costs may occur by using it more regularly."
  },
  {
    "objectID": "posts/2023-06-30-r-dplyr-programming/index.html",
    "href": "posts/2023-06-30-r-dplyr-programming/index.html",
    "title": "dplyr programming",
    "section": "",
    "text": "I wanted to use some dynamic variable names in dplyr and had to look up dplyr programming again.\nThis is something I have to look up regularly and where I am still not comfortable with the terminology. Here, I find the respective tidyverse documentation rather challenging. However, dplyr programming is also something that I use rarely.\nSo here is a brief summary of my recent exploration of the topic.\nlibrary(tidyverse)\n\ncars &lt;- as_tibble(datasets::mtcars)\nvar_select &lt;- \"cyl\""
  },
  {
    "objectID": "posts/2023-06-30-r-dplyr-programming/index.html#pronoun-.data",
    "href": "posts/2023-06-30-r-dplyr-programming/index.html#pronoun-.data",
    "title": "dplyr programming",
    "section": "Pronoun .data",
    "text": "Pronoun .data\nUse the .data pronoun to access a variable name in a character object in a dplyr workflow.\n\ncars |&gt; count(.data[[var_select]])\n\n\n\n\n\ncyl\nn\n\n\n\n\n4\n11\n\n\n6\n7\n\n\n8\n14\n\n\n\n\n\ncars |&gt; count(.data[[\"cyl\"]])\n\n\n\n\n\ncyl\nn\n\n\n\n\n4\n11\n\n\n6\n7\n\n\n8\n14"
  },
  {
    "objectID": "posts/2023-06-30-r-dplyr-programming/index.html#embrace-argument",
    "href": "posts/2023-06-30-r-dplyr-programming/index.html#embrace-argument",
    "title": "dplyr programming",
    "section": "Embrace argument",
    "text": "Embrace argument\nA variable used as a function argument can be embraced with double braces to use it in a dplyr workflow.\n\ncount_var &lt;- function(.dt, .var) {\n  summarise(.dt, n = n(), .by = all_of({{ .var }}))\n}\n\ncount_var(cars, var_select)\n\n\n\n\n\ncyl\nn\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var(cars, c(var_select, \"vs\"))\n\n\n\n\n\ncyl\nvs\nn\n\n\n\n\n6\n0\n3\n\n\n4\n1\n10\n\n\n6\n1\n4\n\n\n8\n0\n14\n\n\n4\n0\n1"
  },
  {
    "objectID": "posts/2023-06-30-r-dplyr-programming/index.html#name-injection",
    "href": "posts/2023-06-30-r-dplyr-programming/index.html#name-injection",
    "title": "dplyr programming",
    "section": "Name injection",
    "text": "Name injection\nName injection can be used to assign new variable names in a dplyr workflow.\n:= is used as the assignment operator with dynamic new variable names.\n\ncars |&gt;\n  summarise(\"{var_select}_count\" := n(),\n    .by = all_of({{ var_select }})\n  )\n\n\n\n\n\ncyl\ncyl_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var2 &lt;- function(dt, var) {\n  summarise(dt, \"{var}_count\" := n(),\n    .by = all_of({{ var }})\n  )\n}\n\ncount_var2(cars, \"cyl\")\n\n\n\n\n\ncyl\ncyl_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\ncount_var3 &lt;- function(dt, var) {\n  summarise(dt, \"{{var}}_count\" := n(),\n    .by = all_of({{ var }})\n  )\n}\n\ncount_var3(cars, var_select)\n\n\n\n\n\ncyl\nvar_select_count\n\n\n\n\n6\n7\n\n\n4\n11\n\n\n8\n14\n\n\n\n\n\nsummarise_dt &lt;- function(data, var) {\n  data |&gt;\n    summarise(\n      \"mean_{{var}}\" := mean({{ var }}),\n      \"sum_{{var}}\" := sum({{ var }}),\n      \"n_{{var}}\" := n()\n    )\n}\n\nsummarise_dt(cars, cyl)\n\n\n\n\n\nmean_cyl\nsum_cyl\nn_cyl\n\n\n\n\n6.1875\n198\n32"
  },
  {
    "objectID": "posts/2023-11-17-py-python-pizza/index.html",
    "href": "posts/2023-11-17-py-python-pizza/index.html",
    "title": "Python Pizza Hamburg",
    "section": "",
    "text": "Python Pizza Hamburg\nThis Friday, I attended the Python Pizza micro conference in Hamburg. It was a very nice, welcoming and informative event. I liked the broad perspectives on how-to, learning and diversity. The topics of the talks were very accessible and mainly experience based.\nSome of the technical things I took out:\n\n“Streamlit: Making Data Shine in Minute” (Alessandro Romano) showed me that Streamlit may be the tool I need to quickly create data dashboards without getting into webdev details.\n“Introducing the ORMIR community and the book ‘Learn Python with Jupyter’” (Serena Bonaretti) helped me to better understand the evolving relation between open source, open science, research and learning.\n“Choose HTMX and avoid learning too much JavaScript” (Martin Borus) demonstrated once more that I should start to experiment with htmx. I run the repository code in Codespaces later and want to try FastAPI and async web page element reloading.\n\nThe friendly environment and some nice exchanges about data science, Python, and open source projects over delicious pizza were really nice.\n\nThis was a Python Pizza conference. So I asked ChatGPT to draw a Pizza in Python, something it happily did.\nChatGPT message: draw a figure of a pizza in python in a jupyter notebook\nThis provided code for a pizza with peperoni. I tried to get a Vega-Altair version but this did not work out. So I stayed with the Matplotlib version and asked to have some pizza slices.\nChatGPT message: add slices to the matplotlib plot\n\n\nCode\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n\n# Draw the pizza circle\npizza_circle = plt.Circle((0.5, 0.5), 0.4, color='brown', fill=True)\nax.add_patch(pizza_circle)\n\n# Draw the cheese circle (a smaller circle on top of the pizza)\ncheese_circle = plt.Circle((0.5, 0.5), 0.35, color='yellow', fill=True)\nax.add_patch(cheese_circle)\n\n# Draw pizza slices\nnum_slices = 8\ntheta = 360 / num_slices\nslice_colors = ['orange', 'lightgreen', 'tomato', 'wheat', 'lightcoral', 'lightblue', 'sandybrown', 'lightpink']\n\nfor i in range(num_slices):\n    slice_wedge = patches.Wedge((0.5, 0.5), 0.4, i * theta, (i + 1) * theta, color=slice_colors[i], fill=True)\n    ax.add_patch(slice_wedge)\n\n# Set aspect ratio to be equal\nax.set_aspect('equal', adjustable='box')\n\n# Set axis limits\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\n\n# Remove axis labels and ticks\nax.set_xticks([])\nax.set_yticks([])\nax.set_xticklabels([])\nax.set_yticklabels([])\n\n# Set the title\nplt.title(\"Delicious Pizza with Slices\")\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "posts/2023-08-14-r-file-hash/index.html",
    "href": "posts/2023-08-14-r-file-hash/index.html",
    "title": "File hashing",
    "section": "",
    "text": "File hashing\nTo increase the transparency of my work, I was interested in file hashing. It allows to assign a unique value to a file. Such a value is calculated with a defined algorithm.\nIn R, the rlang library provides the hash_file() function and uses the XXH128 hash algorithm to generate a 128-bit hash.\nThis can be used to uniquely identify a data file. For reproducible research, you can add hash values for the datafiles used in a project to uniquely identify them.\nHere, I have created two files for data sets from the datasets library and calculate the hash values of these files.\n\n\nCode\nlibrary(readr)\n\nwrite_csv(datasets::iris, \"iris.csv\")\nwrite_csv(datasets::mtcars, \"mtcars.csv\")\n\n\n\nlibrary(tidyverse)\n\ntibble(files = fs::dir_ls(glob = \"*.csv\")) |&gt;\n  mutate(hash = rlang::hash_file(files))\n\n\n\n\n\nfiles\nhash\n\n\n\n\niris.csv\ndbdc1846dff7fba30a88d5b23e15ea80\n\n\nmtcars.csv\n1d350737ac40dc6fb6ae8f5ad616fc4e"
  },
  {
    "objectID": "posts/2023-11-20-r-httr/index.html",
    "href": "posts/2023-11-20-r-httr/index.html",
    "title": "API requests with httr2",
    "section": "",
    "text": "httr2 1.0 was recently released. I used it earlier this month in my API explorations to understand what the Python requests equivalent is in R. Python and requests are so convenient that I had not used R yet to access an API.\nI became aware of Semantic Scholar, a database of scientific literature, with a nice API.\nSo here is an exploration of my Semantic Scholar records (ID 51362391) in R with httr2.\nCode\nlibrary(tidyverse)\nlibrary(httr2)\nlibrary(jsonlite)"
  },
  {
    "objectID": "posts/2023-11-20-r-httr/index.html#api-request",
    "href": "posts/2023-11-20-r-httr/index.html#api-request",
    "title": "API requests with httr2",
    "section": "API request",
    "text": "API request\nAPI · Fetch paper and author data\n\nauthor_id &lt;- 51362391\n\nurl &lt;-\n  str_glue(\n    \"https://api.semanticscholar.org/graph/v1/author/{author_id}\",\n    \"?fields=name,papers,papers.year,papers.title,papers.citationCount,papers.authors\"\n  )\n\nresp &lt;-\n  request(url) |&gt;\n  req_perform()\n\n\ndt &lt;-\n  resp_body_string(resp) |&gt;\n  fromJSON()\n\nprint(dt[[\"name\"]])\n\n[1] \"Holger Döring\""
  },
  {
    "objectID": "posts/2023-11-20-r-httr/index.html#publications",
    "href": "posts/2023-11-20-r-httr/index.html#publications",
    "title": "API requests with httr2",
    "section": "Publications",
    "text": "Publications\n\npapers &lt;-\n  dt[[\"papers\"]] |&gt;\n  mutate(\n    id_short = str_sub(paperId, 1, 5),\n    title_short = str_sub(title, 1, 30),\n    authors_n = map_int(authors, \\(.x) nrow(.x))\n  )\n\nNumber of publications at Semantic Scholar\n\nnrow(papers)\n\n[1] 24\n\n\nPublications\n\npapers |&gt;\n  select(id_short, year, `cita.` = citationCount, `auth.` = authors_n, title_short)\n\n\n\n\n\nid_short\nyear\ncita.\nauth.\ntitle_short\n\n\n\n\na9408\n2022\n0\n1\nFormal binary logic, tidal for\n\n\nc229b\n2022\n0\n1\nBeyond the light-barrier -fast\n\n\ne3034\n2022\n0\n1\nOccams Razor-No Dark Matter in\n\n\n37135\n2021\n0\n1\nLorentzian SRT-Transformation\n\n\n84d1f\n2021\n1\n3\nGermany: From Stable Coalition\n\n\n8bd34\n2020\n9\n3\nInstitutional constraints on c\n\n\n1b9e9\n2019\n11\n2\nParty Positions from Wikipedia\n\n\ne9e28\n2019\n51\n2\nParty Facts: A database of pol\n\n\nf93aa\n2019\n0\n1\nGathering and Managing Data on\n\n\n69fe5\n2016\n5\n1\nMapping established democracie\n\n\n4175b\n2015\n27\n2\nIs Proportional Representation\n\n\n85957\n2015\n0\n3\nHow do European democracies co\n\n\na9372\n2015\n32\n2\nRevisiting the left cabinet sh\n\n\n34e81\n2014\n1\n2\nJean-Claude Juncker’s new Euro\n\n\n1273f\n2013\n61\n2\nWho Gets into Government? Coal\n\n\n31eff\n2013\n31\n1\nThe collective action of data\n\n\nc01fd\n2012\n2\n3\nMinisterial Careers and ’The M\n\n\nc4f64\n2011\n0\n2\nWhy are States with Pr More Re\n\n\ne3cbe\n2010\n0\n1\nCollaborative Data Collection\n\n\nf5948\n2009\n0\n1\nPolitical representation in Eu\n\n\n2ebbf\n2008\n37\n2\nElectoral and Mechanical Cause\n\n\nec86a\n2008\n1\n1\nEvaluating Scripting Languages\n\n\n14ab0\n2007\n70\n1\nThe Composition of the College\n\n\n9674d\n2006\n3\n2\nDivided Government European St"
  },
  {
    "objectID": "posts/2023-11-20-r-httr/index.html#authors",
    "href": "posts/2023-11-20-r-httr/index.html#authors",
    "title": "API requests with httr2",
    "section": "Authors",
    "text": "Authors\nAuthors by paper\n\nauthors &lt;-\n  papers |&gt;\n  select(id_short, year, authors) |&gt;\n  unnest(authors)\n\nauthors\n\n\n\n\n\nid_short\nyear\nauthorId\nname\n\n\n\n\na9408\n2022\n51362391\nHolger Döring\n\n\nc229b\n2022\n51362391\nHolger Döring\n\n\ne3034\n2022\n51362391\nHolger Döring\n\n\n37135\n2021\n51362391\nHolger Döring\n\n\n84d1f\n2021\n94263396\nM. Debus\n\n\n84d1f\n2021\n51362391\nHolger Döring\n\n\n84d1f\n2021\n143708020\nAlejandro Ecker\n\n\n8bd34\n2020\n119358998\nMaria Thürk\n\n\n8bd34\n2020\n145985059\nJohan Hellström\n\n\n8bd34\n2020\n51362391\nHolger Döring\n\n\n1b9e9\n2019\n145315358\nM. Herrmann\n\n\n1b9e9\n2019\n51362391\nHolger Döring\n\n\ne9e28\n2019\n51362391\nHolger Döring\n\n\ne9e28\n2019\n1685592\nSven Regel\n\n\nf93aa\n2019\n51362391\nHolger Döring\n\n\n69fe5\n2016\n51362391\nHolger Döring\n\n\n4175b\n2015\n51362391\nHolger Döring\n\n\n4175b\n2015\n2072035416\nP. Manow\n\n\n85957\n2015\n144008442\nJonathan Bright\n\n\n85957\n2015\n51362391\nHolger Döring\n\n\n85957\n2015\n145474393\nConor Little\n\n\na9372\n2015\n51362391\nHolger Döring\n\n\na9372\n2015\n115016266\nHanna Schwander\n\n\n34e81\n2014\n82184129\nA. Wonka\n\n\n34e81\n2014\n51362391\nHolger Döring\n\n\n1273f\n2013\n51362391\nHolger Döring\n\n\n1273f\n2013\n145985059\nJohan Hellström\n\n\n31eff\n2013\n51362391\nHolger Döring\n\n\nc01fd\n2012\n144008442\nJonathan Bright\n\n\nc01fd\n2012\n51362391\nHolger Döring\n\n\nc01fd\n2012\n145474393\nConor Little\n\n\nc4f64\n2011\n2072035416\nP. Manow\n\n\nc4f64\n2011\n51362391\nHolger Döring\n\n\ne3cbe\n2010\n51362391\nHolger Döring\n\n\nf5948\n2009\n51362391\nHolger Döring\n\n\n2ebbf\n2008\n2072035416\nP. Manow\n\n\n2ebbf\n2008\n51362391\nHolger Döring\n\n\nec86a\n2008\n51362391\nHolger Döring\n\n\n14ab0\n2007\n51362391\nHolger Döring\n\n\n9674d\n2006\n2072035416\nP. Manow\n\n\n9674d\n2006\n51362391\nHolger Döring"
  },
  {
    "objectID": "posts/2023-07-16-r-r4ds-pr/index.html",
    "href": "posts/2023-07-16-r-r4ds-pr/index.html",
    "title": "First pull request accepted · 😊",
    "section": "",
    "text": "First pull request accepted · 😊\nMy first public pull request on Github was accepted.\nOver the last weeks, I have been reading R for Data Science (2e) (R4DS). The first edition really helped me to get deeply into the tidyverse. So I was interested in the content of the second edition.\nAt some point, I realized that the book used an older parameter in case_when() that was recently superseded in dplyr 1.1. Since, I had switched to the new .default parameter already, I thought that it may be a small and valuable contribution to update the section.\nMaking the code changes was easy. It took me a little to find out how to clone the project and submit the pull requests. The GitHub documentation was helpful and it went smoothly following it.\nI have used R4DS and the tidyverse so often that I am quite proud about my very minor addition to it."
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html",
    "href": "posts/2023-02-16-welcome/index.html",
    "title": "Things I learned: A new TIL",
    "section": "",
    "text": "My idea is to keep a more systematic collection of things I learned (TIL).\nI was inspired by posts of Simon Wilson and Peter Baumgartner that documented things they have learned.\nSo here is an initial version and today the TIL has been Quarto.\nHere is an example of integrating Tidyverse-R code.\nHere is an example of integrating Python code."
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html#some-background",
    "href": "posts/2023-02-16-welcome/index.html#some-background",
    "title": "Things I learned: A new TIL",
    "section": "Some background",
    "text": "Some background\nSetting up a blog in Quarto was easy and well documented. So I started quickly.\nGetting the right Python version running in Quarto was quite a challenge. At the end, the documented recommendation to work with a virtual environment in an env folder worked. It took me some time to get there.\nIt only worked temporarily and I will try to run Python in Quarto again at some later point."
  },
  {
    "objectID": "posts/2023-02-16-welcome/index.html#afterwards",
    "href": "posts/2023-02-16-welcome/index.html#afterwards",
    "title": "Things I learned: A new TIL",
    "section": "Afterwards",
    "text": "Afterwards\nIt turned out that the particular challenge was having a page with R and Python.\nFor Python pages a header option was missing. jupyter: python3 solved the Python challenge that took quite some time.\nRendering a Quarto document with R and Python was only possible with a version Docker on the computer."
  },
  {
    "objectID": "posts/2023-10-10-py-doi-requests/index.html",
    "href": "posts/2023-10-10-py-doi-requests/index.html",
    "title": "Content types",
    "section": "",
    "text": "I was interested in getting the metadata for a DOI without using a package in Python or R. My goal was to get a better understanding of the APIs that are available to access DOI metadata.\nHere is an example with a request for my first peer-reviewed publication.\n\nimport requests\n\ndoi_url = \"https://doi.org/10.1177/1465116507076430\"\n\nheaders = {\"accept\": \"text/x-bibliography\"}\nr = requests.get(doi_url, headers=headers)\n\nr.text\n\n'DÃ¶ring, H. (2007). The Composition of the College of Commissioners. European Union Politics, 8(2), 207â\\x80\\x93228. https://doi.org/10.1177/1465116507076430\\n'\n\n\nThis is the API information I was interested in.\nhttps://citation.crosscite.org/docs.html#sec-4\n\n“Currently three DOI registration agencies have implemented content negotation for their DOIs: Crossref, DataCite and mEDRA. They support a number of metadata content types, some of which are common to the three RAs.”\n\nI try to avoid xml-based formats, so that the following content types are of interst to me.\n\nFormatted text citation // text/x-bibliography\nBibTeX // application/x-bibtex\nCiteproc JSON // application/vnd.citationstyles.csl+json\nSchema.org in JSON-LD // application/vnd.schemaorg.ld+json (only DataCite)\n\nIt is actually nice to put a request into a function. I start with a simple example.\n\ndef get_doi_bib(doi):\n    \"\"\"Return a bibliography for a given DOI.\"\"\"\n\n    url = f\"https://doi.org/{doi}\"\n\n    headers = {\"accept\": \"text/x-bibliography\"}\n    r = requests.get(url, headers=headers)\n\n    return r.text\n\n\nget_doi_bib(\"10.1177/0958928715573481\")\n\n'DÃ¶ring, H., & Schwander, H. (2015). Revisiting the left cabinet share: How to measure the partisan profile of governments in welfare state research. Journal of European Social Policy, 25(2), 175â\\x80\\x93193. https://doi.org/10.1177/0958928715573481\\n'\n\n\nTo get the different formats I am interested in, I can rewrite the function.\n\nimport time\nimport requests\n\nCONTENT_TYPES = {\n    \"bibliography\": \"text/x-bibliography\",\n    \"bibtex\": \"application/x-bibtex\",\n    \"json-csl\": \"application/vnd.citationstyles.csl+json\",\n    \"json-ld\": \"application/vnd.schemaorg.ld+json\",\n}\n\n\ndef get_doi_data(doi, content_type=\"bibliography\"):\n    \"\"\"Return metadata for DOI.\"\"\"\n\n    url = f\"https://doi.org/{doi}\"\n    headers = {\"accept\": CONTENT_TYPES.get(content_type, \"bibliography\")}\n\n    return requests.get(url, headers=headers)\n\n\ndoi = \"10.1016/j.electstud.2016.07.002\"\n\nfor key in CONTENT_TYPES:\n    time.sleep(2)  # pause to avoid requests limit\n    doi_request = get_doi_data(doi, key)\n    print(f\"DOI content type: {key}\\n{doi_request.text}\\n\")\n\nDOI content type: bibliography\nDÃ¶ring, H. (2016). Mapping established democracies: Integrated data on parties, elections and cabinets. Electoral Studies, 44, 535â543. https://doi.org/10.1016/j.electstud.2016.07.002\n\n\nDOI content type: bibtex\n @article{D_ring_2016, title={Mapping established democracies: Integrated data on parties, elections and cabinets}, volume={44}, ISSN={0261-3794}, url={http://dx.doi.org/10.1016/j.electstud.2016.07.002}, DOI={10.1016/j.electstud.2016.07.002}, journal={Electoral Studies}, publisher={Elsevier BV}, author={Döring, Holger}, year={2016}, month=dec, pages={535–543} }\n\n\nDOI content type: json-csl\n{\"indexed\":{\"date-parts\":[[2025,7,16]],\"date-time\":\"2025-07-16T12:16:04Z\",\"timestamp\":1752668164004},\"reference-count\":43,\"publisher\":\"Elsevier BV\",\"license\":[{\"start\":{\"date-parts\":[[2016,12,1]],\"date-time\":\"2016-12-01T00:00:00Z\",\"timestamp\":1480550400000},\"content-version\":\"tdm\",\"delay-in-days\":0,\"URL\":\"https:\\/\\/www.elsevier.com\\/tdm\\/userlicense\\/1.0\\/\"}],\"content-domain\":{\"domain\":[\"elsevier.com\",\"sciencedirect.com\"],\"crossmark-restriction\":true},\"published-print\":{\"date-parts\":[[2016,12]]},\"DOI\":\"10.1016\\/j.electstud.2016.07.002\",\"type\":\"journal-article\",\"created\":{\"date-parts\":[[2016,7,23]],\"date-time\":\"2016-07-23T05:27:36Z\",\"timestamp\":1469251656000},\"page\":\"535-543\",\"update-policy\":\"http:\\/\\/dx.doi.org\\/10.1016\\/elsevier_cm_policy\",\"source\":\"Crossref\",\"is-referenced-by-count\":5,\"special_numbering\":\"C\",\"title\":\"Mapping established democracies: Integrated data on parties, elections and cabinets\",\"prefix\":\"10.1016\",\"volume\":\"44\",\"author\":[{\"given\":\"Holger\",\"family\":\"D\\u00f6ring\",\"sequence\":\"first\",\"affiliation\":[]}],\"member\":\"78\",\"reference\":[{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib1\",\"series-title\":\"The European Representative Democracy Data Archive, Release 3\",\"author\":\"Andersson\",\"year\":\"2014\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib2\",\"series-title\":\"Comparative Political Data Set 1960\\u20132013\",\"author\":\"Armingeon\",\"year\":\"2015\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib3\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"143\",\"DOI\":\"10.1177\\/1354068812462931\",\"article-title\":\"Measuring party positions in Europe: the Chapel Hill expert survey trend file, 1999\\u20132010\",\"volume\":\"21\",\"author\":\"Bakker\",\"year\":\"2015\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib4\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"303\",\"DOI\":\"10.1177\\/1354068810369148\",\"article-title\":\"Out with the old, in with the \\u201cnew\\u201d: what constitutes a new party?\",\"volume\":\"17\",\"author\":\"Barnea\",\"year\":\"2011\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib5\",\"series-title\":\"Party Policy in Modern Democracies\",\"author\":\"Benoit\",\"year\":\"2006\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib6\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"1523\",\"DOI\":\"10.1177\\/0010414012463905\",\"article-title\":\"A\\u00a0complete data set of political regimes, 1800\\u20132007\",\"volume\":\"46\",\"author\":\"Boix\",\"year\":\"2013\",\"journal-title\":\"Comp. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib7\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"360\",\"DOI\":\"10.1016\\/j.electstud.2013.01.005\",\"article-title\":\"Democratic electoral systems around the world, 1946\\u20132011\",\"volume\":\"32\",\"author\":\"Bormann\",\"year\":\"2013\",\"journal-title\":\"Elect. Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib8\",\"series-title\":\"Das parlamentarische Wahlrecht: Ein Handbuch \\u00fcber die Bildung der gesetzgebenden K\\u00f6rperschaften in Europa \\u2013 2. Band: Allgemeiner Teil\",\"author\":\"Braunias\",\"year\":\"1932\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib9\",\"series-title\":\"Parties and Democracy: Coalition Formation and Government Functioning in Twenty States\",\"author\":\"Budge\",\"year\":\"1993\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib10\",\"series-title\":\"Mapping Policy Preferences: Estimates for Parties, Electors, and Governments, 1945-1998\",\"author\":\"Budge\",\"year\":\"2001\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib11\",\"series-title\":\"Political Parties of Eastern Europe: a Guide to Politics in the Post-communist Era\",\"author\":\"Bugajski\",\"year\":\"2002\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib12\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"73\",\"DOI\":\"10.1111\\/j.1475-6765.1984.tb00080.x\",\"article-title\":\"Left right political scales: some expert judgments\",\"volume\":\"12\",\"author\":\"Castles\",\"year\":\"1984\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib13\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"119\",\"DOI\":\"10.1111\\/j.1475-6765.2009.01888.x\",\"article-title\":\"Measuring government duration and stability in Central Eastern European democracies\",\"volume\":\"49\",\"author\":\"Conrad\",\"year\":\"2010\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib14\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"193\",\"DOI\":\"10.1111\\/j.1467-9477.1994.tb00144.x\",\"article-title\":\"Termination of Danish government coalitions: theoretical and empirical aspects\",\"volume\":\"17\",\"author\":\"Damgaard\",\"year\":\"1994\",\"journal-title\":\"Scand. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib15\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"161\",\"DOI\":\"10.1177\\/1465116512461189\",\"article-title\":\"The collective action of data collection: a data infrastructure on parties, elections and cabinets\",\"volume\":\"14\",\"author\":\"D\\u00f6ring\",\"year\":\"2013\",\"journal-title\":\"Eur. Union Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib16\",\"first-page\":\"17\",\"article-title\":\"ParlGov: a new data infrastructure in comparative politics\",\"volume\":\"23\",\"author\":\"D\\u00f6ring\",\"year\":\"2013\",\"journal-title\":\"APSA Comp. Politics Newsl.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib17\",\"first-page\":\"19\",\"article-title\":\"A\\u00a0user-driven and flexible procedure for data linking\",\"volume\":\"2010\",\"author\":\"Ejik\",\"year\":\"2010\",\"journal-title\":\"IASSIST Q.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib18\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"495\",\"DOI\":\"10.1111\\/j.1468-2508.2007.00546.x\",\"article-title\":\"Punishment or protest? understanding European Parliament elections\",\"volume\":\"69\",\"author\":\"Hix\",\"year\":\"2007\",\"journal-title\":\"J.\\u00a0Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib19\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"965\",\"DOI\":\"10.1177\\/001041402236310\",\"article-title\":\"Does left\\/right structure party positions on European integration?\",\"volume\":\"35\",\"author\":\"Hooghe\",\"year\":\"2002\",\"journal-title\":\"Comp. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib20\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"73\",\"DOI\":\"10.1177\\/1354068895001001004\",\"article-title\":\"Expert interpretations of party space and party locations in 42 societies\",\"volume\":\"1\",\"author\":\"Huber\",\"year\":\"1995\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib21\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"381\",\"DOI\":\"10.1111\\/1475-6765.12030\",\"article-title\":\"Determinants of cabinet size\",\"volume\":\"53\",\"author\":\"Indridason\",\"year\":\"2014\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib22\",\"series-title\":\"Western European Political Parties: a Comprehensive Guide\",\"year\":\"1989\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib23\",\"series-title\":\"Mapping Policy Preferences II: Estimates for Parties, Electors and Governments in Central and Eastern Europe, European Union and OECD 1990-2003\",\"author\":\"Klingemann\",\"year\":\"2006\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib24\",\"series-title\":\"Policy and Party Competition\",\"author\":\"Laver\",\"year\":\"1992\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib25\",\"series-title\":\"The International Almanac of Electoral History\",\"author\":\"Mackie\",\"year\":\"1991\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib26\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"211\",\"DOI\":\"10.1146\\/annurev.polisci.1.1.211\",\"article-title\":\"The party family and its study\",\"volume\":\"1\",\"author\":\"Mair\",\"year\":\"1998\",\"journal-title\":\"Annu. Rev. Political Sci.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib27\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"654\",\"DOI\":\"10.1111\\/1475-6765.12054\",\"article-title\":\"Defining and classifying technocrat-led and technocratic governments\",\"volume\":\"53\",\"author\":\"McDonnell\",\"year\":\"2014\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib28\",\"series-title\":\"Political Parties of Europe\",\"year\":\"1983\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib29\",\"series-title\":\"Coalition Governments in Western Europe\",\"year\":\"2000\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib30\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"869\",\"DOI\":\"10.1111\\/j.0304-4130.2004.00178.x\",\"article-title\":\"Party government in Central Eastern European democracies: a data collection (1990-2003)\",\"volume\":\"43\",\"author\":\"M\\u00fcller-Rommel\",\"year\":\"2004\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib31\",\"series-title\":\"Elections in Europe: a Data Handbook\",\"year\":\"2010\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib32\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"283\",\"DOI\":\"10.1111\\/1475-6765.00471\",\"article-title\":\"Measuring party orientations towards European integration: results from an expert survey\",\"volume\":\"36\",\"author\":\"Ray\",\"year\":\"1999\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib33\",\"series-title\":\"International Guide to Electoral Statistics; Guide International Des Statistiques \\u00c9lectorales\",\"first-page\":\"1\",\"article-title\":\"Introduction\",\"author\":\"Rokkan\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib34\",\"series-title\":\"International guide to electoral statistics; Guide international des statistiques \\u00e9lectorales\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib35\",\"series-title\":\"Elections and Parties in New European Democracies\",\"author\":\"Rose\",\"year\":\"2003\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib36\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"270\",\"DOI\":\"10.1016\\/j.electstud.2013.10.001\",\"article-title\":\"Updating the party government data set\",\"volume\":\"34\",\"author\":\"Seki\",\"year\":\"2014\",\"journal-title\":\"Elect. Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib37\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"391\",\"DOI\":\"10.1111\\/j.1475-6765.2005.00232.x\",\"article-title\":\"How unstable? Volatility and the genuinely new parties in Eastern Europe\",\"volume\":\"44\",\"author\":\"Sikk\",\"year\":\"2005\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib38\",\"series-title\":\"Die Wahl der Parlamente und anderer Staatsorgane\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib39\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"261\",\"DOI\":\"10.1111\\/1475-6765.00513\",\"article-title\":\"Delegation and accountability in parliamentary democracies\",\"volume\":\"37\",\"author\":\"Str\\u00f8m\",\"year\":\"2000\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib40\",\"series-title\":\"Veto Players: How Political Institutions Work\",\"author\":\"Tsebelis\",\"year\":\"2002\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib41\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"187\",\"DOI\":\"10.1017\\/S0007123411000263\",\"article-title\":\"Constitutionalizing party democracy: the constitutive codification of political parties in post-war Europe\",\"volume\":\"42\",\"author\":\"Van Biezen\",\"year\":\"2012\",\"journal-title\":\"Br. J. Political Sci.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib42\",\"series-title\":\"Mapping Policy Preferences from Texts III: Statistical Solutions for Manifesto Analysts\",\"author\":\"Volkens\",\"year\":\"2013\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib43\",\"series-title\":\"Party Government in 48 Democracies (1945-1998): Composition, Duration, Personnel\",\"author\":\"Woldendorp\",\"year\":\"2000\"}],\"container-title\":\"Electoral Studies\",\"original-title\":[],\"language\":\"en\",\"link\":[{\"URL\":\"https:\\/\\/api.elsevier.com\\/content\\/article\\/PII:S0261379416301652?httpAccept=text\\/xml\",\"content-type\":\"text\\/xml\",\"content-version\":\"vor\",\"intended-application\":\"text-mining\"},{\"URL\":\"https:\\/\\/api.elsevier.com\\/content\\/article\\/PII:S0261379416301652?httpAccept=text\\/plain\",\"content-type\":\"text\\/plain\",\"content-version\":\"vor\",\"intended-application\":\"text-mining\"}],\"deposited\":{\"date-parts\":[[2018,7,17]],\"date-time\":\"2018-07-17T21:43:09Z\",\"timestamp\":1531863789000},\"score\":1,\"resource\":{\"primary\":{\"URL\":\"https:\\/\\/linkinghub.elsevier.com\\/retrieve\\/pii\\/S0261379416301652\"}},\"subtitle\":[],\"short-title\":[],\"issued\":{\"date-parts\":[[2016,12]]},\"references-count\":43,\"alternative-id\":[\"S0261379416301652\"],\"URL\":\"http:\\/\\/dx.doi.org\\/10.1016\\/j.electstud.2016.07.002\",\"relation\":{},\"ISSN\":[\"0261-3794\"],\"subject\":[],\"container-title-short\":\"Electoral Studies\",\"published\":{\"date-parts\":[[2016,12]]},\"assertion\":[{\"value\":\"Elsevier\",\"name\":\"publisher\",\"label\":\"This article is maintained by\"},{\"value\":\"Mapping established democracies: Integrated data on parties, elections and cabinets\",\"name\":\"articletitle\",\"label\":\"Article Title\"},{\"value\":\"Electoral Studies\",\"name\":\"journaltitle\",\"label\":\"Journal Title\"},{\"value\":\"https:\\/\\/doi.org\\/10.1016\\/j.electstud.2016.07.002\",\"name\":\"articlelink\",\"label\":\"CrossRef DOI link to publisher maintained version\"},{\"value\":\"article\",\"name\":\"content_type\",\"label\":\"Content Type\"},{\"value\":\"\\u00a9 2016 Elsevier Ltd. All rights reserved.\",\"name\":\"copyright\",\"label\":\"Copyright\"}]}\n\nDOI content type: json-ld\nNo acceptable resource available.\n\n\n\n\n\n\njson-ld is only available for content registered with DataCite.\nA DOI for an article does not return json-ld metadata.\n\ndoi_content = get_doi_data(doi, \"json-ld\")\n\ndoi_content\n\n&lt;Response [406]&gt;\n\n\n\ndoi_content.text\n\n'No acceptable resource available.'\n\n\n\nA DOI for a dataset returns json-ld metadata.\n\ndoi_content = get_doi_data(\"10.7910/DVN/BUWAAF\", \"json-ld\")\n\ndoi_content\n\n&lt;Response [200]&gt;\n\n\n\ndoi_content.text\n\n'{\\n  \"@context\": \"http://schema.org\",\\n  \"@type\": \"Dataset\",\\n  \"@id\": \"https://doi.org/10.7910/dvn/buwaaf\",\\n  \"url\": \"https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/BUWAAF\",\\n  \"name\": \"Party Facts – Version 2022\",\\n  \"author\": [\\n    {\\n      \"name\": \"Paul Bederke\",\\n      \"givenName\": \"Paul\",\\n      \"familyName\": \"Bederke\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"University of Konstanz\"\\n      },\\n      \"@type\": \"Person\",\\n      \"@id\": \"https://orcid.org/0000-0001-7555-8656\"\\n    },\\n    {\\n      \"name\": \"Holger Döring\",\\n      \"givenName\": \"Holger\",\\n      \"familyName\": \"Döring\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"GESIS – Leibniz Institute for the Social Sciences\"\\n      },\\n      \"@type\": \"Person\",\\n      \"@id\": \"https://orcid.org/0000-0002-6616-8805\"\\n    },\\n    {\\n      \"name\": \"Sven Regel\",\\n      \"givenName\": \"Sven\",\\n      \"familyName\": \"Regel\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"WZB Berlin Social Science Center\"\\n      },\\n      \"@type\": \"Person\"\\n    }\\n  ],\\n  \"editor\": {\\n    \"name\": \"Paul Bederke\",\\n    \"givenName\": \"Paul\",\\n    \"familyName\": \"Bederke\",\\n    \"affiliation\": {\\n      \"@type\": \"Organization\",\\n      \"name\": \"University of Konstanz\"\\n    },\\n    \"contributorType\": \"ContactPerson\",\\n    \"@type\": \"Person\"\\n  },\\n  \"description\": \"Party Facts links datasets on political parties\",\\n  \"license\": [\\n    \"info:eu-repo/semantics/openAccess\",\\n    \"https://creativecommons.org/publicdomain/zero/1.0/legalcode\"\\n  ],\\n  \"version\": \"1.0\",\\n  \"keywords\": \"Social Sciences\",\\n  \"contentSize\": [\\n    \"8063454\",\\n    \"1430994\",\\n    \"1619721\",\\n    \"21778\",\\n    \"9673\",\\n    \"8747276\"\\n  ],\\n  \"encodingFormat\": [\\n    \"application/zip\",\\n    \"text/html\",\\n    \"text/tab-separated-values\",\\n    \"text/tab-separated-values\",\\n    \"text/tab-separated-values\",\\n    \"text/csv\"\\n  ],\\n  \"datePublished\": \"2022\",\\n  \"dateModified\": \"2022-12-16\",\\n  \"@reverse\": {\\n    \"isBasedOn\": {\\n      \"@id\": \"https://doi.org/10.1177/1354068818820671\",\\n      \"@type\": \"ScholarlyArticle\"\\n    }\\n  },\\n  \"schemaVersion\": \"http://datacite.org/schema/kernel-4\",\\n  \"publisher\": {\\n    \"@type\": \"Organization\",\\n    \"name\": \"Harvard Dataverse\"\\n  },\\n  \"provider\": {\\n    \"@type\": \"Organization\",\\n    \"name\": \"datacite\"\\n  }\\n}'\n\n\n\ndoi_content.json()\n\n{'@context': 'http://schema.org',\n '@type': 'Dataset',\n '@id': 'https://doi.org/10.7910/dvn/buwaaf',\n 'url': 'https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/BUWAAF',\n 'name': 'Party Facts – Version 2022',\n 'author': [{'name': 'Paul Bederke',\n   'givenName': 'Paul',\n   'familyName': 'Bederke',\n   'affiliation': {'@type': 'Organization', 'name': 'University of Konstanz'},\n   '@type': 'Person',\n   '@id': 'https://orcid.org/0000-0001-7555-8656'},\n  {'name': 'Holger Döring',\n   'givenName': 'Holger',\n   'familyName': 'Döring',\n   'affiliation': {'@type': 'Organization',\n    'name': 'GESIS – Leibniz Institute for the Social Sciences'},\n   '@type': 'Person',\n   '@id': 'https://orcid.org/0000-0002-6616-8805'},\n  {'name': 'Sven Regel',\n   'givenName': 'Sven',\n   'familyName': 'Regel',\n   'affiliation': {'@type': 'Organization',\n    'name': 'WZB Berlin Social Science Center'},\n   '@type': 'Person'}],\n 'editor': {'name': 'Paul Bederke',\n  'givenName': 'Paul',\n  'familyName': 'Bederke',\n  'affiliation': {'@type': 'Organization', 'name': 'University of Konstanz'},\n  'contributorType': 'ContactPerson',\n  '@type': 'Person'},\n 'description': 'Party Facts links datasets on political parties',\n 'license': ['info:eu-repo/semantics/openAccess',\n  'https://creativecommons.org/publicdomain/zero/1.0/legalcode'],\n 'version': '1.0',\n 'keywords': 'Social Sciences',\n 'contentSize': ['8063454', '1430994', '1619721', '21778', '9673', '8747276'],\n 'encodingFormat': ['application/zip',\n  'text/html',\n  'text/tab-separated-values',\n  'text/tab-separated-values',\n  'text/tab-separated-values',\n  'text/csv'],\n 'datePublished': '2022',\n 'dateModified': '2022-12-16',\n '@reverse': {'isBasedOn': {'@id': 'https://doi.org/10.1177/1354068818820671',\n   '@type': 'ScholarlyArticle'}},\n 'schemaVersion': 'http://datacite.org/schema/kernel-4',\n 'publisher': {'@type': 'Organization', 'name': 'Harvard Dataverse'},\n 'provider': {'@type': 'Organization', 'name': 'datacite'}}"
  },
  {
    "objectID": "posts/2023-10-10-py-doi-requests/index.html#doi-api-access",
    "href": "posts/2023-10-10-py-doi-requests/index.html#doi-api-access",
    "title": "Content types",
    "section": "",
    "text": "I was interested in getting the metadata for a DOI without using a package in Python or R. My goal was to get a better understanding of the APIs that are available to access DOI metadata.\nHere is an example with a request for my first peer-reviewed publication.\n\nimport requests\n\ndoi_url = \"https://doi.org/10.1177/1465116507076430\"\n\nheaders = {\"accept\": \"text/x-bibliography\"}\nr = requests.get(doi_url, headers=headers)\n\nr.text\n\n'DÃ¶ring, H. (2007). The Composition of the College of Commissioners. European Union Politics, 8(2), 207â\\x80\\x93228. https://doi.org/10.1177/1465116507076430\\n'\n\n\nThis is the API information I was interested in.\nhttps://citation.crosscite.org/docs.html#sec-4\n\n“Currently three DOI registration agencies have implemented content negotation for their DOIs: Crossref, DataCite and mEDRA. They support a number of metadata content types, some of which are common to the three RAs.”\n\nI try to avoid xml-based formats, so that the following content types are of interst to me.\n\nFormatted text citation // text/x-bibliography\nBibTeX // application/x-bibtex\nCiteproc JSON // application/vnd.citationstyles.csl+json\nSchema.org in JSON-LD // application/vnd.schemaorg.ld+json (only DataCite)\n\nIt is actually nice to put a request into a function. I start with a simple example.\n\ndef get_doi_bib(doi):\n    \"\"\"Return a bibliography for a given DOI.\"\"\"\n\n    url = f\"https://doi.org/{doi}\"\n\n    headers = {\"accept\": \"text/x-bibliography\"}\n    r = requests.get(url, headers=headers)\n\n    return r.text\n\n\nget_doi_bib(\"10.1177/0958928715573481\")\n\n'DÃ¶ring, H., & Schwander, H. (2015). Revisiting the left cabinet share: How to measure the partisan profile of governments in welfare state research. Journal of European Social Policy, 25(2), 175â\\x80\\x93193. https://doi.org/10.1177/0958928715573481\\n'\n\n\nTo get the different formats I am interested in, I can rewrite the function.\n\nimport time\nimport requests\n\nCONTENT_TYPES = {\n    \"bibliography\": \"text/x-bibliography\",\n    \"bibtex\": \"application/x-bibtex\",\n    \"json-csl\": \"application/vnd.citationstyles.csl+json\",\n    \"json-ld\": \"application/vnd.schemaorg.ld+json\",\n}\n\n\ndef get_doi_data(doi, content_type=\"bibliography\"):\n    \"\"\"Return metadata for DOI.\"\"\"\n\n    url = f\"https://doi.org/{doi}\"\n    headers = {\"accept\": CONTENT_TYPES.get(content_type, \"bibliography\")}\n\n    return requests.get(url, headers=headers)\n\n\ndoi = \"10.1016/j.electstud.2016.07.002\"\n\nfor key in CONTENT_TYPES:\n    time.sleep(2)  # pause to avoid requests limit\n    doi_request = get_doi_data(doi, key)\n    print(f\"DOI content type: {key}\\n{doi_request.text}\\n\")\n\nDOI content type: bibliography\nDÃ¶ring, H. (2016). Mapping established democracies: Integrated data on parties, elections and cabinets. Electoral Studies, 44, 535â543. https://doi.org/10.1016/j.electstud.2016.07.002\n\n\nDOI content type: bibtex\n @article{D_ring_2016, title={Mapping established democracies: Integrated data on parties, elections and cabinets}, volume={44}, ISSN={0261-3794}, url={http://dx.doi.org/10.1016/j.electstud.2016.07.002}, DOI={10.1016/j.electstud.2016.07.002}, journal={Electoral Studies}, publisher={Elsevier BV}, author={Döring, Holger}, year={2016}, month=dec, pages={535–543} }\n\n\nDOI content type: json-csl\n{\"indexed\":{\"date-parts\":[[2025,7,16]],\"date-time\":\"2025-07-16T12:16:04Z\",\"timestamp\":1752668164004},\"reference-count\":43,\"publisher\":\"Elsevier BV\",\"license\":[{\"start\":{\"date-parts\":[[2016,12,1]],\"date-time\":\"2016-12-01T00:00:00Z\",\"timestamp\":1480550400000},\"content-version\":\"tdm\",\"delay-in-days\":0,\"URL\":\"https:\\/\\/www.elsevier.com\\/tdm\\/userlicense\\/1.0\\/\"}],\"content-domain\":{\"domain\":[\"elsevier.com\",\"sciencedirect.com\"],\"crossmark-restriction\":true},\"published-print\":{\"date-parts\":[[2016,12]]},\"DOI\":\"10.1016\\/j.electstud.2016.07.002\",\"type\":\"journal-article\",\"created\":{\"date-parts\":[[2016,7,23]],\"date-time\":\"2016-07-23T05:27:36Z\",\"timestamp\":1469251656000},\"page\":\"535-543\",\"update-policy\":\"http:\\/\\/dx.doi.org\\/10.1016\\/elsevier_cm_policy\",\"source\":\"Crossref\",\"is-referenced-by-count\":5,\"special_numbering\":\"C\",\"title\":\"Mapping established democracies: Integrated data on parties, elections and cabinets\",\"prefix\":\"10.1016\",\"volume\":\"44\",\"author\":[{\"given\":\"Holger\",\"family\":\"D\\u00f6ring\",\"sequence\":\"first\",\"affiliation\":[]}],\"member\":\"78\",\"reference\":[{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib1\",\"series-title\":\"The European Representative Democracy Data Archive, Release 3\",\"author\":\"Andersson\",\"year\":\"2014\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib2\",\"series-title\":\"Comparative Political Data Set 1960\\u20132013\",\"author\":\"Armingeon\",\"year\":\"2015\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib3\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"143\",\"DOI\":\"10.1177\\/1354068812462931\",\"article-title\":\"Measuring party positions in Europe: the Chapel Hill expert survey trend file, 1999\\u20132010\",\"volume\":\"21\",\"author\":\"Bakker\",\"year\":\"2015\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib4\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"303\",\"DOI\":\"10.1177\\/1354068810369148\",\"article-title\":\"Out with the old, in with the \\u201cnew\\u201d: what constitutes a new party?\",\"volume\":\"17\",\"author\":\"Barnea\",\"year\":\"2011\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib5\",\"series-title\":\"Party Policy in Modern Democracies\",\"author\":\"Benoit\",\"year\":\"2006\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib6\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"1523\",\"DOI\":\"10.1177\\/0010414012463905\",\"article-title\":\"A\\u00a0complete data set of political regimes, 1800\\u20132007\",\"volume\":\"46\",\"author\":\"Boix\",\"year\":\"2013\",\"journal-title\":\"Comp. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib7\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"360\",\"DOI\":\"10.1016\\/j.electstud.2013.01.005\",\"article-title\":\"Democratic electoral systems around the world, 1946\\u20132011\",\"volume\":\"32\",\"author\":\"Bormann\",\"year\":\"2013\",\"journal-title\":\"Elect. Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib8\",\"series-title\":\"Das parlamentarische Wahlrecht: Ein Handbuch \\u00fcber die Bildung der gesetzgebenden K\\u00f6rperschaften in Europa \\u2013 2. Band: Allgemeiner Teil\",\"author\":\"Braunias\",\"year\":\"1932\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib9\",\"series-title\":\"Parties and Democracy: Coalition Formation and Government Functioning in Twenty States\",\"author\":\"Budge\",\"year\":\"1993\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib10\",\"series-title\":\"Mapping Policy Preferences: Estimates for Parties, Electors, and Governments, 1945-1998\",\"author\":\"Budge\",\"year\":\"2001\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib11\",\"series-title\":\"Political Parties of Eastern Europe: a Guide to Politics in the Post-communist Era\",\"author\":\"Bugajski\",\"year\":\"2002\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib12\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"73\",\"DOI\":\"10.1111\\/j.1475-6765.1984.tb00080.x\",\"article-title\":\"Left right political scales: some expert judgments\",\"volume\":\"12\",\"author\":\"Castles\",\"year\":\"1984\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib13\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"119\",\"DOI\":\"10.1111\\/j.1475-6765.2009.01888.x\",\"article-title\":\"Measuring government duration and stability in Central Eastern European democracies\",\"volume\":\"49\",\"author\":\"Conrad\",\"year\":\"2010\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib14\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"193\",\"DOI\":\"10.1111\\/j.1467-9477.1994.tb00144.x\",\"article-title\":\"Termination of Danish government coalitions: theoretical and empirical aspects\",\"volume\":\"17\",\"author\":\"Damgaard\",\"year\":\"1994\",\"journal-title\":\"Scand. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib15\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"161\",\"DOI\":\"10.1177\\/1465116512461189\",\"article-title\":\"The collective action of data collection: a data infrastructure on parties, elections and cabinets\",\"volume\":\"14\",\"author\":\"D\\u00f6ring\",\"year\":\"2013\",\"journal-title\":\"Eur. Union Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib16\",\"first-page\":\"17\",\"article-title\":\"ParlGov: a new data infrastructure in comparative politics\",\"volume\":\"23\",\"author\":\"D\\u00f6ring\",\"year\":\"2013\",\"journal-title\":\"APSA Comp. Politics Newsl.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib17\",\"first-page\":\"19\",\"article-title\":\"A\\u00a0user-driven and flexible procedure for data linking\",\"volume\":\"2010\",\"author\":\"Ejik\",\"year\":\"2010\",\"journal-title\":\"IASSIST Q.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib18\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"495\",\"DOI\":\"10.1111\\/j.1468-2508.2007.00546.x\",\"article-title\":\"Punishment or protest? understanding European Parliament elections\",\"volume\":\"69\",\"author\":\"Hix\",\"year\":\"2007\",\"journal-title\":\"J.\\u00a0Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib19\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"965\",\"DOI\":\"10.1177\\/001041402236310\",\"article-title\":\"Does left\\/right structure party positions on European integration?\",\"volume\":\"35\",\"author\":\"Hooghe\",\"year\":\"2002\",\"journal-title\":\"Comp. Political Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib20\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"73\",\"DOI\":\"10.1177\\/1354068895001001004\",\"article-title\":\"Expert interpretations of party space and party locations in 42 societies\",\"volume\":\"1\",\"author\":\"Huber\",\"year\":\"1995\",\"journal-title\":\"Party Politics\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib21\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"381\",\"DOI\":\"10.1111\\/1475-6765.12030\",\"article-title\":\"Determinants of cabinet size\",\"volume\":\"53\",\"author\":\"Indridason\",\"year\":\"2014\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib22\",\"series-title\":\"Western European Political Parties: a Comprehensive Guide\",\"year\":\"1989\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib23\",\"series-title\":\"Mapping Policy Preferences II: Estimates for Parties, Electors and Governments in Central and Eastern Europe, European Union and OECD 1990-2003\",\"author\":\"Klingemann\",\"year\":\"2006\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib24\",\"series-title\":\"Policy and Party Competition\",\"author\":\"Laver\",\"year\":\"1992\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib25\",\"series-title\":\"The International Almanac of Electoral History\",\"author\":\"Mackie\",\"year\":\"1991\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib26\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"211\",\"DOI\":\"10.1146\\/annurev.polisci.1.1.211\",\"article-title\":\"The party family and its study\",\"volume\":\"1\",\"author\":\"Mair\",\"year\":\"1998\",\"journal-title\":\"Annu. Rev. Political Sci.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib27\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"654\",\"DOI\":\"10.1111\\/1475-6765.12054\",\"article-title\":\"Defining and classifying technocrat-led and technocratic governments\",\"volume\":\"53\",\"author\":\"McDonnell\",\"year\":\"2014\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib28\",\"series-title\":\"Political Parties of Europe\",\"year\":\"1983\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib29\",\"series-title\":\"Coalition Governments in Western Europe\",\"year\":\"2000\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib30\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"869\",\"DOI\":\"10.1111\\/j.0304-4130.2004.00178.x\",\"article-title\":\"Party government in Central Eastern European democracies: a data collection (1990-2003)\",\"volume\":\"43\",\"author\":\"M\\u00fcller-Rommel\",\"year\":\"2004\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib31\",\"series-title\":\"Elections in Europe: a Data Handbook\",\"year\":\"2010\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib32\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"283\",\"DOI\":\"10.1111\\/1475-6765.00471\",\"article-title\":\"Measuring party orientations towards European integration: results from an expert survey\",\"volume\":\"36\",\"author\":\"Ray\",\"year\":\"1999\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib33\",\"series-title\":\"International Guide to Electoral Statistics; Guide International Des Statistiques \\u00c9lectorales\",\"first-page\":\"1\",\"article-title\":\"Introduction\",\"author\":\"Rokkan\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib34\",\"series-title\":\"International guide to electoral statistics; Guide international des statistiques \\u00e9lectorales\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib35\",\"series-title\":\"Elections and Parties in New European Democracies\",\"author\":\"Rose\",\"year\":\"2003\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib36\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"270\",\"DOI\":\"10.1016\\/j.electstud.2013.10.001\",\"article-title\":\"Updating the party government data set\",\"volume\":\"34\",\"author\":\"Seki\",\"year\":\"2014\",\"journal-title\":\"Elect. Stud.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib37\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"391\",\"DOI\":\"10.1111\\/j.1475-6765.2005.00232.x\",\"article-title\":\"How unstable? Volatility and the genuinely new parties in Eastern Europe\",\"volume\":\"44\",\"author\":\"Sikk\",\"year\":\"2005\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib38\",\"series-title\":\"Die Wahl der Parlamente und anderer Staatsorgane\",\"year\":\"1969\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib39\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"261\",\"DOI\":\"10.1111\\/1475-6765.00513\",\"article-title\":\"Delegation and accountability in parliamentary democracies\",\"volume\":\"37\",\"author\":\"Str\\u00f8m\",\"year\":\"2000\",\"journal-title\":\"Eur. J. Political Res.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib40\",\"series-title\":\"Veto Players: How Political Institutions Work\",\"author\":\"Tsebelis\",\"year\":\"2002\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib41\",\"doi-asserted-by\":\"crossref\",\"first-page\":\"187\",\"DOI\":\"10.1017\\/S0007123411000263\",\"article-title\":\"Constitutionalizing party democracy: the constitutive codification of political parties in post-war Europe\",\"volume\":\"42\",\"author\":\"Van Biezen\",\"year\":\"2012\",\"journal-title\":\"Br. J. Political Sci.\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib42\",\"series-title\":\"Mapping Policy Preferences from Texts III: Statistical Solutions for Manifesto Analysts\",\"author\":\"Volkens\",\"year\":\"2013\"},{\"key\":\"10.1016\\/j.electstud.2016.07.002_bib43\",\"series-title\":\"Party Government in 48 Democracies (1945-1998): Composition, Duration, Personnel\",\"author\":\"Woldendorp\",\"year\":\"2000\"}],\"container-title\":\"Electoral Studies\",\"original-title\":[],\"language\":\"en\",\"link\":[{\"URL\":\"https:\\/\\/api.elsevier.com\\/content\\/article\\/PII:S0261379416301652?httpAccept=text\\/xml\",\"content-type\":\"text\\/xml\",\"content-version\":\"vor\",\"intended-application\":\"text-mining\"},{\"URL\":\"https:\\/\\/api.elsevier.com\\/content\\/article\\/PII:S0261379416301652?httpAccept=text\\/plain\",\"content-type\":\"text\\/plain\",\"content-version\":\"vor\",\"intended-application\":\"text-mining\"}],\"deposited\":{\"date-parts\":[[2018,7,17]],\"date-time\":\"2018-07-17T21:43:09Z\",\"timestamp\":1531863789000},\"score\":1,\"resource\":{\"primary\":{\"URL\":\"https:\\/\\/linkinghub.elsevier.com\\/retrieve\\/pii\\/S0261379416301652\"}},\"subtitle\":[],\"short-title\":[],\"issued\":{\"date-parts\":[[2016,12]]},\"references-count\":43,\"alternative-id\":[\"S0261379416301652\"],\"URL\":\"http:\\/\\/dx.doi.org\\/10.1016\\/j.electstud.2016.07.002\",\"relation\":{},\"ISSN\":[\"0261-3794\"],\"subject\":[],\"container-title-short\":\"Electoral Studies\",\"published\":{\"date-parts\":[[2016,12]]},\"assertion\":[{\"value\":\"Elsevier\",\"name\":\"publisher\",\"label\":\"This article is maintained by\"},{\"value\":\"Mapping established democracies: Integrated data on parties, elections and cabinets\",\"name\":\"articletitle\",\"label\":\"Article Title\"},{\"value\":\"Electoral Studies\",\"name\":\"journaltitle\",\"label\":\"Journal Title\"},{\"value\":\"https:\\/\\/doi.org\\/10.1016\\/j.electstud.2016.07.002\",\"name\":\"articlelink\",\"label\":\"CrossRef DOI link to publisher maintained version\"},{\"value\":\"article\",\"name\":\"content_type\",\"label\":\"Content Type\"},{\"value\":\"\\u00a9 2016 Elsevier Ltd. All rights reserved.\",\"name\":\"copyright\",\"label\":\"Copyright\"}]}\n\nDOI content type: json-ld\nNo acceptable resource available."
  },
  {
    "objectID": "posts/2023-10-10-py-doi-requests/index.html#linked-data-json-ld",
    "href": "posts/2023-10-10-py-doi-requests/index.html#linked-data-json-ld",
    "title": "Content types",
    "section": "",
    "text": "json-ld is only available for content registered with DataCite.\nA DOI for an article does not return json-ld metadata.\n\ndoi_content = get_doi_data(doi, \"json-ld\")\n\ndoi_content\n\n&lt;Response [406]&gt;\n\n\n\ndoi_content.text\n\n'No acceptable resource available.'\n\n\n\nA DOI for a dataset returns json-ld metadata.\n\ndoi_content = get_doi_data(\"10.7910/DVN/BUWAAF\", \"json-ld\")\n\ndoi_content\n\n&lt;Response [200]&gt;\n\n\n\ndoi_content.text\n\n'{\\n  \"@context\": \"http://schema.org\",\\n  \"@type\": \"Dataset\",\\n  \"@id\": \"https://doi.org/10.7910/dvn/buwaaf\",\\n  \"url\": \"https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/BUWAAF\",\\n  \"name\": \"Party Facts – Version 2022\",\\n  \"author\": [\\n    {\\n      \"name\": \"Paul Bederke\",\\n      \"givenName\": \"Paul\",\\n      \"familyName\": \"Bederke\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"University of Konstanz\"\\n      },\\n      \"@type\": \"Person\",\\n      \"@id\": \"https://orcid.org/0000-0001-7555-8656\"\\n    },\\n    {\\n      \"name\": \"Holger Döring\",\\n      \"givenName\": \"Holger\",\\n      \"familyName\": \"Döring\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"GESIS – Leibniz Institute for the Social Sciences\"\\n      },\\n      \"@type\": \"Person\",\\n      \"@id\": \"https://orcid.org/0000-0002-6616-8805\"\\n    },\\n    {\\n      \"name\": \"Sven Regel\",\\n      \"givenName\": \"Sven\",\\n      \"familyName\": \"Regel\",\\n      \"affiliation\": {\\n        \"@type\": \"Organization\",\\n        \"name\": \"WZB Berlin Social Science Center\"\\n      },\\n      \"@type\": \"Person\"\\n    }\\n  ],\\n  \"editor\": {\\n    \"name\": \"Paul Bederke\",\\n    \"givenName\": \"Paul\",\\n    \"familyName\": \"Bederke\",\\n    \"affiliation\": {\\n      \"@type\": \"Organization\",\\n      \"name\": \"University of Konstanz\"\\n    },\\n    \"contributorType\": \"ContactPerson\",\\n    \"@type\": \"Person\"\\n  },\\n  \"description\": \"Party Facts links datasets on political parties\",\\n  \"license\": [\\n    \"info:eu-repo/semantics/openAccess\",\\n    \"https://creativecommons.org/publicdomain/zero/1.0/legalcode\"\\n  ],\\n  \"version\": \"1.0\",\\n  \"keywords\": \"Social Sciences\",\\n  \"contentSize\": [\\n    \"8063454\",\\n    \"1430994\",\\n    \"1619721\",\\n    \"21778\",\\n    \"9673\",\\n    \"8747276\"\\n  ],\\n  \"encodingFormat\": [\\n    \"application/zip\",\\n    \"text/html\",\\n    \"text/tab-separated-values\",\\n    \"text/tab-separated-values\",\\n    \"text/tab-separated-values\",\\n    \"text/csv\"\\n  ],\\n  \"datePublished\": \"2022\",\\n  \"dateModified\": \"2022-12-16\",\\n  \"@reverse\": {\\n    \"isBasedOn\": {\\n      \"@id\": \"https://doi.org/10.1177/1354068818820671\",\\n      \"@type\": \"ScholarlyArticle\"\\n    }\\n  },\\n  \"schemaVersion\": \"http://datacite.org/schema/kernel-4\",\\n  \"publisher\": {\\n    \"@type\": \"Organization\",\\n    \"name\": \"Harvard Dataverse\"\\n  },\\n  \"provider\": {\\n    \"@type\": \"Organization\",\\n    \"name\": \"datacite\"\\n  }\\n}'\n\n\n\ndoi_content.json()\n\n{'@context': 'http://schema.org',\n '@type': 'Dataset',\n '@id': 'https://doi.org/10.7910/dvn/buwaaf',\n 'url': 'https://dataverse.harvard.edu/citation?persistentId=doi:10.7910/DVN/BUWAAF',\n 'name': 'Party Facts – Version 2022',\n 'author': [{'name': 'Paul Bederke',\n   'givenName': 'Paul',\n   'familyName': 'Bederke',\n   'affiliation': {'@type': 'Organization', 'name': 'University of Konstanz'},\n   '@type': 'Person',\n   '@id': 'https://orcid.org/0000-0001-7555-8656'},\n  {'name': 'Holger Döring',\n   'givenName': 'Holger',\n   'familyName': 'Döring',\n   'affiliation': {'@type': 'Organization',\n    'name': 'GESIS – Leibniz Institute for the Social Sciences'},\n   '@type': 'Person',\n   '@id': 'https://orcid.org/0000-0002-6616-8805'},\n  {'name': 'Sven Regel',\n   'givenName': 'Sven',\n   'familyName': 'Regel',\n   'affiliation': {'@type': 'Organization',\n    'name': 'WZB Berlin Social Science Center'},\n   '@type': 'Person'}],\n 'editor': {'name': 'Paul Bederke',\n  'givenName': 'Paul',\n  'familyName': 'Bederke',\n  'affiliation': {'@type': 'Organization', 'name': 'University of Konstanz'},\n  'contributorType': 'ContactPerson',\n  '@type': 'Person'},\n 'description': 'Party Facts links datasets on political parties',\n 'license': ['info:eu-repo/semantics/openAccess',\n  'https://creativecommons.org/publicdomain/zero/1.0/legalcode'],\n 'version': '1.0',\n 'keywords': 'Social Sciences',\n 'contentSize': ['8063454', '1430994', '1619721', '21778', '9673', '8747276'],\n 'encodingFormat': ['application/zip',\n  'text/html',\n  'text/tab-separated-values',\n  'text/tab-separated-values',\n  'text/tab-separated-values',\n  'text/csv'],\n 'datePublished': '2022',\n 'dateModified': '2022-12-16',\n '@reverse': {'isBasedOn': {'@id': 'https://doi.org/10.1177/1354068818820671',\n   '@type': 'ScholarlyArticle'}},\n 'schemaVersion': 'http://datacite.org/schema/kernel-4',\n 'publisher': {'@type': 'Organization', 'name': 'Harvard Dataverse'},\n 'provider': {'@type': 'Organization', 'name': 'datacite'}}"
  },
  {
    "objectID": "posts/2023-05-01-py-wikipedia-data/index.html",
    "href": "posts/2023-05-01-py-wikipedia-data/index.html",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "",
    "text": "I wanted to get the first image of a Wikipedia page and the coordinates.\nChatGPT was very helpful here as well.\nThe code ChatGPT provided worked with the examples it used. I made only some small adjustments to the code below."
  },
  {
    "objectID": "posts/2023-05-01-py-wikipedia-data/index.html#image",
    "href": "posts/2023-05-01-py-wikipedia-data/index.html#image",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Image",
    "text": "Image\n\n\nCode\ntry:\n    import wikipedia\nexcept ImportError:\n    ! pip install wikipedia\n\n\nChatGPT added comments to every line of the code. I combined them into blocks to make the snippet more concise.\n\nimport urllib\n\nimport requests\nimport wikipedia\n\nfrom bs4 import BeautifulSoup\n\n# Set the Wikipedia page title and get page\npage_title = \"Berlin\"\npage = wikipedia.page(page_title)\n\n# Get html content of page and parse it with BeautifulSoup\nhtml = page.html()\nsoup = BeautifulSoup(html, \"html.parser\")\n\n# Find the infobox image element and get url image\nimage_element = soup.find(\"table\", class_=\"infobox\").find(\"img\")\nimage_url = \"https:\" + image_element[\"src\"]\n\n# Download the image\nurllib.request.urlretrieve(image_url, 'image.jpg')\n\n('image.jpg', &lt;http.client.HTTPMessage at 0x7fffb459a430&gt;)"
  },
  {
    "objectID": "posts/2023-05-01-py-wikipedia-data/index.html#coordinates",
    "href": "posts/2023-05-01-py-wikipedia-data/index.html#coordinates",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Coordinates",
    "text": "Coordinates\n\nimport requests\nimport json\n\n# function to get the coordinates from the infobox of a Wikipedia article\ndef get_coordinates(title):\n    url = \"https://en.wikipedia.org/w/api.php\"\n    params = {\n        \"action\": \"query\",\n        \"prop\": \"coordinates\",\n        \"titles\": title,\n        \"format\": \"json\",\n        \"formatversion\": 2\n    }\n    response = requests.get(url, params=params)\n    data = json.loads(response.text)\n    pages = data[\"query\"][\"pages\"]\n    coordinates = None\n    for page in pages:\n        if \"coordinates\" in page:\n            coordinates = page[\"coordinates\"][0]\n            break\n    return coordinates\n\n# example usage\ntitle = \"Berlin\"\ncoordinates = get_coordinates(title)\nprint(coordinates[\"lat\"], coordinates[\"lon\"])\n\n52.52 13.405"
  },
  {
    "objectID": "posts/2023-05-01-py-wikipedia-data/index.html#map",
    "href": "posts/2023-05-01-py-wikipedia-data/index.html#map",
    "title": "Wikipedia, Python, ChatGPT",
    "section": "Map",
    "text": "Map\n\nimport folium\n\nmap_coord = [coordinates['lat'], coordinates['lon']]\n\n# create the map\nmap = folium.Map(location=map_coord, zoom_start=3.5)\n\n# add a marker at the location\nfolium.Marker(location=map_coord, popup=title).add_to(map)\n\n# display the map\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "posts/2023-02-22-py-hello-jupyter/index.html",
    "href": "posts/2023-02-22-py-hello-jupyter/index.html",
    "title": "Hello Jupyter",
    "section": "",
    "text": "Hello Jupyter\nI used my new Quarto and Jupyter skills to create web pages for an introduction to notebooks that Arnim Bleier gave recently at GESIS DSS."
  },
  {
    "objectID": "posts/2023-06-17-git-rebase/index.html",
    "href": "posts/2023-06-17-git-rebase/index.html",
    "title": "Git rebase interactive",
    "section": "",
    "text": "Git rebase interactive\nGit rebase interactive is nice. I have used Git for a long time and correcting wrong commits has been a hassle so far. I try to keep a nice Git history and pay attention to details in Git commits. Merge conflicts and rebasing in Git have so far been challenging to me and I run regular into conflicts.\nSo today I was pleasently surprised how well interactive rebasing in Git works. Here is the magic message:\ngit rebase -i HEAD~5\nRevising the commit history in a text editor worked really well.\n\npick c86752b Use date last modified for TIL post\npick faa548f Add post Jupyter notebooks in Git\npick 86096fa Add TIL Markdown comments\npick a682d0d Add codespace init script\npick c993202 Add VS Code settings\n\n# Rebase 22b5523..c993202 onto 22b5523 (5 commands)\n#\n# Commands:\n# p, pick &lt;commit&gt; = use commit\n# r, reword &lt;commit&gt; = use commit, but edit the commit message\n# e, edit &lt;commit&gt; = use commit, but stop for amending\n# s, squash &lt;commit&gt; = use commit, but meld into previous commit\n# f, fixup [-C | -c] &lt;commit&gt; = like \"squash\" but keep only the previous\n#                    commit's log message, unless -C is used, in which case\n#                    keep only this commit's message; -c is same as -C but\n#                    opens the editor\n# x, exec &lt;command&gt; = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with 'git rebase --continue')\n# d, drop &lt;commit&gt; = remove commit\n# l, label &lt;label&gt; = label current HEAD with a name\n# t, reset &lt;label&gt; = reset HEAD to a label\n# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]\n#         create a merge commit using the original merge commit's\n#         message (or the oneline, if no original merge commit was\n#         specified); use -c &lt;commit&gt; to reword the commit message\n# u, update-ref &lt;ref&gt; = track a placeholder for the &lt;ref&gt; to be updated\n#                       to this position in the new commits. The &lt;ref&gt; is\n#                       updated at the end of the rebase\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#"
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html",
    "href": "posts/2023-11-25-py-ipython-display/index.html",
    "title": "iPython display",
    "section": "",
    "text": "The display functions from iPython is nice in an interactive Jupyter notebook. Unfortunately, it does not work equally well in Quarto or in a Jupyter notebook converted into html.\nThe JSON method is particularly helpful to explore a Python dictionary but does not work in rendered notebooks.\nNevertheless, it was good to get to know the functions and I add them here for the learning record.\nsee the Jupyter notebook (with nbconvert) and Quarto rendered version."
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html#json",
    "href": "posts/2023-11-25-py-ipython-display/index.html#json",
    "title": "iPython display",
    "section": "JSON",
    "text": "JSON\n\nfrom IPython.display import JSON\n\nperson = {\n    'name': {\n        'first': 'Jane',\n        'last': 'Doe'\n    },\n    'age': 43,\n    'email': 'jane.doe@example.com'\n}\n\nJSON(person)\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html#single-element",
    "href": "posts/2023-11-25-py-ipython-display/index.html#single-element",
    "title": "iPython display",
    "section": "Single element",
    "text": "Single element\n\nfrom IPython.display import Markdown, HTML, JSON, Math\n\n\nHTML(\"&lt;h2&gt;HTML Title&lt;/h2&gt;\")\n\nHTML Title\n\n\n\nMarkdown(\"## Markdown title\")\n\nMarkdown title\n\n\n\nMath(\"a^2 + b^2 = c^2\")\n\n\\(\\displaystyle a^2 + b^2 = c^2\\)\n\n\n\nJSON([\"foo\", {\"bar\": (\"baz\", None, 1.0, 2)}], expanded=True)\n\n&lt;IPython.core.display.JSON object&gt;"
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html#markdown-title",
    "href": "posts/2023-11-25-py-ipython-display/index.html#markdown-title",
    "title": "iPython display",
    "section": "Markdown title",
    "text": "Markdown title"
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html#multiple-elements",
    "href": "posts/2023-11-25-py-ipython-display/index.html#multiple-elements",
    "title": "iPython display",
    "section": "Multiple elements",
    "text": "Multiple elements\n\ndisplay(HTML(\"&lt;em&gt;HTML element&lt;/em&gt;\"))\ndisplay(Markdown(\"__Markdown title__\"))\ndisplay(Math(\"a^2 + b^2 = c^2\"))\n\nHTML element\n\n\nMarkdown title\n\n\n\\(\\displaystyle a^2 + b^2 = c^2\\)\n\n\nAn example of a Quarto issue with display(). The elements are ordered differently in the code cell and the output.\n\nprint(\"'first element'\")\ndisplay(\"second element\")\nprint(\"'third element'\")\n\n'first element'\n\n\n'second element'\n\n\n'third element'\n\n\nRendering of dictionaries with JSON does not work in Quarto or nbconvert."
  },
  {
    "objectID": "posts/2023-11-25-py-ipython-display/index.html#quarto-workflow",
    "href": "posts/2023-11-25-py-ipython-display/index.html#quarto-workflow",
    "title": "iPython display",
    "section": "Quarto workflow",
    "text": "Quarto workflow\nA note how I render the Jupyter notebook of the post.\ncd snippets ;\nruff format ipython-display.ipynb ;\njupyter-nbconvert --execute --inplace ipython-display.ipynb ;\nnbdev_clean --fname ipython-display.ipynb ;\njupyter-nbconvert --to html ipython-display.ipynb --output ipython-display-nbconvert.html"
  },
  {
    "objectID": "posts/2024-07-20-r-round/index.html",
    "href": "posts/2024-07-20-r-round/index.html",
    "title": "Round to first two digits",
    "section": "",
    "text": "To improve the readability of a table, I wanted to round various numbers between 100 and 10,000,000 to their first two digits. 123,456 would become 120,000 and 987 would become 990.\nHere is the solution I came up with.\n\\[\n\\text{scale} \\leftarrow 10^{\\lceil \\log_{10}(x) \\rceil}\n\\]\n\\[\n\\text{round}\\left(\\frac{x}{\\text{scale}}, 2\\right) \\times \\text{scale}\n\\]\n\n\nCode\nlibrary(purrr)\n\noptions(scipen = 999)\nset.seed(0)\n\n\n\nround_first_two &lt;- function(x) {\n  scale &lt;- 10^ceiling(log10(x))\n  round(x / scale, 2) * scale\n}\n\nx1 &lt;- c(113, 2795, 42459, 442060, 6870466)\n\nx1\n\n[1]     113    2795   42459  442060 6870466\n\nmap_dbl(x1, round_first_two)\n\n[1]     110    2800   42000  440000 6900000\n\n\n\n\nGitHub Copilot suggested a more general solution that works for numbers smaller and equal to zero.\n\nx2 &lt;- c(113, -2795, -42459, -442060, 6870466, 0)\n\nx2\n\n[1]     113   -2795  -42459 -442060 6870466       0\n\nmap_dbl(x2, round_first_two)\n\n[1]     110     NaN     NaN     NaN 6900000     NaN\n\nround_first_two_digits &lt;- function(x) {\n  if (x == 0) {\n    return(0)\n  }\n\n  num_digits &lt;- floor(log10(abs(x))) + 1\n  scale_factor &lt;- 10^(num_digits - 2)\n  round(x / scale_factor) * scale_factor\n}\n\nx2\n\n[1]     113   -2795  -42459 -442060 6870466       0\n\nmap_dbl(x2, round_first_two_digits)\n\n[1]     110   -2800  -42000 -440000 6900000       0"
  },
  {
    "objectID": "posts/2024-07-20-r-round/index.html#copilot",
    "href": "posts/2024-07-20-r-round/index.html#copilot",
    "title": "Round to first two digits",
    "section": "",
    "text": "GitHub Copilot suggested a more general solution that works for numbers smaller and equal to zero.\n\nx2 &lt;- c(113, -2795, -42459, -442060, 6870466, 0)\n\nx2\n\n[1]     113   -2795  -42459 -442060 6870466       0\n\nmap_dbl(x2, round_first_two)\n\n[1]     110     NaN     NaN     NaN 6900000     NaN\n\nround_first_two_digits &lt;- function(x) {\n  if (x == 0) {\n    return(0)\n  }\n\n  num_digits &lt;- floor(log10(abs(x))) + 1\n  scale_factor &lt;- 10^(num_digits - 2)\n  round(x / scale_factor) * scale_factor\n}\n\nx2\n\n[1]     113   -2795  -42459 -442060 6870466       0\n\nmap_dbl(x2, round_first_two_digits)\n\n[1]     110   -2800  -42000 -440000 6900000       0"
  },
  {
    "objectID": "posts/2024-07-28-r-log10/index.html",
    "href": "posts/2024-07-28-r-log10/index.html",
    "title": "Thousands categories",
    "section": "",
    "text": "Thousands categories\nI wanted to create categories of thousands and needed to put numbers into intervals of one, ten, and hundred thousands as well as millions.\nHere is the solution I came up with using \\(10^{\\lfloor \\log_{10}(x) \\rfloor}\\)\n\n\nCode\nlibrary(tidyverse)\noptions(scipen = 999)\n\nset.seed(12)\n\n\n\nn &lt;- 12\n\ndt &lt;-\n  tibble(seed = round(runif(n, 1, 10), 1)) |&gt;\n  mutate(\n    x = seed * sample(10^(3:6), n, replace = TRUE),\n    log_x = log10(x) |&gt; round(1),\n    floor_log_x = floor(log_x),\n    category = 10^floor(log10(x))\n  ) |&gt;\n  arrange(x)\n\n\n\nCode\nggplot(dt, aes(y = factor(category))) +\n  geom_bar(fill = \"lightgreen\") +\n  labs(y = \"category\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nseed\nx\nlog_x\nfloor_log_x\ncategory\n\n\n\n\n3.4\n3400\n3.5\n3\n1000\n\n\n4.5\n4500\n3.7\n3\n1000\n\n\n8.4\n8400\n3.9\n3\n1000\n\n\n1.6\n16000\n4.2\n4\n10000\n\n\n2.5\n25000\n4.4\n4\n10000\n\n\n2.6\n26000\n4.4\n4\n10000\n\n\n6.8\n68000\n4.8\n4\n10000\n\n\n9.5\n95000\n5.0\n5\n10000\n\n\n1.2\n120000\n5.1\n5\n100000\n\n\n1.1\n1100000\n6.0\n6\n1000000\n\n\n1.3\n1300000\n6.1\n6\n1000000\n\n\n8.3\n8300000\n6.9\n6\n1000000\n\n\n\n\n\n\n\n\nCode\npl &lt;-\n  ggplot(tibble(x = c(500, 20000000)), aes(x = x)) +\n  stat_function(fun = log10, color = \"lightblue\", linewidth = 1.5) +\n  geom_point(data = tibble(x = 10^(3:7)), aes(x = x, y = log10(x)), color = \"blue\", size = 3) +\n  labs(x = \"x\", y = \"log10(x)\") +\n  scale_x_log10(labels = scales::label_comma())\n\npl"
  },
  {
    "objectID": "posts/2024-til/index.html",
    "href": "posts/2024-til/index.html",
    "title": "Today I learned (TIL) · 2024",
    "section": "",
    "text": "Use git force push safely (2023) with\ngit push --force-with-lease --force-if-includes"
  },
  {
    "objectID": "posts/2024-til/index.html#june",
    "href": "posts/2024-til/index.html#june",
    "title": "Today I learned (TIL) · 2024",
    "section": "",
    "text": "Use git force push safely (2023) with\ngit push --force-with-lease --force-if-includes"
  },
  {
    "objectID": "posts/2024-til/index.html#april",
    "href": "posts/2024-til/index.html#april",
    "title": "Today I learned (TIL) · 2024",
    "section": "1. April",
    "text": "1. April\nFor Python, I’ve configured my OS to prevent pip installations outside of virtual environments by setting the PIP_REQUIRE_VIRTUALENV environment variable. For this configuration export PIP_REQUIRE_VIRTUALENV=\"true\" is set in my .zshrc file. The configuration was inspired by the post On pip isolation."
  },
  {
    "objectID": "posts/2024-til/index.html#march",
    "href": "posts/2024-til/index.html#march",
    "title": "Today I learned (TIL) · 2024",
    "section": "17. March",
    "text": "17. March\nCreating the last post I realized that it is more convenient to work in VS Code with a Jupyter notebook (ipynb) than in a Quarto document (qmd). The notebook enables the use of Jupyter keyboard shortcuts whereas the Quarto document usage is rather static in VS Code.\nThe documents can be converted into the other format with\nquarto convert"
  },
  {
    "objectID": "posts/2024-til/index.html#march-1",
    "href": "posts/2024-til/index.html#march-1",
    "title": "Today I learned (TIL) · 2024",
    "section": "10. March",
    "text": "10. March\nRecently, I started using the just command runner and have now used it regularly in several of my Python projects."
  },
  {
    "objectID": "posts/2024-03-21-py-jupyterlite-urllib3/index.html",
    "href": "posts/2024-03-21-py-jupyterlite-urllib3/index.html",
    "title": "Requests in JupyterLite",
    "section": "",
    "text": "Requests in JupyterLite\nIn a recent post, I tried to use requests in JupyterLite. It did not work at the time.\nToday, I have found out that urllib3 recently announced support for Pyodide, the Python distribution used by JupyterLite.\nNow, you can use requests or urllib3 in JupyterLite and this code does also work in the browser environment (install packages with micropip).\n\n# import micropip\n# await micropip.install(\"requests\")\n\nimport urllib3\nurllib3.disable_warnings()\n\nimport requests\n\nheaders = {\"accept\": \"text/x-bibliography\"}\nr = requests.get(\"https://doi.org/10.5281/zenodo.7043510\", headers=headers)\n\nr.text\n\n'Döring, H., &amp; Herrmann, M. (2024). &lt;i&gt;Party positions from Wikipedia tags&lt;/i&gt; (Version 24.07) [Computer software]. Zenodo. https://doi.org/10.5281/ZENODO.7043510'"
  },
  {
    "objectID": "posts/2023-04-23-py-chatgpt/index.html",
    "href": "posts/2023-04-23-py-chatgpt/index.html",
    "title": "R coding with ChatGPT",
    "section": "",
    "text": "R coding with ChatGPT\nFinally I got into ChatGPT and started using it.\nI was inspired to give ChatGPT a try after reading a post. The author describes using ChatGPT to code a  model.\nSo I had a conversation with ChatGPT about the social sciences, statistics and R.\nI have to say that I am impressed.\nChatGPT and I had an exchange about R. I asked for some examples. ChatGPT originally had a preference for Base-R code but it used more Tidyverse-R approaches after I asked for it. Or it converted the Base-R code to Tidyverse-R at my request.\nThe code examples were good and I really liked the comments it added to the code. At some point ChatGPT went back to Base-R and I could not fully convince it to use a Tidyverse-R first approach.\nSo here is a nice output from our exchange. I asked for a text analysis of a Biden speech in R.\nParts from the content of the exchange are below.\nI added the rvest::read_html parts from the ChatGPT suggestion. I did not find a way that ChatGPT added it to its initial script. ChatGPT had some Base-R and Tidyverse-R confusion at this point. I updated the title of the figure to the new speech title used as well.\nI don’t use tidytext regularly so looking up the information would have taken some time for me. Here, ChatGPT was very helpful. Thanks.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(rvest)\n\n# Read in the HTML document\nhtml_doc &lt;- read_html(\"https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\")\n\n# Extract the text\nbiden_speech &lt;- html_text(html_doc)\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(\n    x = \"Frequency\",\n    y = \"Word\",\n    title = \"Joe Biden's American Jobs Plan speech\",\n    subtitle = \"Most common words\"\n  )\n\n\n\n\n\nJoe Biden’s American Jobs Plan speech\n\n\n\nuser can we analyse a biden speech?\nChatGPT Yes, we can use text analysis techniques to analyze a speech by Joe Biden. Here’s an example using the tidytext package:\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Load speech data\nbiden_speech &lt;- read_lines(\"https://www.rev.com/blog/transcripts/joe-biden-covid-speech-transcript-september-9\")\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(x = \"Frequency\", y = \"Word\", title = \"Most common words in Joe Biden's COVID speech\")\nIn this example, we load the transcript of a speech by Joe Biden on the topic of COVID-19, which is available as a text file from the Rev.com blog. We tokenize the speech using the unnest_tokens() function, remove stop words using the anti_join() function, and calculate word frequencies using the count() function. Finally, we visualize the most common words using ggplot2. Note that in order to run this code, you will need to have the readr package installed to read in the text file from the web.\nuser the url does not work\nChatGPT I apologize for that. Here’s an updated example using a different speech by Joe Biden that is available as a text file from the University of Pennsylvania:\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Load speech data\nbiden_speech &lt;- read_lines(\"https://www.sas.upenn.edu/~jkingsby/BidenIowaSpeech.txt\")\n\n# Tokenize speech\nbiden_words &lt;- biden_speech %&gt;%\n  enframe(name = NULL, value = \"text\") %&gt;%\n  unnest_tokens(word, text)\n\n# Remove stop words\nbiden_words &lt;- biden_words %&gt;%\n  anti_join(stop_words)\n\n# Calculate word frequencies\nword_freq &lt;- biden_words %&gt;%\n  count(word, sort = TRUE)\n\n# Visualize word frequencies\nword_freq %&gt;%\n  top_n(20) %&gt;%\n  ggplot(aes(x = n, y = reorder(word, n))) +\n  geom_col() +\n  labs(x = \"Frequency\", y = \"Word\", title = \"Most common words in Joe Biden's Iowa speech\")\nIn this example, we load a different speech by Joe Biden that is available as a text file from the University of Pennsylvania. The rest of the code is the same as in the previous example.\nuser that url is also not working. do you have a link for a biden speech\nChatGPT I apologize for the inconvenience. Here is a link to a transcript of a recent speech by Joe Biden on infrastructure:\nhttps://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\nYou can copy the text of the speech from this page and use it in the read_lines() function to load it into R for analysis using the tidytext package.\nuser how can i convert a html document to text in r?\nChatGPT You can use the rvest package in R to extract text from HTML documents. Here’s an example code snippet that shows how to do this:\nlibrary(rvest)\n\n# Read in the HTML document\nhtml_doc &lt;- read_html(\"https://www.whitehouse.gov/briefing-room/speeches-remarks/2021/03/31/remarks-by-president-biden-on-the-american-jobs-plan/\")\n\n# Extract the text\ntext &lt;- html_text(html_doc)\n\n# Print the text\ncat(text)\nIn this example, we use the read_html() function from rvest to read in the HTML document from the provided URL. We then use the html_text() function to extract the text from the HTML document. Finally, we use cat() to print the text to the console.\nNote that the rvest package is designed for web scraping, so it is important to respect the terms of use and not use it to scrape websites without permission.\nuser ok, can you add that to the r code snippet above?\nChatGPT\n(…)"
  },
  {
    "objectID": "posts/2023-10-31-py-zenodo-api/index.html",
    "href": "posts/2023-10-31-py-zenodo-api/index.html",
    "title": "Zenodo API",
    "section": "",
    "text": "This week, I worked with the Zenodo API. My goals was to add Zenodo metadata to GitHub for the partypositions-wikitags project.\nThe code of the project is archived at Zenodo with the DOI 10.5281/zenodo.7043510.\nCode\nimport requests\n\nheaders = {\"accept\": \"text/x-bibliography\"}\nr = requests.get(\"https://doi.org/10.5281/zenodo.7043510\", headers=headers)\n\nr.text\n\n\n'Döring, H., &amp; Herrmann, M. (2024). &lt;i&gt;Party positions from Wikipedia tags&lt;/i&gt; (Version 24.07) [Computer software]. Zenodo. https://doi.org/10.5281/ZENODO.7043510'"
  },
  {
    "objectID": "posts/2023-10-31-py-zenodo-api/index.html#doi-api",
    "href": "posts/2023-10-31-py-zenodo-api/index.html#doi-api",
    "title": "Zenodo API",
    "section": "DOI API",
    "text": "DOI API\nSo here is some metadata information. Lets start with the DOI API.\n\nimport requests\n\ndoi = \"10.5281/zenodo.7043510\"\n\nheaders = {\"accept\": \"application/vnd.citationstyles.csl+json\"}\nr = requests.get(f\"https://doi.org/{doi}\", headers=headers)\n\nr.json()\n\n{'type': 'book',\n 'id': 'https://doi.org/10.5281/zenodo.7043510',\n 'language': 'en',\n 'author': [{'family': 'Döring', 'given': 'Holger'},\n  {'family': 'Herrmann', 'given': 'Michael'}],\n 'issued': {'date-parts': [[2024, 7, 31]]},\n 'abstract': 'Estimation of party positions from Wikipedia tags with Stan',\n 'DOI': '10.5281/ZENODO.7043510',\n 'publisher': 'Zenodo',\n 'title': 'Party positions from Wikipedia tags',\n 'URL': 'https://zenodo.org/doi/10.5281/zenodo.7043510',\n 'copyright': 'MIT License',\n 'version': '24.07'}"
  },
  {
    "objectID": "posts/2023-10-31-py-zenodo-api/index.html#zenodo-record",
    "href": "posts/2023-10-31-py-zenodo-api/index.html#zenodo-record",
    "title": "Zenodo API",
    "section": "Zenodo record",
    "text": "Zenodo record\nWe can also access a record through the Zenodo API. This does not require a Zenodo access token.\n\nr = requests.get(\"https://zenodo.org/api/records/8275697\")\nrecord = r.json()\n\nrecord.keys()\n\ndict_keys(['created', 'modified', 'id', 'conceptrecid', 'doi', 'conceptdoi', 'doi_url', 'metadata', 'title', 'links', 'updated', 'recid', 'revision', 'files', 'swh', 'owners', 'status', 'stats', 'state', 'submitted'])\n\n\nI was interested in the Zenodo metadata.\n\nrecord['metadata']\n\n{'title': 'Party positions from Wikipedia tags (July 2023)',\n 'doi': '10.5281/zenodo.8275697',\n 'publication_date': '2023-08-23',\n 'description': '&lt;p&gt;Estimation of party positions from Wikipedia tags with Stan (July 2023)&lt;/p&gt;',\n 'access_right': 'open',\n 'creators': [{'name': 'Holger Döring',\n   'affiliation': 'GESIS – Leibniz Institute for the Social Sciences'},\n  {'name': 'Michael Herrmann', 'affiliation': 'University of Konstanz'}],\n 'related_identifiers': [{'identifier': 'https://github.com/hdigital/partypositions-wikitags/tree/23.07',\n   'relation': 'isSupplementTo',\n   'scheme': 'url'}],\n 'version': '23.07',\n 'resource_type': {'title': 'Software', 'type': 'software'},\n 'license': {'id': 'other-open'},\n 'relations': {'version': [{'index': 1,\n    'is_last': False,\n    'parent': {'pid_type': 'recid', 'pid_value': '7043510'}}]}}"
  },
  {
    "objectID": "posts/2023-10-31-py-zenodo-api/index.html#github-metadata",
    "href": "posts/2023-10-31-py-zenodo-api/index.html#github-metadata",
    "title": "Zenodo API",
    "section": "GitHub metadata",
    "text": "GitHub metadata\nSome of the metadata is imported by Zenodo from Github and some metadata needs to be added or updated manually.\nYou can specify some of the addtional metadata in a .zenodo.json file in your GitHub repository.\nhttps://developers.zenodo.org/#github\nI used the archived Zenodo record for a json dump of the metadata.\n\nimport json\n\nprint(json.dumps(record['metadata'], indent=2))\n\n{\n  \"title\": \"Party positions from Wikipedia tags (July 2023)\",\n  \"doi\": \"10.5281/zenodo.8275697\",\n  \"publication_date\": \"2023-08-23\",\n  \"description\": \"&lt;p&gt;Estimation of party positions from Wikipedia tags with Stan (July 2023)&lt;/p&gt;\",\n  \"access_right\": \"open\",\n  \"creators\": [\n    {\n      \"name\": \"Holger D\\u00f6ring\",\n      \"affiliation\": \"GESIS \\u2013 Leibniz Institute for the Social Sciences\"\n    },\n    {\n      \"name\": \"Michael Herrmann\",\n      \"affiliation\": \"University of Konstanz\"\n    }\n  ],\n  \"related_identifiers\": [\n    {\n      \"identifier\": \"https://github.com/hdigital/partypositions-wikitags/tree/23.07\",\n      \"relation\": \"isSupplementTo\",\n      \"scheme\": \"url\"\n    }\n  ],\n  \"version\": \"23.07\",\n  \"resource_type\": {\n    \"title\": \"Software\",\n    \"type\": \"software\"\n  },\n  \"license\": {\n    \"id\": \"other-open\"\n  },\n  \"relations\": {\n    \"version\": [\n      {\n        \"index\": 1,\n        \"is_last\": false,\n        \"parent\": {\n          \"pid_type\": \"recid\",\n          \"pid_value\": \"7043510\"\n        }\n      }\n    ]\n  }\n}\n\n\nThen, I manually cleaned up the metadata:\n\nkept only entries that are not imported automatically\nused unicode characters for umlaute\nspecified license id\n\n\nmetadata_json = \"\"\"\n{\n  \"title\": \"Party positions from Wikipedia tags\",\n  \"description\": \"Estimation of party positions from Wikipedia tags with Stan\",\n  \"creators\": [\n    {\n      \"name\": \"Döring, Holger\",\n      \"affiliation\": \"GESIS – Leibniz Institute for the Social Sciences\"\n    },\n    {\n      \"name\": \"Herrmann, Michael\",\n      \"affiliation\": \"University of Konstanz\"\n    }\n  ]\n}\n\"\"\"\n\nHere, I validate the json. Running the cell should not raise an error.\n\nmetadata_json = json.loads(metadata_json)\n\nFinally, I added it to the GitHub repository – commit ac7c462 😊"
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html",
    "href": "posts/2024-08-31-uv/index.html",
    "title": "uv instead of venv/pip",
    "section": "",
    "text": "uv recently released its 0.3 version.\nuv is a package and project manager that potentially allows me to fully replace my venv/pip/pip-tools workflow and the use of pyenv as well as pipx. It provides a single tool, is significantly faster, and includes a complete project manager.\nThe 0.3 release added many new features and comprehensive documentation. Version 0.4, which revised the project workflow, has been released.\nPackage management has been challenging in Python and has often taken me a lot of time. uv has the potential to harmonize the approaches and tools I have used with a single tool.\nHere are the uv commands relevant to me, a collection inspired by this post."
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#installation",
    "href": "posts/2024-08-31-uv/index.html#installation",
    "title": "uv instead of venv/pip",
    "section": "Installation",
    "text": "Installation\nIt is recommended to install uv globally instead of using pip install uv."
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#uv-workflow",
    "href": "posts/2024-08-31-uv/index.html#uv-workflow",
    "title": "uv instead of venv/pip",
    "section": "uv workflow",
    "text": "uv workflow\nSpecify Python dependencies in a pyproject.toml (see Projects below).\nuv add ruff\n\nuv run ruff check\n\nuv lock --upgrade\nuv sync\n\nsource .venv/bin/activate\nwhich python"
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#projects",
    "href": "posts/2024-08-31-uv/index.html#projects",
    "title": "uv instead of venv/pip",
    "section": "Projects",
    "text": "Projects\nCreate a project with a README.md, a pyproject.toml, and an example script.\nuv init\nuv run hello.py\nYou can also specify a project name to create the project in a new folder."
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#python-versions",
    "href": "posts/2024-08-31-uv/index.html#python-versions",
    "title": "uv instead of venv/pip",
    "section": "Python versions",
    "text": "Python versions\nuv can install a specific Python version from python-build-standalone.\nThe Python version in a pyproject.toml or a .python-version file is used.\nThis allows me to replace pyenv, which I have used to manage different Python versions.\nuv venv --python 3.11\n\nuv python list\nuv python install --reinstall 3.10 3.11\nThere may be minor differences with other Python builds."
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#scripts",
    "href": "posts/2024-08-31-uv/index.html#scripts",
    "title": "uv instead of venv/pip",
    "section": "Scripts",
    "text": "Scripts\nYou can specify dependencies as embedded metadata in a script. uv will run the script and install the dependencies.\necho 'import urllib3; print(urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\").data)' &gt; robots.py\n\nuv add --script robots.py urllib3\n\nuv run robots.py"
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#python-tools",
    "href": "posts/2024-08-31-uv/index.html#python-tools",
    "title": "uv instead of venv/pip",
    "section": "Python tools",
    "text": "Python tools\nYou can run and install Python tools with uvx.\nIt can be used as a replacement for pipx.\nuvx ruff clean\n\nuv tool install ruff\nls -l $(which ruff)\n\nuv tool list\nuv tool upgrade --all"
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#venvpip-workflow",
    "href": "posts/2024-08-31-uv/index.html#venvpip-workflow",
    "title": "uv instead of venv/pip",
    "section": "venv/pip workflow",
    "text": "venv/pip workflow\nMy goal is to use the uv workflow, but here are some examples of using uv as as venv/pip/pip-tools replacement with the respective parameters.\nuv venv\nuv pip install urllib3\nsource .venv/bin/activate\nwhich python\n\necho \"urllib3\" &gt; requirements.in\nuv pip compile -U requirements.in -o requirements.txt\nuv pip sync requirements.txt"
  },
  {
    "objectID": "posts/2024-08-31-uv/index.html#clean-up",
    "href": "posts/2024-08-31-uv/index.html#clean-up",
    "title": "uv instead of venv/pip",
    "section": "Clean-up",
    "text": "Clean-up\nThe uv cache folder can get large quickly, so it is helpful to clean it up regularly\nuv cache prune\n\nuv cache clean\n\ndu -h -d 1 $(uv cache dir)\nKeep in mind that many .venv folders are created with a uv workflow, so you may want to remove them at some point.\nfind . -type d -name \".venv\" -print0 | xargs -0 du -sh"
  },
  {
    "objectID": "posts/2023-02-17-r-geom-col/index.html",
    "href": "posts/2023-02-17-r-geom-col/index.html",
    "title": "Horizontal bar chart",
    "section": "",
    "text": "Horizontal bar chart\nTo have horizontal bar charts ordered by frequency, I have used geom_bar() and coord_flip for a long time.\nI have now learned in an example that this is not necessary.\nHere are a few examples and the code for future references.\n\nlibrary(tidyverse)\n\nmtcars &lt;- as_tibble(datasets::mtcars)\n\n\nggplot(mtcars, aes(x = cyl)) +\n  geom_bar(fill = \"lightgreen\")\n\n\n\n\n\n\n\n\nI used to do some pre-processing to prepare data for the plot.\n\npl_dt &lt;-\n  mtcars |&gt;\n  mutate(cyl = fct_infreq(factor(cyl)) |&gt; fct_rev())\n\nFor the figure, I used coord_flip.\n\nggplot(pl_dt, aes(cyl)) +\n  geom_bar(fill = \"grey\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nThat was not necessary, as I have learned now.\n\nggplot(pl_dt, aes(y = cyl)) +\n  geom_bar(fill = \"lightblue\")\n\n\n\n\n\n\n\n\nHere is an alternative approach with geom_col().\n\npl_dt &lt;-\n  mtcars |&gt;\n  count(cyl) |&gt;\n  mutate(cyl = fct_reorder(factor(cyl), n))\n\nggplot(pl_dt, aes(x = n, y = cyl)) +\n  geom_col(fill = \"lightblue\")"
  },
  {
    "objectID": "posts/2023-07-30-py-playwright/index.html",
    "href": "posts/2023-07-30-py-playwright/index.html",
    "title": "Screenshots with Playwright",
    "section": "",
    "text": "Screenshots with Playwright\nI heard about Playwright in Episode #424 of Talk Python To Me.\nHere is an example of taking screenshots from the Playwright documentation which I updated for taking screenshots of this learning blog.\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as spw:\n    for browser_type in [spw.chromium, spw.firefox, spw.webkit]:\n        browser = browser_type.launch()\n        page = browser.new_page()\n        page.goto(\"https://hdigital.github.io/learning-diary/\")\n        page.screenshot(path=f\"screenshot-{browser_type.name}.png\")\n        browser.close()\nThe code needs to be run in a Python script and does not run in Jupyter.\n\n\nChromium screenshot · 💻\n\n\n\nFirefox screenshot · 💻\n\n\n\nWebkit screenshot · 💻"
  },
  {
    "objectID": "posts/2025-07-16-post/index.html",
    "href": "posts/2025-07-16-post/index.html",
    "title": "Claude Sonnet 4 coding agent",
    "section": "",
    "text": "This week I explored Claude Sonnet 4 and GitHub Copilot’s new Agent Mode. Claude Sonnet 4, recently released by Anthropic, is particularly strong at coding tasks. Agent Mode was added to Copilot and VS Code earlier this year. I was inspired to try them both after reading a recent post that advocates delegating all development tasks to a coding agent."
  },
  {
    "objectID": "posts/2025-07-16-post/index.html#what-is-agent-mode",
    "href": "posts/2025-07-16-post/index.html#what-is-agent-mode",
    "title": "Claude Sonnet 4 coding agent",
    "section": "What Is Agent Mode?",
    "text": "What Is Agent Mode?\nUntil now, I’ve mainly interacted with LLMs via chat and through Copilot’s inline suggestions in VS Code. Agent Mode is something more: it’s like a true pair programmer. It reads files in your project, executes commands, makes and reviews changes, commits code, and creates pull requests. It supports nearly the full programming workflow autonomously."
  },
  {
    "objectID": "posts/2025-07-16-post/index.html#what-i-tried",
    "href": "posts/2025-07-16-post/index.html#what-i-tried",
    "title": "Claude Sonnet 4 coding agent",
    "section": "What I Tried",
    "text": "What I Tried\nI used the Claude coding agent for several tasks—code reviews, feature implementation, and changelog updates—and was impressed across the board.\n\nCode Reviews\nFirst, I asked Claude to review multiple projects. For two current ones, it gave helpful feedback and practical improvement suggestions. For two legacy codebases, Claude’s assessments were insightful: one codebase was maintainable but needed refactoring, while the other was outdated beyond repair—though Claude acknowledged the embedded domain expertise.\n\n\nIssue Resolution\nNext, I asked Claude to fix an open GitHub issue, replacing one package with another offering similar functionality. Claude reviewed the GitHub issue, checked the documentation for both packages, implemented the change, validated it, and refined it after testing. It then created a branch, made the commit, and opened a PR. I only had to supervise and approve command execution. The entire task, from reading the issue to a working PR, was handled autonomously.\n\n\nChangelog Updates\nFinally, I asked Claude to generate and update changelogs for several projects. I provided a template from one project, and Claude analyzed commits, PRs, and issues to generate changelogs for each project, following the structure I shared."
  },
  {
    "objectID": "posts/2025-07-16-post/index.html#what-didnt-work",
    "href": "posts/2025-07-16-post/index.html#what-didnt-work",
    "title": "Claude Sonnet 4 coding agent",
    "section": "What Didn’t Work?",
    "text": "What Didn’t Work?\nIn one code review, Claude overemphasized legacy documentation included in the repo, resulting in an overly critical assessment.\nAdditionally, I realized that the way I phrased my prompt had a significant impact on its interpretation. Once reframed, Claude’s feedback was more balanced."
  },
  {
    "objectID": "posts/2025-07-16-post/index.html#final-thoughts",
    "href": "posts/2025-07-16-post/index.html#final-thoughts",
    "title": "Claude Sonnet 4 coding agent",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nClaude Sonnet 4 in VS Code Copilot agent mode impressed me. It felt less like a tool and more like a colleague. I also tested GPT-4 in a similar setup, but Claude was noticeably more capable. To me, these tools signal a real shift in how we write and maintain code—one where LLMs become integral to the development workflow."
  },
  {
    "objectID": "posts/2024-07-14-r-geocoding/index.html",
    "href": "posts/2024-07-14-r-geocoding/index.html",
    "title": "Geocoding in R",
    "section": "",
    "text": "Geocoding in R\nGeocoding of places in R with the tidygeocoder package using the OpenStreetMap Nominatim API and creating a sf geometry list-column.\n\nlibrary(tidyverse)\nlibrary(sf)\n\nplaces &lt;-\n  tibble(\n    city = c(\n      \"Berlin\", \"Bremen\", \"Bielefeld\", \"Dortmund\", \"Dresden\", \"Flensburg\", \"Frankfurt\",\n      \"Freiburg\", \"Hamburg\", \"Hannover\", \"Kassel\", \"Köln\", \"Konstanz\", \"Leipzig\",\n      \"Magdeburg\", \"München\", \"Passau\", \"Rostock\", \"Trier\", \"Nürnberg\", \"Stuttgart\"\n    )\n  )\n\nplaces &lt;-\n  places |&gt;\n  tidygeocoder::geocode(city, method = \"osm\") |&gt;\n  st_as_sf(crs = \"EPSG:4326\", coords = c(\"long\", \"lat\"), na.fail = FALSE)\n\nwrite_rds(places, \"deu-cities_sf.rds\")\n\n\n\nCode\nlibrary(tidyverse)\n\n# use data in rds-file to avoid geocoding request of 20s\nplaces &lt;- read_rds(\"deu-cities_sf.rds\")\n\nggplot() +\n  geom_sf_label(data = places, aes(label = city)) +\n  coord_sf(crs = \"EPSG:4839\") + # LLC projection Germany\n  theme_void()"
  },
  {
    "objectID": "posts/2024-10-27-py-urllib3/index.html",
    "href": "posts/2024-10-27-py-urllib3/index.html",
    "title": "http requests with urllib3",
    "section": "",
    "text": "My goal is to use the urllib3 more regularly. It is a library that has no dependencies (see below)\nHere are some examples of making http requests with urllib3.\nimport urllib3\n\nresp = urllib3.request(\n  \"GET\",\n  \"https://doi.org/10.1177/1465116507076430\",\n  headers = {\"accept\": \"application/vnd.citationstyles.csl+json\"}\n  )\nresp.status\n\n200\ndoi_json = resp.json()\ndoi_json['author']\n\n[{'given': 'Holger',\n  'family': 'Döring',\n  'sequence': 'first',\n  'affiliation': [{'name': 'Max Planck Institute for the Study of Societies, Germany,'}]}]\nresp.data[:100]\n\nb'{\"indexed\":{\"date-parts\":[[2025,7,8]],\"date-time\":\"2025-07-08T00:11:55Z\",\"timestamp\":1751933515556,\"'"
  },
  {
    "objectID": "posts/2024-10-27-py-urllib3/index.html#dependencies",
    "href": "posts/2024-10-27-py-urllib3/index.html#dependencies",
    "title": "http requests with urllib3",
    "section": "Dependencies",
    "text": "Dependencies\nurllib3 has no dependencies and the popular requests library uses urllib3.\nHere is a documentation of the dependencies with uv.\nuv init uv-project\ncd uv-project\n\nuv add urllib3\nuv tree\nResolved 2 packages in 2ms\nuv-project v0.1.0\n└── urllib3 v2.2.3\nuv remove urllib3\nuv add requests\nuv tree\nResolved 6 packages in 2ms\nuv-project v0.1.0\n└── requests v2.32.3\n    ├── certifi v2024.8.30\n    ├── charset-normalizer v3.4.0\n    ├── idna v3.10\n    └── urllib3 v2.2.3"
  },
  {
    "objectID": "posts/2024-10-25-r-broadcaster/index.html",
    "href": "posts/2024-10-25-r-broadcaster/index.html",
    "title": "Public broadcasting Germany",
    "section": "",
    "text": "Today, there was a decision about a public broadcasting reform in Germany.\nThere were suggestions to reduce the number of public broadcasters before the meeting of the Minister-presidents.\nSo, I was interested in the state’s population, which is covered by German public broadcasters.\n\n\nCode\nlibrary(conflicted) # create errors for function name conflicts\n\nlibrary(tidyverse)\nconflicts_prefer(dplyr::filter, .quiet = TRUE)\n\nlibrary(sf)\nlibrary(patchwork)\n\nggplot2::theme_set(theme_minimal())\n\n\n\n\nCode\nstates_raw &lt;- read_csv(\"rundfunk-laender.csv\")\nmap_raw &lt;- read_rds(\"r-ne_states-deu.rds\")\n\n## Broadcaster ----\n\nservices &lt;-\n  map_raw |&gt;\n  inner_join(states_raw) |&gt;\n  summarise(\n    n = n(),\n    pop_sum = sum(population),\n    pop_mio = NA,\n    states = paste0(sort(state), collapse = \", \"),\n    geometry = st_union(geometry) |&gt; st_centroid(),\n    .by = service\n  ) |&gt;\n  mutate(pop_mio = round(pop_sum / 1e6, 1)) |&gt;\n  select(-pop_sum) |&gt;\n  arrange(service)\n\n\n\n\nCode\npl_dt &lt;-\n  services |&gt;\n  mutate(service = fct_reorder(factor(service), pop_mio))\n\n## bar chart\npl1 &lt;-\n  ggplot(pl_dt, aes(x = pop_mio, y = service)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = \"\")\n\n# map German states\npl2 &lt;-\n  ggplot() +\n  geom_sf(data = map_raw, colour = \"grey85\", lwd = 0.3) +\n  geom_sf(data = services, aes(size = pop_mio, colour = service), alpha = 0.4) +\n  coord_sf(crs = \"EPSG:4839\") + # LCC projection Germany\n  guides(colour = \"none\", size = \"none\") +\n  theme_void()\n\npl2 + pl1 + plot_layout(widths = c(3, 2))\n\n\n\n\n\n\n\n\n\nCode\nggsave(\"broadcaster-deu.png\", pl2, width = 3, height = 5, dpi = 300)\n\nservices |&gt;\n  st_drop_geometry()\n\n\n\n\n\n\nservice\nn\npop_mio\nstates\n\n\n\n\nBR\n1\n13.4\nBY\n\n\nHR\n1\n6.4\nHE\n\n\nMDR\n3\n8.4\nSN, ST, TH\n\n\nNDR\n4\n14.6\nHH, MV, NI, SH\n\n\nRB\n1\n0.7\nHB\n\n\nRBB\n2\n6.3\nBB, BE\n\n\nSR\n1\n1.0\nSL\n\n\nSWR\n2\n15.4\nBW, RP\n\n\nWDR\n1\n18.1\nNW\n\n\n\n\n\n\nSources\n\nStatistische Ämter des Bundes und der Länder, dl-de/by-2-0\n\nFläche und Bevölkerung nach Ländern\n\nNatural Earth"
  },
  {
    "objectID": "posts/2024-07-13-r-httr-doi/index.html",
    "href": "posts/2024-07-13-r-httr-doi/index.html",
    "title": "DOI reference with httr2",
    "section": "",
    "text": "DOI reference with httr2\nGet citation references from DOI API with httr2.\n\nlibrary(tidyverse)\nlibrary(httr2)\n\nget_doi_reference &lt;- function(doi) {\n  request(paste0(\"https://doi.org/\", doi)) |&gt;\n    req_headers(\"Accept\" = \"text/x-bibliography\") |&gt;\n    req_perform() |&gt;\n    resp_body_string()\n}\n\nreferences &lt;-\n  tibble(\n    doi = c(\n      \"10.1177/1465116507076430\",\n      \"10.1080/01402382.2013.783347\",\n      \"10.1177/0958928715573481\",\n      \"10.1017/pan.2021.28\"\n    )\n  ) |&gt;\n  mutate(reference = map_chr(doi, get_doi_reference))\n\nreferences\n\n\n\n\n\n\n\n\n\ndoi\nreference\n\n\n\n\n10.1177/1465116507076430\nDöring, H. (2007). The Composition of the College of Commissioners. European Union Politics, 8(2), 207–228. https://doi.org/10.1177/1465116507076430\n\n\n10.1080/01402382.2013.783347\nDöring, H., & Hellström, J. (2013). Who Gets into Government? Coalition Formation in European Democracies. West European Politics, 36(4), 683–703. https://doi.org/10.1080/01402382.2013.783347\n\n\n10.1177/0958928715573481\nDöring, H., & Schwander, H. (2015). Revisiting the left cabinet share: How to measure the partisan profile of governments in welfare state research. Journal of European Social Policy, 25(2), 175–193. https://doi.org/10.1177/0958928715573481\n\n\n10.1017/pan.2021.28\nHerrmann, M., & Döring, H. (2021). Party Positions from Wikipedia Classifications of Party Ideology. Political Analysis, 31(1), 22–41. https://doi.org/10.1017/pan.2021.28"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning",
    "section": "",
    "text": "Claude Sonnet 4 coding agent\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nJul 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned (TIL) · 2025\n\n\n\nTIL yearly\n\n\n\n\n\n\n\n\n\nApr 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nColor Chart page with AI\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nJan 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nhttp requests with urllib3\n\n\n\nPython\n\nAPI\n\n\n\n\n\n\n\n\n\nOct 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPublic broadcasting Germany\n\n\n\nR\n\nggplot\n\ngeo\n\n\n\n\n\n\n\n\n\nOct 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nArrange plots with tables\n\n\n\nR\n\nggplot\n\n\n\n\n\n\n\n\n\nSep 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nuv instead of venv/pip\n\n\n\nPython\n\npackaging\n\n\n\n\n\n\n\n\n\nAug 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nThousands categories\n\n\n\nR\n\nggplot\n\n\n\n\n\n\n\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRound to first two digits\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nJul 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSelect map region in R\n\n\n\nR\n\ngeo\n\n\n\n\n\n\n\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBar charts with ggplot\n\n\n\nR\n\nggplot\n\nAI\n\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeocoding in R\n\n\n\nR\n\ngeo\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDOI reference with httr2\n\n\n\nR\n\nAPI\n\n\n\n\n\n\n\n\n\nJul 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned (TIL) · 2024\n\n\n\nTIL yearly\n\n\n\n\n\n\n\n\n\nJun 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npip install in cell\n\n\n\nPython\n\npackaging\n\n\n\n\n\n\n\n\n\nApr 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nR in Docker and Codespaces\n\n\n\nR\n\ncloud\n\nDocker\n\npackaging\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRequests in JupyterLite\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nMar 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPython f-strings\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nToday I learned (TIL) · 2023\n\n\n\nTIL yearly\n\n\n\n\n\n\n\n\n\nNov 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\niPython display\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nNov 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nJupyterLite\n\n\n\nPython\n\npackaging\n\n\n\n\n\n\n\n\n\nNov 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAPI requests with httr2\n\n\n\nR\n\nAPI\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPython Pizza Hamburg\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\npyproject.toml metadata and dependencies\n\n\n\nPython\n\npackaging\n\n\n\n\n\n\n\n\n\nNov 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nZenodo API\n\n\n\nPython\n\nAPI\n\n\n\n\n\n\n\n\n\nOct 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGet DOI metadata\n\n\n\nPython\n\nAPI\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nR packages with pak\n\n\n\nR\n\npackaging\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto version in Docker\n\n\n\nDocker\n\nQuarto\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFile hashing\n\n\n\nR\n\n\n\n\n\n\n\n\n\nAug 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr join_by() argument\n\n\n\nR\n\ntidyverse\n\n\n\n\n\n\n\n\n\nAug 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nScreenshots with Playwright\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nJul 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPackage versions with renv\n\n\n\nR\n\npackaging\n\n\n\n\n\n\n\n\n\nJul 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFirst pull request accepted · 😊\n\n\n\nR\n\ngit\n\n\n\n\n\n\n\n\n\nJul 16, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ndplyr programming\n\n\n\nR\n\ntidyverse\n\n\n\n\n\n\n\n\n\nJun 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nstring interpolation with str_glue()\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJun 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nConditional R cells\n\n\n\nR\n\nQuarto\n\n\n\n\n\n\n\n\n\nJun 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGit rebase interactive\n\n\n\ngit\n\n\n\n\n\n\n\n\n\nJun 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter notebooks in Git\n\n\n\nPython\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Codespaces\n\n\n\ncloud\n\nPython\n\n\n\n\n\n\n\n\n\nJun 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Pages\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\nJun 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAI images with DALL-E\n\n\n\nAI\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWikipedia, Python, ChatGPT\n\n\n\nPython\n\nAI\n\ngeo\n\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGeocoding in Python\n\n\n\nPython\n\ngeo\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDataverse URLs\n\n\n\nR\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPosit Cloud\n\n\n\nR\n\ncloud\n\n\n\n\n\n\n\n\n\nApr 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nR coding with ChatGPT\n\n\n\nR\n\nAI\n\n\n\n\n\n\n\n\n\nApr 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWebR (WebAssembly)\n\n\n\nR\n\ncloud\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPyScript (WebAssembly)\n\n\n\nPython\n\ncloud\n\n\n\n\n\n\n\n\n\nMar 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nA few days of Quarto\n\n\n\nDocker\n\nPython\n\nQuarto\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPython visualization with Altair\n\n\n\nPython\n\nggplot\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHello Jupyter\n\n\n\nPython\n\nQuarto\n\n\n\n\n\n\n\n\n\nFeb 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter notebooks with Quarto\n\n\n\nPython\n\nQuarto\n\n\n\n\n\n\n\n\n\nFeb 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHorizontal bar chart\n\n\n\nR\n\nggplot\n\n\n\n\n\n\n\n\n\nFeb 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nThings I learned: A new TIL\n\n\n\nR\n\nPython\n\nQuarto\n\n\n\n\n\n\n\n\n\nFeb 16, 2023\n\n\n\n\n\nNo matching items"
  }
]